{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition for House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fields\n",
    "\n",
    "brief version of eah row.\n",
    "\n",
    "* SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "* MSSubClass: The building class\n",
    "* MSZoning: The general zoning classification\n",
    "* LotFrontage: Linear feet of street connected to property\n",
    "* LotArea: Lot size in square feet\n",
    "* Street: Type of road access\n",
    "* Alley: Type of alley access\n",
    "* LotShape: General shape of property\n",
    "* LandContour: Flatness of the property\n",
    "* Utilities: Type of utilities available\n",
    "* LotConfig: Lot configuration\n",
    "* LandSlope: Slope of property\n",
    "* Neighborhood: Physical locations within Ames city limits\n",
    "* Condition1: Proximity to main road or railroad\n",
    "* Condition2: Proximity to main road or railroad (if a second is present)\n",
    "* BldgType: Type of dwelling\n",
    "* HouseStyle: Style of dwelling\n",
    "* OverallQual: Overall material and finish quality\n",
    "* OverallCond: Overall condition rating\n",
    "* YearBuilt: Original construction date\n",
    "* YearRemodAdd: Remodel date\n",
    "* RoofStyle: Type of roof\n",
    "* RoofMatl: Roof material\n",
    "* Exterior1st: Exterior covering on house\n",
    "* Exterior2nd: Exterior covering on house (if more than one material)\n",
    "* MasVnrType: Masonry veneer type\n",
    "* MasVnrArea: Masonry veneer area in square feet\n",
    "* ExterQual: Exterior material quality\n",
    "* ExterCond: Present condition of the material on the exterior\n",
    "* Foundation: Type of foundation\n",
    "* BsmtQual: Height of the basement\n",
    "* BsmtCond: General condition of the basement\n",
    "* BsmtExposure: Walkout or garden level basement walls\n",
    "* BsmtFinType1: Quality of basement finished area\n",
    "* BsmtFinSF1: Type 1 finished square feet\n",
    "* BsmtFinType2: Quality of second finished area (if present)\n",
    "* BsmtFinSF2: Type 2 finished square feet\n",
    "* BsmtUnfSF: Unfinished square feet of basement area\n",
    "* TotalBsmtSF: Total square feet of basement area\n",
    "* Heating: Type of heating\n",
    "* HeatingQC: Heating quality and condition\n",
    "* CentralAir: Central air conditioning\n",
    "* Electrical: Electrical system\n",
    "* 1stFlrSF: First Floor square feet\n",
    "* 2ndFlrSF: Second floor square feet\n",
    "* LowQualFinSF: Low quality finished square feet (all floors)\n",
    "* GrLivArea: Above grade (ground) living area square feet\n",
    "* BsmtFullBath: Basement full bathrooms\n",
    "* BsmtHalfBath: Basement half bathrooms\n",
    "* FullBath: Full bathrooms above grade\n",
    "* HalfBath: Half baths above grade\n",
    "* Bedroom: Number of bedrooms above basement level\n",
    "* Kitchen: Number of kitchens\n",
    "* KitchenQual: Kitchen quality\n",
    "* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "* Functional: Home functionality rating\n",
    "* Fireplaces: Number of fireplaces\n",
    "* FireplaceQu: Fireplace quality\n",
    "* GarageType: Garage location\n",
    "* GarageYrBlt: Year garage was built\n",
    "* GarageFinish: Interior finish of the garage\n",
    "* GarageCars: Size of garage in car capacity\n",
    "* GarageArea: Size of garage in square feet\n",
    "* GarageQual: Garage quality\n",
    "* GarageCond: Garage condition\n",
    "* PavedDrive: Paved driveway\n",
    "* WoodDeckSF: Wood deck area in square feet\n",
    "* OpenPorchSF: Open porch area in square feet\n",
    "* EnclosedPorch: Enclosed porch area in square feet\n",
    "* 3SsnPorch: Three season porch area in square feet\n",
    "* ScreenPorch: Screen porch area in square feet\n",
    "* PoolArea: Pool area in square feet\n",
    "* PoolQC: Pool quality\n",
    "* Fence: Fence quality\n",
    "* MiscFeature: Miscellaneous feature not covered in other categories\n",
    "* MiscVal: $Value of miscellaneous feature\n",
    "* MoSold: Month Sold\n",
    "* YrSold: Year Sold\n",
    "* SaleType: Type of sale\n",
    "* SaleCondition: Condition of sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                 0\n",
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "                ... \n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "SalePrice          0\n",
       "Length: 81, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAE6CAYAAAAodIjdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABCVklEQVR4nO2dZ9gkRbWA37O7hBXYFUSRDBJFZIkKSuaKckVFMioogmAiiOGacAkKihJURCW4AgomgmAAJCxRFlg2ESVLULgkReASz/1xqnf66+k44Zvub877PPPMdE9Vd3U6XXVSiariOI7jjD7jBt0Ax3GcYcUFsOM4zoBwAew4jjMgXAA7juMMCBfAjuM4A8IFsOM4zoCYULrggsv23V/t+UeuHrE8cZnN+r1Lx3HGCEn5UYbRkDEvv/iwZP1XWgB3ggtUx3FGi4nLbFYohOsmg6RsIEa/e8BpJ65uJ8txnPriPWDHcQaOjzybQ22McH6TOE5/6KRn6IwOfesBV30L+03iOP1hWDs3acddNznTNwE8rBfdcRynLLXRAbvAdhynl9Stt5tGbbwgwI0HjtMrhvVZKjruQZyXRnhBNOFt5ThNYVgEbpw0GVJ3uVIbI5zjOL3Bn73mUBsjXJkoFsdxqvP8I1e7EK4proJwnCGg6vPVrduoC/xy1EYAO47TH/ohDF3A9gaPhHMcxxkQtRHAjuP0hiLXq7FKEztxtfGCGJabxHFGgyYKo25pogypjReE4zi9wd3QmkNtjHDuhuY4vcEFbou6q2NcBeE4zpil7nLFVRCOM8ZwFURzcBWE4zhjkqHOB+w4zmAY1h5vshNXN2GbRm0EcBNOluM0gV48S00MRS6jeqmbnKmNEc5xnP4wrKHIdRO2adSmB+w6YMfpDU0Qjo5RGy8IF76O0xt89NkcatMDdhynN7jAbQ61EcCugnAcpxvKvHjqJmNqI4DB39yO0yuGVQ3RtOOuzazIaW+mup88x6kj7oZWHp8VOeDC1nH6w7C6oTWB2ghgaN7wwXHqiD83zaE2ArhuynHHaSrekWkOHgnnOI4zIGrTA3Y3NMfpDd7ZaQ61iYRzHMfphiZ24mozK3LTTpzjOPWiiTKkVioIx3G6x+0vzaE2Ahj8xnGcXuDPTXOojQBu4vDBceqId2SaQ210wI7jOMNGbXrA/pZ2nP7QjxwJdcwF0URqk4wHfOjkOE53VH3ZDDoZT21UEK4DdhynG5ooQ2ojgB3HcYaN2ghgVzc4jjNs1EYAN3H44DiO0w218YJwHKc3uDG7OdRGADcxkYbjOM2ibi8jd0NzHGfM0DQ3tNokZPfer+M43dBEGeL5gB1njOEjyeZQGy8Iv0kcxxk2amOEa+LwYSzT7fVIvlC9VzZ6+LltDrURwE696PVD7ELBcdpxFYTjOM6A6GsP2IedzaUXKiFXQwyOYTzXabEEdT/u2vgBpz3wdT95jlNHmiaEekU/8h73gkb4ATuO0xv8WTPSzkPdjP21McJ5KLLjOL2kCfKkNoEYTThZjtMEfPTZHGrVA3Ycp3v8WWoOtRHA4G9ux+kF/hw1h9p4QTiO0zuGVQjX8bjzvCBqI4DdDc1xnG4oI3wHIaDdDc1xhgh/9owmGPZrowN2NzTH6Q3DKnCbSG1yQbjwdRxn2KiNH7DjOL3BVRDNwVUQjuOMSZoQilwbLwjwN7fj9IphfZaaNimn64AdZ4zhwrc51EYF4TiO00ua8OJxFYTjOGMCzwfcBU0cPjhOHfGOTHOojQB2HKc3uMA1muAFURsB7G5ojtMbvAdsNEGe1EYAO/XCJ+VsLsnOTL90o0XbHe3r28ROXN+McFUfNs+G5jhON9T1BT8QI1xdDt5xnOGkTG940HKqNiqIJg4fxjLdXosi9UNaGac31LUnONo0wQjnKgjHccYE7gccw4Wn4zhOPrXJBeEC23GcYaOvOmDXRTmOM1o00Y7UVwFcReA27cQ5Tl0Z1o5PJ5NyDhqflNNxnDFJ3YRtGrUxwjVx+OA4dcQ7O82hNn7ALnwdpzf46NMYahWE4zj1oB/+sXXLA5FG3YRtGrURwHW4YI7jOKOJz4jhOM6YoWmTctamB9yE4YLjNIFh7cg0UYbURgA7jtMbhkXgjgU8FNlxHGdA1KoH7ELYcbpnWFUQSYbaDc3TUTrOYPDnxqibsE3DI+Ecx3EGRG10wI7jON3QxJ5/bQSw934dx+mGJsqQ2uiAHcfpDf7sNQfXATuOMyYZai+IqtTtxDhOU/Eer9EEmVIbHbDjOM6wURsdsKsgHKc3uA64OYxaD9iFq+OMDkmBOyzPXhNfNLUxwg3LTeI4/WZYe8BNlCG1UUE4juMMG7XpAbsO2HGcXtIEN7RazYjhOI7TKf2Y+64XNHZGDFdbOE51XP3XHGrjB+w3ieM4w0ZtesCO4/SGYe3MNNGOVJsecNNOnOM49aKJMsR7wI4zxnAdcHOoTQ/YbxLHcYaN2gRiNHH44Dh1xDsz2dTt3NQmEMNxnN7gKohs6nZuaqMDbqIF03HqyKCFSl1oQiRcbQSw4zi9o249vdEg2Ymrm7BNo1YCeBhuEsfpN8MofKEZAjdJrY1ww3LjOI4znNTGCOc6YMdxhg1XQTjOGMOfo+ZQGwHsKgjHcYaN2uiAXQXhOL1hWI1wTaRWCdn9xnGc3jCsz1LRcQ/ivAwkIbuHIjebbq9HHW78YWYYz2/aPVt3uVIbLwinXvT6+vn94Djt1KYH7Dpgx3F6yVCHIlft8dTtxDiO02yaIFNqkw/YcRxn2KiNAHYdoeM4w0ZtBLDjOE43NLETV+tIOMdxqjOsLn9NlCG1EcCO4/SGYRG4YwF3Q3McxxkQ7obmOGOMYVVBNBFXQTjOGKeTzk23qQNc6JejNgLYVRCO0xtGQ/i5gO0NtRHAjuM43ZDWiStKCjVoaiOA63ZiHMdpFp4NzXGcgeNGuOZQGwHsOmDH6Q9uhKsvtRHALnwdpze4Ea451EYAO47TG1wF0Rw8Es5xHGdAjFo2NBeujjM61N31ql80safvociOM8bohTtWE41wTZQhrgN2nDGGG+GaQ20SsvsFdRxn2KhND7iJwwfHqSPuBdEcaiOAHcfpDS5wm4OrIBzHcQaE94AdZwwyjGqIJsYS1EYAN+3EOU6dGQaBm6SJMqQ2AthxHKeXpL2E6iakayOAmzh8cJw6MozqhzSaIE9EVUsVnLDgsuUKOo7jDIAyAncQL6OXX3xYsv6rTQ847eQN65vbcZzuaYL8qI0AdhVEvej2WpRJCNOEB6SJuArCqGuPOE7fVBCdPHB+4zhObxjWZ6nXSYd6wUBUEJ4NzXEGx7AI3DhNlCG1ScjuOI4zbNSmB+w6YMfpDd75aQ61McK58HWc/uCzIteX2ghgx3F6gydkNzwSrgKugnCc3tCL52gs9ICbIE9qI4Adx+kNaZ2ZXgvEOgjYJGWOu25CuTYCuG4nxnGaTB0FZL9povGxNgLYcRynlzShU1cbP2DXATuOM2zUxg/Yha/jON1QRubUTc7UqgfsOE73NFEX2gvqJlzLUJseMAzvjeM4vcSfm+bgCdkdZwwyrJ0Zz4bWIZ4v1nF6xzA+O66CcBxn4Axr7zeJhyJXwN3QHMfpJU2QJ+MG3YCIJpwsx3GcXlKbHrDjOL1hWFUOTaQ2AthVEI7TG1wHbDRBB1wrNzS/cRynNwzrs+RuaIGqN0Dd3kyO02SGReDGaaIMqY0RznEcZ9ioTSiy64AdpzcMq/qhidSmB+zC13GcYaM2OmDHcXqDP2vNwVUQY4AmTJDoOE47tfEDdjrHBazjNLMTVxsB3LQT5zh1ZVjVf02UIbURwI7j9IZhEbhJ6j4FfRq1EcBNHD44jlMfmig/aiOAm3jyHKeODKsKoom4G5rjjDH8WWsO7obmOGOMXjxH3eZuqcNLwLOhVcR7zY7jdINnQ+uQur2ZHKepDGtHpokypDa5IBzHcYaN2gjgYXlLO47jRNTGC6KJwwfHcZxuqE0P2HEcZ9hwNzTHGWO4Oq851MYLwnH6gXsEGMNw3E3sxNVGADftxDnNYBgET5JhFL5Q7rjrJmdqI4Adx+kNwyJwxwK1McL5TeM4zrBRmx5w3YYGjuM0mybIlNoIYKdedHvzFiXH9hFP//Bz3Rz6loynk5vAbxzHcTqlk07DmE3G48LTcZzRxN3QusSFtuN0z7COJJsmfKFGAjjt5A3LjeM4vcSfm+ZQm2Q8TRw+OE4dGdYecBOpjQ7Yha/jOMNGbQIxHMdxhg5VrfQB9ut3nX6XHyv7qGOb/LjrU36s7KOObeq0Tts2OtjpTf2u0+/yY2UfdWyTH3d9yo+VfdSxTZ3WSX5cBeE4jjMgXAA7juMMiE4E8MmjUKff5cfKPurYptHYRx3bNBr7qGObRmMfdWxTp3VGUDoXhOM4jtNbXAXhOI4zIFwAO47jDAgXwI7jOAOiFgJYRN466DY4Tr8RkfEi8ssS5ZbI+4xGW3uBiKww6DbUndxcECKyY97/qnpuQf1NgdVUdZqIvB5YVFXvSyl6kogsBPwc+KWq/iu/2SAiqwAPqeoLIrIlsA5whqo+3avjEJHXAJ8HVlDVT4jIasAaqvqHRLlDCrZ/XN7/Zc5TJ/uoWkdE5gFpVlmx4rpO3vZS9r+oqv4nZf0k4PWqek9i/TqqOjdjW2nX8F/APFV9LFF2/bx2qerNifIbq+r1eXXyEJHxwFLEnidV/XvKfl8RkRVFZEFVfTFnkzOx6yDACsBT4fdrgb8DK3fa1jTCs7cTsBIjj+GIRLmq98f5wPqh7jmqulOFNr0e+ERKmz6eUvbdwGKq+rvE+p2Bf6nqXxLrO3peRUSADwNvUtUjwgvmjap6Q6mDSqEoGc/7wvcbgHcAl4flrYDrgEwBLCJTgQ2BNYBpwALAL4B3Jsuq6mZBuH0cmCkiNwDTkicuwTnAhiKyKuYO8nvgLOC/e3gc07CHYZOw/DDwW+APiXKLhe81gI2AC2L7zb04Fc5TJ/tYLGN9FttXLF/EbZgAmY+I7AqcADwmIgsAH1PVG8PfPyc8sCnsg12HK8Lylti1WVlEjlDVM2Nlj81pkwJbJ9adREtQ/FVVN2mrlYGIHABMBR4FXo3tI+tldS9wrYhcADw7v1Gxh15VVw7bPgU4T1X/FJa3A3Yo0aZnaAnKBbF76llVnZRR5ffYy2wm8ELOpqveH/GZIN5Use7vgauBS4FXCsp+g/TzMh24EEjKkarPRcRJ2DXeGjgCeAaTQxt1uL1yocjAJcDSseWlgYsL6szGLsCs2Lq5BXXGY2/ih4HbgTuAHTPK3hy+vwgcEH7PKth+peMghBomjmFOTvmrsDdxtLwYcFUvz1Mn++jnBzgk4/N54MmM4106/H5buMYfLLp+wMXAUrHlpcK6JYBbujyGWWm/S9a9G3hdhfJT0z4ZZeeVWVewP8GE07dzynR1/nK2e3Pa75J1Z1comxkSXCRzOjmesvKgzKdsOsrlVfUfseVHSfRsUnhRVVVE7C4QWSSroIisA+wNvBd7W71PVW8WkWWAv5LeQ31JRPYAPkqrh7tAj4/jRRGZSOhNBLVHXg9hKSA+tHwxrMuj9HnqdB8isjDWg3wLsHC0XlOGc6H8xsAPgTdjPajxZPegjgK+C7yc8l+ajWF8dA1U9QYR2Qr4g4gsT/rwNmJ5VX00tvxYWPekiLyUVUlE1gbWYuRxn5Fsp4gsHtob/ZZY+Sdz2vUg1nsshaoeXrYs8IiIfB0bEYENfx+pUB81KXF+GGl9OaPYdSLyVlWdV2abFe6PKSLyb+xcToz9jpqW1SMHuyf+W0Pvv4BJIjJBVUfcg2GENTHnOCo9F5jMGU9LHrye1qinI8oK4MtE5GLg7LC8GzY0yOM3IvJT4LUi8glMvXBKRtkfAqcCX1XV56OVqhrdgGnsDXwS+Jaq3iciKwNnZpTt9DimAhcBywfjyTuBj+WUPwO4QUTOC8s7AKcXtKnKeep0H2diPc13Y0OnD2MjjCxOBHbH1C0bAnsBq2eUvRk4X1VnJv8QkX1Tyj8jIqto0P+q6j+CDv987EHIYrqI/CG0CWykND28sJ5OqxCEzpaYAP4TsB1wDXYO40zGht+RcIjriJWU4XNMj3hvaMcfib2ctV2/vimmOzwjLP8O670DfFNVL6edPbB78LzQjqvCulwS+vJx2DX8v5RykU53ArC3iNwbjqFI51/q/lDV8UVtTWlTpD4R4Ksi8gLwUqxNaUL7XOAUEfmsqj4btrMo8H1y1KRUfy5+gF2LpUTkW8DOQJZ8KkXpSLhwUaMs61ep6nl55UOddwHbYifvYs3R6Yae5gqqemepBnVe54PA5mGx8DhE5HXAxtgxXK+qjxeU3wDYNLb9WSXaVPo8dbIPEZmlquuJyFxVXSf0DK5W1Y0zyt+kqhtG5ePbSCm7BvBE2nkRkaUSvVZEZArWW7o7sX4BYFdVTfUSCAaQnWjpxq8FztGcGzgImCnYkHGKiCwF/EJV35VVpyxBuGeh2m7AugxTld0Wa9vHgEWwjsd7EuXHY0blD3fQtmmxxZeB+4FTtN1YuWLedlT1gYztl7o/xIzYL6nqS2F5DcxGc38Z+VEWEZkAfBPYF3gAe46WB04DDo32n1Kv0nMR6qwJbBMWL1fVPIFdTK/0I918MBXCncB9YXld4IJe1wnllgp1twfeUKL8jsBxmGHngyXKjweWwVQbK2AviF6fr0r7AG4I31cBawNLAvfmlL8KG1qeARwDfI6Sui7gNQX/bzyK91V03DOBSdiDeUdKuRWBybHlrbDe0+eABQv2sUvJdTcmls+N/b42Y9vXFO2/R+dpFWCh8HtL4EDgtd3eH6HcauH3qsCT2Gj3MnJ00qH8BxPX5LXADgV1JgJvDZ+JFe6PUs9FKLt+OD8HAOt3fe4LdvYM8O+UzzPAvzuo+yDWhX9TouxMbBg4K7Yu19iQUSfXmADsir0hTw83z33AzjnlT8IMd3uHz0XAj3LKHwA8DtwKzAXmkWEEiJ2f5HnKPbdV9hGrsy+wOLAFNmR+DPhkTvkVw808CRsCHwesWrCPd2BeD38Py1OAk1LKxQ0zfy19o9qL8C5M31r2HjwpPLifDHVnYd41yXIzgGXC73XD+f18uE9OLdhHm3EpY91dOdu4O2P9GcCNwKHEDJwF7fkANjp4MnwuATYN/03OqDMbU0OsCvwN0+n/qdv7g9gzDBwZPTuY8C56vmenrJuVU35prBd8bvh8lQLjaMZzsX9O+W+E5+0w4HBgDvD1svdw6ja7qVxwcEcC+2NW+knAfsB3ML3r9ETZ65MnmGKh0kmdOcR6vcDryfdquIOgpgnL44Dbc8pXsoh3eF77vo8O2zUDG/bFr0fbC5EOPQ7Ccb+5i/atBKyT8d/c2O/vAcfErnfWC3Q7rDf3KKYbjD4/J/SsEuUvBN6bsn574I8Z+5ia9sk5xk8BN2FuUpPCZ2vM1XK3rHudlnX/S5T0KCp5zuPn9VpiPdi85y5ZN7YuVWgHAfpgEIrvD59IQK4MnJkofxumu12l4vHcCSwcW54I3NnNOerntPTvV9UpseWTRWS2qv6PiHw1UfZWEfkQMD74Ax+I3TR5dFJnnI7Ugz1BfjTg3dgQP9KFLR/WZVHJIg4gIscCp2nQDZagk318I229JvSUsfL3keKRoKq5vpyq+qCpaueT5r/ZqcfBo1pR3xb0/Zer6r9U9X4Rea2I7KCq5yeLxn5vDXwltOXVxPHEeQQTdu/HRmMRz2BD8iSfA/4oFhwQGfk2wEYOqf61Ws1jAuwZeGfiHF4uIu8DHspoF7Q8ivaihEdRhftjroh8D3MrXRXrjSMiry0+FG4SkeOAH4XlzzDyPMf5LiZvZsXWXRAM1XOwUXecPTAj4iUi8gRmlP+VjvSQSuMRzFsiMmguhB1bx/RTAD8n5nQfRafsTKvhyYt3APA1zAJ7NubfeWTB9jupc1GKF0Sem8tiwO1igSGK+a3eJOZEj6q+P1G+lEU8we2YBXcCFohxtuZHAnayj2djvxfGHvg8YbZhovwutCz2WTwoIu8ANBgzDsrYx2QqehwEbhKRX2PeEvHjzrNyT9WYsUdVnw7Gs/MT5S4Xkd8A/8CGpJcDiMjSjHT5azVUdQ4wR0TO0gwjT6L83WLulh+m5e1xFaYKGuGh0KHHRLSftheYqj4hIg+o6k8yqlX1KCp7f3wCuw9WArZV1efC+rWwkUYeB2Cql19j98VfMCGcxqKaYohW1dki8ih2fPH1czDB/JXgUrcbMENE7gHOUtUsL6R/YR2/v4Q2vQvzSPpB2O6BBcfURt/yAYvImzBDxiZYY6/H3sAPAxuo6jV92XFxu3ak5UFwteZYY0Vki7xtqeqVifJTM8oV9mSChXhv7O18LWa1viKlXMf7iG1jIczbYssKdWaq6gY5/y+JXe//wnq3FwMHqeoTZfdRsP9pKatVs302iVvpY+vmqepbE+sEewiXBn6jqg+H9ethKquLc/axGnA07b7GqS+S4L7262gfGWUqeUzE6s3AJoqck1g/BThZVd+etc9uybs/RGQDTbgpisj2mgjpj/03HrhUVbcque/bgXeo6lOJ9UtgBs43l9jGlsDxwFqqulBGmY/mbUNVi9xB2+hbD1hV76U1nElyDYCIXEiO831KDxMROUFVD86qm1YnwbWYX6FSECaMhZP+Inlhc9p7eGjjomG5LQ9CGuGGWzN8HsfezoeIyP6qunvaPrrkNcByOe2JhwNHfqS594qaG1qhy1RwfXo66uWLBWLsgLlK/UgzciSo6t5p6wsoNYxV64X8KmV9W68qhWmYbvZ4zHtib/LVWothQ98nsd7dbzXhqgdMSqik7ooEmIgcnbPtz2ND72m0jnNDLFjpI8nCIvIbVd1VMnI8JF9esXpV749TRGQvVb0l1N8DOJj2kP5ov6+IyKsiMrlgNBhxPHZOv8BI9c53wn+piMhGWIdnJ8wg/1NafuZpPInp67sKvhjRhj72gAujTKr2MEOdDVR1ZlbdtDqxurti+qLp2BB4M+CLmkjiESv/TUxXdDPwM6zXmHnCxKKuzqQ1HHsc2EtVb82pczymErgc0wXfEPvvTlVdI/wej1ltlwP+rKrXxcp9XVW/mbOP+AM2HjM+HqGqJ2aUj/e8Iz/S72mOv3VsxLNx2Ndfgc+FF3G83AzMne8REVkXC4Q5GnvZvaSq+ybKf0lVjxGRH5IuJDKHfWJBGodivXKwYew3NTjrp5TfEXto34DdH3nO/1Gdmaq6QbxnXTRaCGXWwXrdO2FJpf4r9t9dqrpaRr27VXXVnO0uhb1oIjXHbdiL7Z8pZZdWC4RZMW1bmu0HXOn+CPfG74APYc/cXsD2ecJVRH4PrIdds3jOjNTrLSLbY0bE6LhvBb6rqhemlD0KO/dPYi/eX6vqQ1ltidX7BTaiPwf4mareUVSnEO3S0pn1wd4kRwL3YG/gS4Dv93D7B5VZl/i/khdEKCNYpMyvMAPcUWRYTzEj4Fax5S2B6wq2vzewSMZ/k2O/T8WSDR2M9W6Oi/2XG2ePuQ1Fn2WBCX243tcDe2I9oQlYj2tGSrlKHgdYWDrhHmr79PgYKntahGs+DnN9+izmv1poGQfeiOk5r00eNx14TKSUnYhl7uvpde7i3K6OvQwuopyPbt+uN+ZOtlqHdSdh3l3XY52M/YjlZqm8vT6e8Fnhe274XoDgOhYrMw/zZU1+5pUQjGm+lrMK6sxLLI9LrsuoNwXL4HUH8GPMn/SYlHJpzuhFx3FZyXVxwTUBywB3LmaJLTru/8Is5AdiurK8suthuQduDp+TCT6e5AjuDOGZdj7ivqE3A+/O20bsv1IBD2H9CeH7Qixr3IhPzj5SAyIKztdGwKLYyGRauCaZwSbAp7ER2K2YP+laKWVWxVyepmFC+gDMve1vwOol2lQpSIkKPtZV7g/an+9/hnbNzbvWsfoLYgESawML5JT7ISNdAUd8cup9hljACWaA/XSJdr0O6wjdD/w5nLsDqt47qv11Q4ssw0+Hofk/saFdnDT3myiM8CtpGw36ow9haQgviP21GDakyKOUF4RYTPmJInIQNlx6HOuBflFVXxKRcdhJ/1Ki6r0icigtC/JHMK+FtONYGNPFLikjXbEmYb3UJAtGP9SSjuwn5l52OSYA0vaxPJbW7xlaOsGdROR5zGF/T1U9NVZ+J2wIfhQW4QSm3/udiHwKc3SPwjCT/FlEvoyNFJRwboMhBG1Z5yt7HAS+Qrt+Lm0dtM5/kaU9SWVPC22l0vwPCWt7BssDB6vq7JxtlvaYyOAwzGNnetje7ODZkMUx2Egj182vg/uj4/SmwSh2OibkBMvH8lFVvSql+E0d7uYTqhrZB1DVp8TysZyUaMuOqnquiLwfu8arYkEyb1PVx8RCrm/DXgTV6ERql+wZRFEmm1MuymQ9TD97P5bz9bMZ5VbEhvZ/xRywo8/6lBhaYzq348InNbSYlmP64cCKGWXahqrheH+A9QxmYr3mxTPqH4Qp/l8I5+e+8JmTduxYr+M9Gef5pYx9XIDl202u3ytqY2L9XGCllPIrYS6ER+Wc1/tyPvfGygmmV/8csGzi+r87ZbuVAh5i9cZjyf2r3LPTUj4/yyi7JGZ8OxB7Af4YuAV74RVFDZYKZ8Ui35atcgyhXqUgJUr2/Du9PzC7QDyF6iTg7QX7mklMhYKpMGaWbOeimGtaUbl5jAy0Gg/cmlIukgenA5tnbGubqtdJtb8qiJWL1oWTOhUb2l8TbsgH+tWmCm2vmrt0YWyGh+T6NxCLnMmoW3rogqlMclUIifJ/y/nvIRK5MIDbcsp3FfHTxbWYgun/HmCkPnBHMl5usbp9y6WA2TSOCi+H27C81Gtivq/Tc+odGh78wykIZw3Pxq1YYvLPEsuHXNC207BR4lxgtdDGn+SU/z7mkbFHOK87kpKHu9P7A1PZJSNKi+wWaSqtokjXtcO+HsBmDpkJvCWn/HeB32C99m3C72NTylWSB1U+/fSCuFlV10+sG2EdFpFXsZtrHw3ZsUTkXs2JuBKRa1R1UxmZ9R/KWaxLWblF5GXgufYtZJY/GbhIE0NVsUisbVX1Uylt2Qh4UIN1WkT2wnrnDwCHaUZEmGRkJcsom2pNDyqUO5P/icgcbCj698T6FYELNWdKIhGZiT34Z2nKtFAp5St5HIjIAloi4CFR5wwsZ+0FZMw+EcpV9rQQkTlqGdYE6zSsEPtvtqqum9GmO4EpGlQJYhn9Zmvwdsmok+kxkVH+NViQ0rZh1cWY90eq+kJK+lh3en+knQ9J8dFO/P8zLNduPBfy+GSbEnWuA76mwX8+qDGOUtV3ZJQfhxnR4l4yp6rqK4lyz5EeARvds5nHUUTPdcBi6dreAkyWkXlJJxFzRwvsiA1HrxCRizD9YWbsJ4Cqbhq+O5lWpJSuCzMUlRJygQ1Udb/kSlU9L7iypfFTwoUXkc2Bb2MjgHUxw8bOGfUuC7q4c7X47fkHsWltDtZWntRFMN/ItAjAqcClwU0n7kf6ZeB/Cva1G6Yfu0lEbsKG75fktLHstYhYKfjAlgp4CNwTPuNoTUOT1p7I57aKLvGVsH8VkWQqzjw/0U7CWR/DbChP0G5HaUMt4uxr4VOIlvex7vT+uFdEDsTUNGCGyFTbSIxPYUay6OV3NQndbAqLaCx4SVWnS84EB2r+vD8BfhJsFcslhW/gPrJjGrqj111qzLgzDbtZ4rq0H5AxfMYifD6EWa2fxS7Uthlll8j7FLStrK5rVsVjzkvQk/ofMQ8BLFDgsNjy7JztPYM94C9RbLFeADNEPY49MDOB/w3rUofm2JD/jFj5M7AeW9lzMQ7Lj/AwNgw8PO26lL0WsfLXYMPEuZgd4DDMlzmvTtlUkT+P/f5oyfY8jfWsL4z9jpafSikfWerPD+fm5+G5eIhYaspEnUKPiYx6f6Hdut829RbwpUTbCr0HOrk/sJfGr7AXyaOYO2VqKthQ9gQsSONoLCil7D1yHqbiWSl8vo7NqZdVfjrWMVwCE7IzgONTys2qcq9W+fRTBbGJqv61g3qLY7Hlu6lqm8VdWolA0nrKqik9olhPfAvM//J8cqzcIvJVVT2qQpuvxDwkbkis3wjTKW2eUucWYF1VfVlE7sBCSK+K/lPVtcvuv6Bt47Ak5k+HVfdoKyY/q84uqvrbonUp9dbBesH/jQ17f4mFfe+p7UPQ71PiWsTKVw54yFCD5a5L+z9j21vk/a/tYeofzS/eNk1SFPX2a83xmMho2yxtT46etm57Vf1DVtu0ILRWRBbRjKCWTgkj4ZmY18f2mDGtVA89yI7DiaUawDo2T2WUn6WWkH1fbHqrqWmqERE5UVU/2+Eh5dJPN7S7xbKerUTBtNJxwsk6OXzS/s9zp8kiPnx4jpZuDEyYj3joI+ErIclGgn9hkwD+Prbui9jUQj9n5NBsL0zFksbZwJVh+Po8drMgNstzbvhlcIeJhPp0zYipD8fyqoj8IPnwFVDa5UtELlHVbYMO+GlMD/xlVY2E6gwRaZsJG+t5FF6LGC+El8ldIvJZrBeZ5X63HfYSWDZxDSeRPnddJ3xDVbcRke+oapF6JlOYibkKpt4jqvoVEVk/DN8VGzXcnFY2wasisoIGXW3Q0ab1tHYG/qCqpwcXr1K5DERkE+w6LwqsIJZrYn9V/XRG+dWxUe1Sqrp2eFG/X9OjN5dW1Uh1crGIlDleYL7sOFBEFrPFwlQAE8TcH3clR10TCV+xKMOjsNzR24nIWsAmqnpa2Ta2NaDTiiX4PeWnlS6NiKypqnfIyHj0+aTdoKq6t1go73dU9QsVdrcwZtmOz0N2HzbZ4FaqenDY/g0i8nZsyPixUPZWzNVmxDQwMc7CZgZYmpG60nGYLjgVEfk25vwfTd1zkIi8U1VT/aYDpfTGHQquJcP3LpoIO45Q1R1T1lXN7XAQ5jd9IBZhuRXmDZFG1VSRy4XjldjveFvTwl+XFsv+9n4RabNd5AlKsckcd8G8DpahPV1iVO5QTDhEL6VpIvLbDMEV52vANWFkFoXct9kosPDviIMonlsw4gQsOvQCsOxiwY6RxSlYJ+WnofxcETkL8xtuQ0b6xY+PL2vOBKki8lZMJbJEWH4cUyndklHlCGykdo2q3igWMn1XznH8HFMbRcL6b5j3SMcCuJ8qiNnJYWePtnuyqu4nI+PRI1RVt86p+1dV3aTCvq7H8qu+EpYnYC+VTTFD3VoVmx/fdjSkvixN1ZJTby6mung1LI/HdFR5FuVnMD37K1hvO8ubYwpmBDwCC9eMeAa4Im0oJzaRY+ZLLUW903Fuh1D/NUUqlFjZSdj8c9H1G49NvfNcolyeeiC19yqW13cf7F5IGu/a7sPQK9sRs3WsjgnV3VQ1LylSZY+JWN0lMf9byJjLsBPVSyg7Q1XfHldrSPAKySh/o6pulCifKh9E5H7MxlFaxRirW8kLoipVjqMs/ewBV5lWujTa8jbYTtvzqCa9LJLMFoue+y0j3ZKyhr2LY8OsSCWwCGZQekVsttZov6nZpMh3UxkXVDSrS2uG3flofn7f19KK+pucUy7aVimPEa2Y4za2/+3JeGBoVyl04nFQedgbuATzNImGohPDuhEPZNmhd6LO77AIsENVtSgPNZgB6gbMMHSNqqqYm2Ie3SQAfyXsc2FgLRFB26PIOun5Q/nczxGPi8gqMH86952xSMg2VHWl/MPKpZQXRBedgGfFJumNjmNjKk6OkKSfAvggbFrpF2mFJbf1urrgOiyiqGhdnIUx74x47yRP73gMJrSnYzfp5sBR4aLGp7PvJORydywN4wRaLlJlOBqYFUYAUZu+nFdBRATzo1xZVY8MeselNWE0jPFuETkS8zaYQL6P7gNaoNdP0JHekerDXrAgmPl6QFX9j5iP7Aiks7So0X32xzR1WIoK4ivYNT8JOFss5DmVmGD4FykJwLPqxerviz1/y2HzvW2MRY4mR4dfjP2u8kL8JBa8sSz2QriE7GTphP9OBtYUkYcxNV6Z1KXL0roHAdJeInHKpgKIXhZVQ5gPwe6/VUTkWiyZV5a7aCn6poLoFyLyRuzC/4KRF3ESFu2zZo/3tzQWVw82s+0jPd7+dqr65w7atFFYvEFTUg0myv8YG9ZtrapvDjq1S1R1o4zyd2PD5Xl5OuNQdv5wrGTbR2XYG/6/Fos0vDksbwCcmFRDSWdpUdNUYLEq6aqwoGfcHdP/rob51p6nqn+LlansMZHYxzzs/rheVdcV880/Kk0Xn6hXWr3TCaHjMk5VnylRNpo/8jZaNiRNexnG6sS9IBRTFx6epjrrlKCGXAPrlNxZYaSYSj97wJWs9RV4N2boWo6RyVaewWZCzWvPcpjPY2SVvxpLYflQolxSKDwYvt8oIm9M9m6kPSpv/l8U9/qvE0saHp2nKzH/1hFDG2k3PkZtXkZElknpccV5u6quLyKzYH7SkQVzyj+ITahZ5u28Z4kyvaDqsBcsY9VvReQR7Fq8EXuoR5AmYIvQkrM1pNS7F7OkHyWWpGoPLChm1ViZyh4TCf5PVf9PRBCRhcJ9kxdpV9Wroax3EGG/+2HGbLApvk6Ov3Ay2AHLBfFCQblI9fhJ7BzOAz6fJxhlZBKvNpJCXkYGlMVZPah2MpM1FdE3ASydWevLsCTmpB0Jc8WCC65R1fsK6k7DvA92CcsfCevelSh3bPheGHMnm4M9wOtgw5YRPaiyOtYMfoYlcdk1LO8Z2pS86IdgN/KxtKO0Dy/jvBQMUJHu6vXkR2t9CctkdiUF885pa5aDsqHFneodqw57UbNsr4n1WKCgxyIVpxeK1Vs7pU5RL3USpuM9lvRrGpUr5TGR4CGxiS/PB/4iIk/Rmlg2jROopt4p5R0UBPu5mPfDydg1Xw+b03BHVb0+Zx/3YoFEhQIY8954CetQbYeFnx+cU34TrJNxNhZ8kRt9S34UXJ4Ks5B+ekFUttaX3O7UlNVLYDfQYaraNrVMrG6bxTLPiiki52ITO84Ly2uHfeTqfUTkDYx8GP+eU7Z0m8T8YDdR1Wvz9p9S78NYz2997GbdGThUVX+TUf4SzHA1j5ig1pzpkILaokxKw8oeB50S9L2HYBntPhEE7BpZIzERuYbW9ELvI0wvpKrfSCsf6kzFsvOthfVkt8M6A6n3iIjsjw2T/4/WqEnjQl468JjIad8WmKH0Is2Y7qmqekdKegeJyJ8x18/pKW36sqpul9Puc7Cou8sY2QlIy8sRD86ZgKnlMlVbQRa9C3uprQP8EZsMN3Pmmn7RVxUEFa31ZcgSAmKx3JeSMrdXjCdE5CO08gHvgRnlslgjEr5h37eISOYEf0HlcizWU3kMMyDcTiunaxrPi8imGiYpFQtaeD6toFpQxYlYL6I0qvpLsUCJbbC3/Q4FgnIZrR6JV2ra+EjASka0XbK8ZFiqY9vLc1ubhvkBRyOWh7FeW5YqbKKqXiYiojYdz2HhvGUKYOxlNgXrXOwt5qz/i5zyXwDW1hS3sBideExEz0CS6P5dlOx82VXVO6W8g7CZY6YnK6vqlWIJrPKIQrvLMH9UoxZZmls4vDguwvKDL4TJgekicrhmTNMVISLvpX2atSNKtrONfgrgo6hore8GVX1Sis48fBzTAR8flq8lP4n2XBE5lZEZmebmlD8SszhfqhbiuBUpkyEm+BRwuohMxs7Tk2QHGEC1ZDwAiMiZqronlvYzuS6NP4nItqp6SZntB6omMy8bbRe3VB+O9VDLsoqq7iaWxB9Vfa7gHikdbRfj+fBifDmoFR7Dkq5ncQ/pmfbilPaYSDCTnDB9IEuVUlW9U9Y7KM/YlhvCHB8JiRnXllfVrGdvioj8OyoOTAzLmTaYIHjfiwnflbD8F7nqHRH5CRYMtBU2QcPOlPBKyd1mP1QQ4SbeGRuWlLbWd7nPrbBhdZ4utOo2F8YEZKQPuwr4sWan9btJVTcUS9u3Xngwcy31sbqTAFT13wXlSgVVJOqM8DYIQ7DMQJLYPl7Aehdl9jEtZbVqe0rDKNpuVyyKKGISlmzmbWQg1T0ursN6/deqGSFXwYaaqfsQy91xOzZyOxIbtR2Tp6sUkZMw4+/u2KzE/8GCJVJf7GJT3U/DdI9FQ+tCj4lBISW8g0TkMdJHpALsqqpL5Wx/OhbJOAF7sTyGXcc2n/mqiKUpXRtTGf1KsyPlkvXmquo6se9FsQlyN+u4LX3UAd+kqhv2YbtpQQ9LYAaNvTRnplIpOXNvF227FLPeHo0ZCx8DNtKcSJzQ851KgRdEh+35CiYcJtLqdQk29c8pqtq3EUlOmypH28XqlnZbC+XfhQ3j18J6de/EZgiZXr3lpfa3Epa9K3OUJCI3YJndkvr1osQ3kcfEbpozK3Ks/I7E3LFU9fycsqW9GmJ1FsdeCvGh+FWJMh3r+6VkopxOEMtDHvXA47Ikt6MR05Vfj+non8S8hQqvR2Zb+iiAv42lQfw1I6POMmO5S253xcQqBZ7QElmZwon7ES0d8O6Yn+jbE+WyIttsh9mJpxfBeqXjMHXFZGxanEw9czA23EIrDn9PLPw01fUlDKGrBFUgIkdrBe+ToIeerarPBp35+thEl23GROkwqkg6S7BeSQCHOq/DXrhCRkhurOwVpB9D26hKMnKRxOqkugVW6cVH91MYSa2OeR5kGtNi9U7CXLLicx/eo6qpaoWgj03zangdNp3UwYnyqYEePR59zsMSNZ2OhRff2CsB3EWbDsVUmFtjcgQsgfuhHW+zjwI4zSVMtcClp5+kXcA0FUGKkB9BMNAktz0e0/1W8g+V6p4ZlYIqQp19NJaxKbT165pt0JyLGZbWwRKQnIoNGdsCFqTDlIYisj02zM+NtpORPtavYWRPPku/16lwjKe2XBgTRC+ranLy1UhYR2zAyKQ/miWMxJKZ34/lDY6rINo6JmIGwM0wo9e1wI3AC6qaa1cQS2/65shGEFSCt6pqqgFZKuY8kZKBHtJBhGGs7i5Ybt9rVPXTYfT6XVXdKe/Y+4Gkz17zEcymclg3ncp+zIixo6qeq6ori8gS3fZ4e9SmyDqcOnNvsnyGgF0S62mn3lBqFuBXRWRyRfVBaS+IQNWgCoBtxAx3+2C9mmmYqiOLl1VVReQDWOTYaSKyT0bZbkKLC6PttDMf60y/WnJ8plV1ZmLVtUFlkFZ2/os29GrLvnj3CN/xEUmWgUzUDIf7ACeFkcacEvu4G1iBlu/v8qRPqRNR1qshomygRxQotSMWBBMZs/fAErNnouYh89vY8r3YC3EQdDp7TSH98IL4Oi3H5EvJz80wWiStw/vH/lNGPgyIJdn4NqbjORKLLV8SS6Czl6pelLGf/wDzxGL342qXPFepql4QVYMqUNUPichumN7xWeBDmu9L/EzQH38E2Dz0oBbIKNtpSsMq0XaVqDoKiZCRblzjsJ5tGffJ0seg1fJZi1gww4exl2fUriIWwyLObghtexvmpRIFWiR7nmW9GiJKBXpoiDAUkWN1pD3oQrFpq9oQmxZ+uqreFdRtp2EC7n4steSs4sPvOeNjHcndgJNV9RzgHBGZ3c2G+yGAJeP3wKh40wOciBmvJgOXY5nXrg9DrbMxH8I0zqViVIzabAdTJHhBYAJyd7Ld3SJ3mTeIyLcIQRV5+xALQDgIOAeLEtoz9Nqy3KF2w4IA9lHVf4rICtgMsr2kdLRdVSK9dPg9wt9YRI5S1ayQ9XgP+GVMD5rV8++0bQsw0rNmOvDTDH34wVjn4DxVvTUMw/NyUETk+S23EUY4f6Ll1fBVbXk1fDGlfOSTfFhQxUwm+5kAWERE3hR6sYjIylgvO42DMLUXWE95CrAy5vv+A0wlM9qMF5EJqvoy5lUTz63clQztuQ446J/2wN7Uv8Ae5PmCOEv/NlqIOZyvxMgMS2ckyszXwYrI7XHdWZERRSxn6wqqemdBOyZhvpbLYsnrLw3Ln8em3/5ATt01aQVVXKbF0Wd3AJ/REGSARYd9XFXzAkSiurmqF2m5GgkmuEe4HWX1/qWDaLuySE7Cn+RyF/uIjI5Vj/tUbDQRN7q+oqr7dtumxH5WBFZT1UvDPTlBc5LgSAmvhlBuPKZPLp30SkTegw3V78XO14rYFFxtfuaJZ+8sYIaqfj8s9+TaVUVEvoa5Tj6OqXbWDyq6VYHTVTVtxpdS9KMH/A8g6sX8M/YbinMW9BURORNYBbPczs+whGXRjxMf0if1sZlvLBF5H2HCS2BlEVkXcylLMzacCTyFucJ9AsuyL8AHNWcOMKkeVAHwNg3+xUGQHhsMJMltd6J66TSlYSfRdmXJG4WljsrE/Fo/g7msgR3LTzXbg+WmjN9FbKQjjb6XZ+l1RWRDbCS2EiM7DLmeAGEYvx/mnrkK5q3wE+ylnVa+bPrKyNZxp8SmPCpCVS8Ko7BIaN+h2Ul2Xg3X4qnQ3m/F/ptYZn+9RlW/JSKVZ68pu/G+fLBcrIXrRvODOdlLiXKv0Jpx+OXwO1p+KafeTGw4Niu27paMsvNiv8cTkmeXaNvNieXxwG0ZZb8U+71L4r+jUsrfhLn+7II9ABuH9WtSMDNscvtZ62L/HUPGzNc9uM43p/1OWw7rtsB00kdgzv/vx6Lu5mDD3zN7eNw3YxF60fKb0toU/rsztGVlrNe4IpbXouj4Z2OdgPh9OC+n/Dys5zs7dr1TZ2oO/18VnoXLaIUMX5BTfgFsKqnfhc9ngQUyym6PReP9E/NVj1+jP/bjfhnkp38bTr/RU2+0UTtYs6ou3cftXx++Z8XWzS1zforODaYLTHshPAF8u2gfJQXR7Njv2xP/zSpoX6XrHdr+KjbCiI7l3z26DpVeoFg46Xop69cN9U7v4XFvA/wd0/1eiRmXtsooe02Hxz8jfs2w3nPqfRj+vzG6/tiUTWBqhqzyW6R9csqfiqlctg6faZj/bFb5TbGRAtiI5BBMBbBoL+6POn364YYWJUyfKBZ2GQ35JmF+nKNOzB9xMeC2YB2OG34y/RErcquIfAhT2q+GvfWvyyhbKX5dVY8GjpZqQRVVh+KVVS/S4QzE2l0Kz1xUdXzFKotqinVdVWeLyKOk5Avp4rgvC/dGPEVm1nB8atAZJzOCFRl6rxSb7mqiWDTgpzG/4ywqpa/U6vmTq6hdpmIZ5SYEb6K3Y4bHL2OGuG+l1Wsq/dABxxOmx/W/hQnT+8j3iov0hAMwXe4LWN7hi8mY+bUDIRExwp9T8oMqNON32jK0XgrxFwJhOWu+vaozEEftLh1tNwqIiCyuiTDo4Jb2soaUqgk6Pe4FMDfI+V4QIpLlBbE3pg5YgNbLUSn2tPkfYF9MtbA/5ut+alZhrejVEGwFP8Q8ahbE1GDPJjsNMV4RkVVU9Z5Q/01kz5S+MzbyWAhTQyynqv8Wke9h+TPGlADuW9ca2GnQ3fvR/mDW0X7v4yzsgVoaSyhyI/C9jLId6bI7bFeqTi+n/FxMsE8BZmEGsCsHdN32C+dxC2yUtBiW43cGZq3v5XGXHo5jveOqxzIeM3L1pXyocxMW6jwr1N8bODqnfBW1y6y032F59iDuj77ee33bsGWUOi5crJuw6KTJAz3YoGdMfB7E/Grf1IPtX4EZ+o7Ecr726zh2w1xiHsBCSAd/I5nxZBbmQVGo0yXoSTGf1X3i6wbY/qswnfoT4ff7+nDcc8qsC+unYRniqh7L7zFXyH6Vvyl8z42tm1VQZyEsaGcdgp45o9wM4DXh97jY+smDvD/69elnPuDTKDfVzmhyAjaX2llY72t3zE3nZmxqoC272biqbhV04LsCPw2+vr9W1VQ1RCd0EFQxWpxAyYk8A1Wi7fqOWj6LSzUj1WgOJ1DtuKsMxzfGItTuw9RakX2gKCHN4pg94gZGRmRm2Tqqln9OLPx9jogcg7meZkboVVS7bK5BJ64jVT8LkB8h2kj6mYxntlZIMjMaSHrindlqCUVK5e2tsK+3YtFeu6lqUa6GKtvtOKiinwTd4Taari9NK/9GLEjnRlW9OkTbbakFc6n1E7FplR7FEtFcjXkh5Ob16OC4t8YiveJBCXur6hUpZVdM24am5CpJ1Nsio16q8ayD8iti52lBTN89CcuTnZpvYrSCT5pIP3vAVZPMjAbPiciumC8imMI/6vF0/SYSm65oNyxpyBPAb7DItl5SKqhiAFQKLVbLLHUczI+2e3CQwje0adXwItgMmy3hRyLydEGnofRxB4PpFCzirNALIilog6fCZygwRGUJzm7LiyVnWk5VfxSWr8QmYVUscCMr4U9pL4hho0xij075JHYD3y8i92P5FfbPr9J3Poy9fR/D3uB7Ah8JoZqf7cH2p2HDyU8D71HVk1T1sR5sFxH5EtiMGdI+d9rHerGPLvkWlipyYVqGrDZXMxHZWESmi8i5IrKeiNyCqaoeDSGrA0NElsOStm+GuTzdyshZO9Ioddwwfy6yPVT1BVWdGz5twldElheRk0XkDyKyr4gsIiLHAn/DBF5W+6POzjMi8u/Y55mYR0tavY1F5EYR+Y+IvCgir2SU/xIj52lbCEtYtCWW3yKLV8RmI4n2l6d2GS76rWTGhieTwu+DB6307tMxTsAiux7H9Mk3A/8b1lWykufso1JQxQDOQWrEX0q5jqPtRuEYXsWMQB/o9XHHyh+PdUY2w1zv1ifhPYMZcw/DXDqPxwy7ZwNvLNj2ih0edymvBkLARmz5xNjv61PKH4wl+NkWMxhPD5/7sXzWA71n6/Dpmw44DRH5u6quMGo7bO23o1kbKmz/eKzX8zkNCU+CAe572IwGB3Wz/bC9WdqaMnz+77TlQRCMMZdqwUSe0kWio34jNl3SppixaAXgLsw17rScOqWOO1a+TddLIoF70h4hIg9hXgq5emYZmYToHC2ZvFxacxnOn7Ag7VqIyN2aMf2OiNyjqqsk1n0PeAdmLL4LM4BfAZyjKXPIDSP9npY+yaDSU0bZwqokTanC9sDqGnubqakKPoUlzelaAFM9qGK0+RTwBbEE3nkTeXaU6Gg0UNU5InIPNnPxZpiHxhaYR08WZY872kepXMVi2cmi5+UJYHIwuqLZkxzEn68qM8+U9WqYISKfUNVTEm3dn5TZgVX1C+H/BYENMWG8JfCVoFtPnRR2mBhtATyQB0xVLwzfpwOIyGu0t25bGhe+sZWviEivjrmTKLVRQ8uHFtf2OMSShC+EhY9fjblE5XoclD1uETmkYDtxo91kLLouLlCjNK5KtnDNe0nnsScmcD+DeTUsR/rsE58DzhcLt4/aswF2znbI2f5ETBU5OXwewaL0hp5+5IKIz+E14i8GlE5ufgNsdoHTsOlXVghDzv1V9dNdbvo2sXSNybzC0bxRXaOdhy6PClIytLjmx7Gdqv5vlQplj5uWYW4NbD61yJj1PhK9R1VdqWrDA3kvt7ZeeVWvBjWD8juCK13k9vhHVb08rTFik32+BQtOmYG92I7TnJmvh41R1QEPGhGZgbmeXRDTp96iXealFZFlsfj852nlBdgQe+F8UFUf7mb7TUAqTORZV8SmhZpKK2DgSiyfc6YvcNXjFpGrgPfGbAWLYUJs85Syl6nqNkXrOkVErgV2V9UHw/JsLDx6UWBat/sRkYuwfNK3YML3r/RpGqqmMtoqiIGjqg8GVVpE1+4wQcC+PdEz+JOqXtbtthtElYk868rPqB69WfW4lwLi08q/GNbNR0QWxqbsWTKhC56EZRrsFQtGwjdwTdAvPyk2H1xXqOp7gt76LZj+9/PA2iLyJDaN/dRu99F0hk0APyg2JZGKhUceRMtA1zVhKJY6HBsCahVa3CGrJDwHDpfiSRerHvcZwA0icl5Y3oH2iUz3x1y4lqGlawXLNXFiQXuqsHh8QVXjvvCv78UOQm/3FhF5Gpt1+V+Y0fpt2GhjqOlnIEYd+SStedgextLefWaQDRpD7IZFgu2jFuW2HL2fyLPfPC8im0YLUi56s9Jxq+q3MD/bp8Jnb1U9KlHm+2oTyX5BVVeOfaaoai8F8Ayx6YtGkOXVUBUROVBEfiUif8fUOdtjNpEdsemShp6h0gE7o4MUTORZV4JR9gxaU9E/hU2FnjVDdbJ+qeMOQn41VZ0mIq/HEsLfl1JuQazTUGYG5cqIyBuwJOwvkOLVoKqPdrn944BrgetU9R/dbGusMhQCWETypulWVT1y1BozxpCciTyBrIk8a00Iool8uQ9W1RNSynR03GIzPmwIrKGqq4vIMsBvNWVmXRm9GZTjtotbs7wanN4zLAI4LSHOIsA+wOtUddFRbtKYIfjOfhXrNZ6MuXJdLyJrAmcPMrKtF2RFb3Z63EGnvB4WPh554syPQAvLE1T15WREXPivp1n7nMEyFEY4VT02+h3cfg7C9HC/whLFO50zQUMYrogcoarXA6jqHQlvk6aSdRCdHveLwWtCQ900b4MbMH/iKrmDnQYyFAIYiOb3OgTLiHY6lgDFHcK7p7ahxT0i6xg6Pe7fiMhPgdcGA9jHgVMSZSIJ/gXgChG5NyyvRMoEoU5zGRYVxHcxy+vJwI9U9T8DbtKYQURewWZRiCIdoxBvARZW1dq7ohVFb6pqW0elm+MWm6l421D2YlX9S+L/h2hNaDsRy1AG1vt9XjNyLDvNY1gE8KuYpfdlRj5ouYlTHKefZHlNiMg/gB+Tof7Q9BmwnQYyFALYcQZNFa8JiaWVdMY2Q6MDdpwBcyItr4nLSXhNAHG3tTFhvXSK8R6w44wCUiERvYgsodk5f50xxLCFIjvOoCjtNeHCd3jwHrDjjAJjwVvE6T0ugB3HcQaEqyAcx3EGhAtgx3GcAeEC2HEcZ0C4AHYcxxkQLoAdx3EGxP8D0f/yMwbdA2AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking the null values \n",
    "sns.heatmap(df.isnull(), yticklabels=False, cbar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     1452 non-null   object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# going line by line or column by column and in both the dfs\n",
    "\n",
    "df[\"LotFrontage\"] = df[\"LotFrontage\"].fillna(df['LotFrontage'].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: MSZoning, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mszoning has null values here which are not in train df\n",
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping alley column coz its having many null values \n",
    "df.drop(['Alley'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going feature by feature and filling those categorical values with mode and the columns having more than 70 to 80% null values dropping it \n",
    "df['BsmtCond'] = df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual'] = df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])\n",
    "df['FireplaceQu'] = df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType'] = df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish'] = df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual'] = df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond'] = df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC', 'Fence', 'MiscFeature'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType'] = df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea'] = df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAE9CAYAAACLJ+A4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABDuUlEQVR4nO2dd9gdVbX/P98kQCgGUKqEJp2LNBEpKk29oBQLSBFERLGBUax4FRB/imK5KE1RQEEBQRSChl5FpQQSQo3GBGkKV4ogSkmyfn+sPXnnzJk5Z2byJjkm6/M885wzM3v27DNnZs3eq22ZGUEQBEEzRizoBgRBEPwnEsIzCIKgBSE8gyAIWhDCMwiCoAUhPIMgCFoQwjMIgqAFITyDIFjokXSmpMcl3V2xX5K+J2mapCmStuxXZwjPIAgWBX4M7Npj/27Aemk5DDitX4UhPIMgWOgxsxuBJ3sU2Qs425ybgeUkrdqrzlF1T/76PW6IUKQgCGpx06U7aG7r+M1iG9SWObvP/OOH8B5jxulmdnqD060GPJRbfzht+2vVAbWFZxAEwaCSBGUTYTnXhPBcCDnq8sMq9x2/a+f9lS9b3BcECxItNted1yY8AqyeWx+btlUSwnMhpIkQDIEZDCojlxw5P083Hjhc0vnA64B/mFnlkB1CeAZBMKCMGDV8PU9J5wE7AitIehg4BlgMwMy+D0wA3gpMA/4FHNKvzhCeQRAMJMM5bDez/fvsN+BjTeoM4RkEwUAynD3PeUEIzyAIBpL5bDBqTAjPIAgGkuh5BkEQtGDk4oMdABnCMwiCgUQjoucZBEHQGI2MnmcQBEFjRoyMnmcQBEFjYtgeBEHQgjAYBUEQtEAjQngGQRA0JobtQRAELQiDURAEQQui5xkEQdCC0HkGQRC0YORiITyDIAgaE8P2IAiCFsSwPQiCoAXR8wyCIGhBCM8gCIIWjBg1X2fPbEwIzyAIBpJwkg+CIGhBDNuDIAhaENb2IAiCFkTPMwiCoAUhPIMgCFoQ1vYgCIIWhM4zCIKgDYphexAEQWNC5xkEQdCCGLYHQRC0IHqeQRAELQhrezDfOerywyr3Hb/r6ZVli/uCYEESPc9gvtNECIbADAaW0HkGQRA0RwPuqjTYoj0IgkUWjRhRe+lbl7SrpKmSpkn6fMn+NSRdJ2mSpCmS3tqvzuh5BkEwkGiYDEaSRgKnAG8GHgZukzTezO7NFfsicIGZnSZpY2ACsFavekN4BkEwkAyjwWhrYJqZTQeQdD6wF5AXngaMSd+XBR7tV2kIzyAIBhKpvlZR0mFA3s3kdDPLrKGrAQ/l9j0MvK5QxbHAlZKOAJYG3tTvnCE8gyAYTBr0PJOgnBvXkf2BH5vZtyVtC5wjaRMzm111QAjPIAgGkmEMz3wEWD23PjZty3MosCuAmf1B0mhgBeDxqkrD2h4EwUCiEaq99OE2YD1Ja0taHNgPGF8o8yCwC4CkjYDRwP/1qjR6nkEQDCQaOTzWdjObKelw4ApgJHCmmd0j6ThgopmNBz4F/FDSJ3Hj0fvMzHrVG8IzCILBZBgjjMxsAu5+lN92dO77vcD2TeoM4RkEwUAy6BFGITyDIBhMIrY9CIKgOZFVKQiCoA0NnOQXBCE8gyAYSIbL2j6vCOEZBMFgEsP2IAiC5sQEcEEQBG0IV6UgCIIWRM8zCIKgOWEwCoIgaEO4KgVBELQgrO1BEATNaZJJfkEQwjMIgsEkep5BEAQtiJ5nEARBC8LaHgRB0ILoeQZBELQgdJ5BEAQtiJ5nEARBCyK2PQiCoAUR2x4EQdCCEWFtD4IgaE70PIMgCFoQOs8gCIIWhLU9CIKgBdHzDIIgaI5FeGYQBEELYtgeBEHQghCeQRAEzbHQeQZBELQgep5BEAQtiJ5nEARBc8LaHgRB0IYBH7YPduuCIFhkMY2ovfRD0q6SpkqaJunzFWXeLeleSfdIOrdfndHzDIJgMBkmnaekkcApwJuBh4HbJI03s3tzZdYDjgK2N7OnJK3Ur94QnkEQDCR1epQ12RqYZmbTASSdD+wF3Jsr80HgFDN7CsDMHu9XaQzbgyAYTEaMrL1IOkzSxNxyWK6m1YCHcusPp2151gfWl/Q7STdL2rVf86LnGQTBQNLESd7MTgdOn4vTjQLWA3YExgI3Snq1mT1ddUD0PIMgGEw0ov7Sm0eA1XPrY9O2PA8D483sJTObAfwRF6aVhPAMgmAgMVR76cNtwHqS1pa0OLAfML5Q5mK814mkFfBh/PRelcawPQiCgWS4DEZmNlPS4cAVwEjgTDO7R9JxwEQzG5/2vUXSvcAs4DNm9kSvekN4BkEwmAyjk7yZTQAmFLYdnftuwJFpqUUIzyAIBpLZMXtmEARBCyIxSBAEQXOG0Ul+nhDCMwiCgaSGFX2BEsIzCIKBJHqeQRAEbQidZxAEQXNmK6ztQRAEjYlhexAEQQvCYBQEQdCC6HkGQRC0IOZtD4IgaEEYjIIgCFoQOs8gCIIWhM4zCIKgBdHzDIIgaEH0PIP5zlGXH1a57/hdO+fIypct7guCBUn0PIP5ThMhGAIzGFRmD/gUayE8F0Ki5xksDFgIz2B+Ez3PYGEghu1BEAQtCOEZBEHQghCeQRAELQjhGQRB0ILZFgajIAiCxkTPMwiCoAUhPIMgCFpgFsIzCIKgMbOj5xkEQdCcMBgFQRC0IHSeQRAELQidZxAEQQui5xkEQdCC6HkGQRC0YPaCbkAfQngGQTCQDLq1fbBbFwTBIouZai/9kLSrpKmSpkn6fI9y75JkkrbqV2cIzyAIBhJDtZdeSBoJnALsBmwM7C9p45JyLwPGAbfUaV8IzyAIBpLZVn/pw9bANDObbmYvAucDe5WU+wrwDeD5Ou0L4RkEwUDSpOcp6TBJE3NLfiKv1YCHcusPp21zkLQlsLqZ/aZu+8JgFATBQNLEVcnMTgdaTcglaQTwHeB9TY4L4bkQErNnBgsDs4bPz/MRYPXc+ti0LeNlwCbA9ZIAVgHGS9rTzCZWVRrCcyEkZs8MFgaG0Un+NmA9SWvjQnM/4ICh89g/gBWydUnXA5/uJTghdJ5BEAwoZvWX3vXYTOBw4ArgPuACM7tH0nGS9mzbvuh5BkEwkAxnbLuZTQAmFLYdXVF2xzp1hvAMgmAgqeGCtEAJ4RkEwUAye3YkBgmCIGhMTMMRBEHQgn6GoAVNCM8gCAaSyOcZBEHQgjAYBUEQtCCG7UEQBC0YxvDMeUIIzyAIBpLoeQbznUgMEiwMhPAM5juRGCRYGJgdw/YgCILmRM8zCIKgBbMGfO7hEJ4LIaHzDBYGwkk+mO+EzjNYGIhhexAEQQsiwigIgqAF0fMMgiBoQQjPYIFQ12hULBc60GBQCGt7sECoKwRDWAaDyuwQnkEQBM2JYXsQBEELQngGQRC0IFyVgiAIWmCNup7zPxophGcQBAPJrFkLugW9CeEZBMFAEjrPIAiCFoTOMwiCoAXR8wyCIGiBNep6hsEoCIIAiPDMIAiCVswecKVnCM8gCAaS0HkGQRC0IIRnEARBC2YPuPQcsaAbEARBUIbNrr/0Q9KukqZKmibp8yX7j5R0r6Qpkq6RtGa/OkN4BkEwkMyaZbWXXkgaCZwC7AZsDOwvaeNCsUnAVma2KfAL4IR+7QvhGQTBQGJmtZc+bA1MM7PpZvYicD6wV+Fc15nZv9LqzcDYfpWG8AyCYCCZbfUXSYdJmphb8vPLrAY8lFt/OG2r4lDgsn7tC4PRQkjd+YuKZWNKjmCQaBJhZGanA3N9A0s6ENgK2KFf2RCeCyFNhGAIzGBQGUZj+yPA6rn1sWlbB5LeBPwPsIOZvdCv0hCeQRAMJMMYYXQbsJ6ktXGhuR9wQL6ApC2AHwC7mtnjdSoN4RkEwUAyu48VvS5mNlPS4cAVwEjgTDO7R9JxwEQzGw98E1gGuFASwINmtmevekN4BkEwkAynk7yZTQAmFLYdnfv+pqZ1hvAMgmAgaTaH0fwnhGcQBANJZFUKgiBowYB3PEN4BkEwmMwa8GzIITyDIBhImk3DMf8J4RkEwUASwjMIgqAFAy47Q3gGQTCYRM8zCIKgBeHnGQRB0IKwtgdBELQghu1BEAQtCOEZBEHQgkGfPTOEZxAEA0n0PIMgCFoQ1vYgCIIWzJoZ1vYgCILGRM8zCIKgBTY7ep5BEASNiWTIQRAELYhhexAEQQtmh8EoCIKgObMthGcQBEFjwkk+CIKgBSE8gyAIWhAGoyAIghbMDj/PIAiC5syeNWtBN6EnITyDIBhIQucZBEHQghCeQRAELQg/zyAIghZEzzMIgqAFkVUpCIKgBWFtD4IgaEGkpAuCIGjBoA/bRyzoBgRBEJRhs6320g9Ju0qaKmmapM+X7F9C0s/T/lskrdWvzhCeQRAMJGazay+9kDQSOAXYDdgY2F/SxoVihwJPmdm6wP8C3+jXvhCeQRAMJLNnzqq99GFrYJqZTTezF4Hzgb0KZfYCfpK+/wLYRZJ61mpmjRbgsAVZdlE//39SWxf0+f+T2rqgzz+v2jq/FuAwYGJuOSy3b2/gR7n1g4CTC8ffDYzNrf8ZWKHnOVs0cuKCLLuon/8/qa0L+vz/SW1d0OefV20dhGVeCc8YtgdBsLDzCLB6bn1s2lZaRtIoYFngiV6VhvAMgmBh5zZgPUlrS1oc2A8YXygzHjg4fd8buNZSF7SKNn6epy/gsov6+ZuUXdTP36Tson7+JmWb1LnAMbOZkg4HrgBGAmea2T2SjsNVEOOBM4BzJE0DnsQFbE/UR7gGQRAEJcSwPQiCoAUhPIMgCFoQwjOoRNIaC7oNQTCohPCsQNLLey09jhtXZ9u8RtJSw1DNxbn6LqpxzhGSthuG8waJeIENLrUMRpK2Byab2XOSDgS2BL5rZn+pKL8JHkM6OttmZmcXyowE7jGzDWs1VFoTWM/Mrpa0JDDKzJ6tc2wbJM0ADBCwBvBU+r4c8KCZrV1x3B1mtmVh2yQz26Ki/NuA/6LzWh1XUm574FhgTdxLQl7UXlUotx3wI2AZM1tD0mbAh8zsozV+dvGcc9rd6zdUHdOjzDZmdnOL9mwHrEXOS6R4X6VySwDvKil7XNp/F/7fdh3qxWzTkjrXAR42sxck7QhsCpxtZk83OXfT8+fvJ0kXmdm7So4rtnVF4IMlbXh/rsyRveows+8U6hTwHuBVZnZcEuqrmNmt/dqzsFLXVek0YLP0IH4KfzjPBnYoFpR0DLAjLjwn4MH4N6XyczCzWSnLyRpm9mCvk0v6IB5+9XJgHdzJ9fvALrkyrwZ+CKwGXAZ8zsyeSvtuNbOt0/dn6X3jjkntWzuV/yHwKzObkNZ3A95e0sb9gQOAtSXlfcjG4K4PZb/r+8BSwE74Nd0bqLoZzwA+CdwO9Arm/V/gv0l+bGZ2p6Q3Fs5b61rReZ3qumVcI+ldwC97+Mmdir+AkfQHM9u2X6WSzsH/+8kM/X6jcF8lLgH+gV+rF0r2797vfCVcBGwlaV3cVecS4FzgrQ3P3fT8+fjqV1WW6m7Db4Grqb5XXtagDeD/2WxgZ+A44Fn8mry2YT0LDzXDm+5In0cDh+a3lZS9C1cH3JnWVwauqih7I/4nXIM/7OOB8SXlJgOLA5Py5ymUuQnYFe8Zfhq4B1gn7ZvU6/f1+e131dy2Jv7S+AP+UsmWLfFeclndUwqfywC/rSh7S8323lL8zdl/0fRa4Q/eM+k/mpn7/izwTMX5n8Ufshdz5Z8plJlU9r3P77qPNFKqUfbutv93jzqzZ+AzwBFVbR/uc+efs6pnruSYyfPw91feV4vaUrfn+ayko4ADgTdKGgEsVlH232Y2W9JMSWOAx+kMjcrzpZrnf8HMXsySnKTwqWKv5mVmdnn6/i1JtwOXSzqopOwcJK1E55C52At+VNIXgZ+m9fcAjxbrMVdh/EXSmxi6BusDG+IvlDL+nT7/JemVeDjYqhVlr5P0TeCX5Ho0ZnZHodxDaXhrkhYDxuGCJ0+ta2VmIyvaUomZ1enRjJC0PP6Szb7P6WGZWVlP/W5gFeCvNer/vaRXm1nVdQdcfQCcBGyEv5xHAs9ZGn0UeCmNLg4G9kjbyp6BWuducP7NJD2DX58lc98hN1Iq8GtJb7U0WurThtF4Orai6uj9haIvJVWbpeNWxF+Siyx1hee++JD0UDP7W9J3fLOi7ERJy+HDwtuBf+K9sS7M7Iaa579B0hfwm+fNwEeBS4uFJC1rZv9IdV+Xho8X4cP9Ytk9gW8Dr8QF/Jq4kPmvQtH9gWOAX6X1G9O2Km4E3pAEwpV4aNi+uNAt8ut0rb4J3IHfmD+qqPd16XOr3DbDh1F5Pgx8Fx+SP5La8LFiZXWuVTI6vWRmL6X1DfBh6gNm9qtCfRua2f2SOvS9cxraKeSXxe+NTAjk9xm54amkS9O2lwH3SrqVzpfHnrmymS5xFHCIpOmpbJUu82Q8kuRC/Lq+F1i/rP3AIfi1/aqZzZC0NnDOXJy71vmbvMByKikBX5D0AvBSrg1lgvYc4H5c1XMcfp8WX7YA38OfgZUlfRVXMX2xbtsWRuoajJYGnjfXU2a9qcuyh6rHcWsBY8xsSsX+vP5xcfxN3vXmTz3dQ4G34DfCFXiWFMuVOQCYbgVDRBL0XzKzDxa234kLnqvNbAtJOwEHmtmhvX5TPzIFv6QjgCXN7ARJk81s8z7HLQGMzgRay3OPxI0YZYI6X67WtZJ0I/7C/FPS9d0K/AzXZ99mZp/PHXu6mR0m6bqSU5qZFYV83d/UpVcvVHxDruyafcp2GDglTTSzrSRNyYRbL4OX3FC5hplNLdnX6Nx1z9/kBdaG7HxZG9Jo5bdmtk1J2Q0ZsjNca2ZlQnbRoc7YHu8lLIX3Zh7A35Q/qygrfHh/dFpfA9i6xjmEG2K+XrF/cdzC+Wpg8bnVV5DSagF3AiOy77n9l5LTwxaXHvVOArYFbgb+K23r0pGm7UvhqosfpvX1gN0ryi4LfIehfIXfBpYtKXdT0+sDLFWx/a7c968Ap+T+i9LfVFHPYoX1NfNtxw1m38UNYqVtB75RZ1vafk7NbTem33I2cEI6f6keDx+qTwVmpPXNy+4D3Ki1RPq+I/BxYLmKOvueP5VZL31fFzc+noTbCaqelXcUru9ywNsryt6aO88mwAr4i7Ws7Jbp9xwBbNnkHlsYl7p+njKzfwHvBE41s33ShS7jVFx4ZEPbZ/EU+D0x52J8+NB5cnfn+TM+dDgZmJas3t0NldaX9ENJV0q6NltKij4taRn8pvmZpO8Cz+X2fwsXUDNw3eQP0/LP1JYqxgFH4Rb6eyS9CijrjQGchQ/tMmvzI8D/qyh7Jn4t352WZ9LxRaYDv5P0JUlHZktZhZK2k3QvPmxD0maSTs0VyQ9LdgauAjDPxt1T3yVnF0lnAA8Xdl8ALJ3KbY6/jB/EBdKplPPmkm2l9wAF1Uvqkb+mpNxBuJ7xcPy/Xx13MyrjWDwj+dMAZjaZcuv3RcCsnFV+ddwqX0ad8y9vZn9K3w8GzjOzI/Df/raKeo+x3AjG3J3qmIqypycV05fwjsG9lExBIeloPNP6y3EBe1ayBSy61JGwNOtN1bbK4cI4W/YGvg78oaTc/cC6ufV1gPsr6rwT+Ah+o78mW0rKLY3fuKPwm/LjwCtKynUlfi3b1mZhqPdb51pNrrntmLKlos5b8Ac2f/67c99/ir9EjgQeI/VQ8Z5MVTu3wV9yD+IvmoNxAZAvMyX3/VvACen7iPy+tO0juMHtOWBKbplBYfSDv7TyngGZtf8J4Pi5/K9uLvmvppSUy+7/z9LDKt/gvPlr9TtyPcge/0FZu4reKffiOst1arZjKq5WytaXBKbOzTX9T1/qGoya9KaaWOX2yH2fiasE9iop96yZTcutT8cfijJmmtlpFfvmYGb5XuZPKgvC0pJeZWbTAZKhYOl+9efJ9IElu15MerTsWq1DtW/gvyW93sxuSmW3Z8haPwcz+3KTtpnZQ+qcqiXvF/hB/L9fA3iL+egDXOf5rfxBkr4G7IMLzfOAL+Mvh7Jrmz/hzvi9hbmHQrHsubgv6vFAftbDZ61glTez44HjJR1vZkeV/uDONs+gxBPDCoEHiXuSrnikpPXwl+3vS8plVvn30tsqX/f8UyR9Cx+VrIsbAEmGxiomSvoOQyO+j+Gqtzz748aqKyU9gf9n55tZlTfDo7g1/vm0vgTdCYUXKYY9JZ2k9+DW5S1xobQ38EUzu3Au6jwN15NdgN9s2UN6NYCZ/TJX9ljcev4rOq2yHQ9aA2PVrvjwazr+0K+JR+xcUShXFbIpvIcwtuR3vRl/+2+MPxTbA+8zs+tLym6OX89lU51PprJ3FspdR/kD2WWwkfQLXI96Mm7NHwdsZWb7FcqNM7Pv9tom6XHgj8CJwKXmkTjTywRRUpGsCvwNFzDrm9lLklZNx25VPCZ3bD/Xsqzc8rgOOV/2xkKZV+RWR+P31cvN7OiS+pYC/gc3WoIbLf+fmT1fKLcxbpX/g5mdl1627zazsqFw3/Onl+s4/Hqdmf3fcne0dczsHAokA++XgDfh98JVuJfAc8Wyqfw2+DP7Llwlda6Z/bBQ5mLcIf6qVOebcQPiwwBm9vGyuhdm6lrbV8SHIUVfsJ0L5Ubgw7YncaucgGuswionaSyu/N4+bfotMM7MHi6UK9Pt5ZrREXY2o6JMZXSGvLuzF7CN5SzIuf1L4B4G4CqE5czssUKZWcBf6OxVWVpfzcwWL5Qfgb9YrsGvmfCh4d+r2pmOyyKgnqnYn9ftjcYfiJlm9tmSsivghpo34UPmK/Dr/0ShXN+Q0zTaeDPeo9kFH5m8CVjdzGYWjhX+sK4CXGhmj6TtWwArFV9Mad8euKDvcC0zs6JrGZI+gAucsXiAxTa4MOtr8Zd0u5mV6UfnC1Xnl/QaM7u9sG13M/t1YdtI3INkpxbn3hGPUNvYzJYo7Du417EVI4yFmzpje7xXdCju/7UDbryosnROqqszwN9ih+B6x1HA+6iIRpofS6+243q+Q3Fh92jJ/j/hbixlxz5Usb2v7hR3nwLXO3YtNX/XrS2vx/6418FTdHobXIe/FKuOy+K7f4HrSs8tKTMSuK5BW+4EXpH9R7iF/oyKsnfhL47JaX1DPFy0WG7L3LIV3mOs0iNeRc5qDiwPXJFbvyB37inFpaLOJue/A9ik8N+URp2le3TZmtf1tfhL6S/A9akNZbr/PUheKbH4Ulfn+QozOyMN1W7AndZvqyhbJ7Y5Y0Uzy/cqfyzpE8VCdXuoqexiuJEhi+e+HviBFXxSJb0ztzoCv3mLQ7Al8R7pAcAWuKP223ELfZET8QeqbBh5Qsk2gKslfRr4OTlLv3WqGDL9alnkTtf1LagPRuAGs2XLTp5019/Fe2aGBzN80pJ+F9fp/RW3rn47d+izuFAoxcxewK3OF0l6Ge46UywzS9Js5Zz1+/CSmT0hz9w0wtyx/8SKss+b2fOSkLSEufP+BiXl8r8p07m/u6LOFSyXBMTMnkoqhIxx6bNJ3HqT8+8N/CLpXd+A61TfUlH2n8Bdkq6i876aM7ROOup98VHi+cD2Zc9Tjn2BE+XZtc40s/t7lF0kqCs8M8HzV7nb0KOURO0kPoT3imZKep7e0Q1PyLM0nZfW96d8xrqzcMPBPmn9wLStzH3lNFx/mbm8HJS2faBQrqexStK5+E16JS64rwWmWYk+EsDMTkkP9nZm9vvCvpPKjsFvSOiMADJyLjBm9oP09Woz+13+4GQ0KnI7Q+qCmbhVusrx/1zcqJAJt/3w/+J16dx/wXsk26bzjWHonulIeKI+WXoq6PuQ5yi6lj1Op2tZnoeTQeVi4CpJT6Xf0YE1G9rOVi6Jjdwpfs7Ly5KhxSoyjZXR5PxmNl3SfvhvehA34HUZDBO/TEsvngd2tSE3qH7nPzD9//vjnRzDn8HzbB5mNxtk6uo8d8d7e6vjgmQM8GXziZPan9xvwJPwh9Pwns4RZvZQodxkK0TolG1L2+80s836bavRtsl4z+1s3Ar5cJUBpHDcJKuRuq3H8Yub+1EWt5fpHbu2NTzXnMiW3Lay63cYHrr3PO450ZUOT55NqxIr8QKo0qNZif4sGUH+jf8n78F70z+zgn625LgdUtnL89c16Vc/hRvrwAMPTjCzaZJGWbeeNjMc3oD//jcAh1m34fCduJ/kSqlcaeeh7vnVnb5uJTxr0wvpWpWFfSKfJTIL9ZxaHHnlyn0Mv45Pp/Xlgf3NrNTfNhm5DgI+gavx1gW+16ODsPAyL3UCuD/mF/G8nWX7t6+57Rq8tzkyLQdSoXPDdUPr5NZfRSEbDd7D/B3ec3oS712+Pu1bNlduQ9zl5n48cuf/gJX7/OZv4fq+WhmA0jHCjSxnAI8V9m2LP2QP0anvPJYS/RjeO39Z+v5FvAdSGg2CP+Sfx/M+rokbBY/HRxUvz5X7Ez5sXeB6ptSeFepcXzyCaytcPZTf/i5gGvB+PGpt0/R9crreVffWCviwfPeq65Hq3ahPu2qfP/0vlUtF/TviPe0b8J76DOCNFWUnl2yblPv+zvS5J+7BcheeWWql3DV+YEHfEwvkPuzzJ5+EOzyXLhXHvDI93LfhPZVjgFdXlO1KsVWxbU3cUPF/uKX1YqqNM7vgw5rr083zALBTbv9H8Lf8zngPekz6/nt8GF2lsH8NrqN6EPh9j2uWpWR7iYqUbLmydRzKd0jX8K90Or4fSQrbK5TP0tu9Pl2Dt1FtWJjRY5meK3c5FSGcJXWOxtUQp+KGxTNxHVm+TKlRhRLjSrpG1+MvgS3w7Ep/S/fBroWye6b/+w48/nsGHtjxN+Dg/DUC1ipp+1rpnv1axW9bHg++eGO2lJT5XY1r1Pj86Tq8LLc+BnhdRf23Axvk1tcHbq8oexe5FxHeObknt545/f+k7Pdmz1yde2NhW3oO25u4J6Sh3f54/PsFabnESjKuS9oW2A7v+v9vbtcY4B3WcIhdUv8SQGYgmGpuwMj23Yf3bot+n6/AfdY+aWbf71G3gDdYwWewYfuKDuW/wi3vXdcqd8yaVkOfpqFED8fjUSXnDoMqYQtcv3ULnb6zXbpJSRfiPfUDyGXpMbNxuTJr9jpf/ndKmgh8AR96nw7sZmY3y5NUnGed7lJ34td1WdwjYFNzXeFKeG/u1ancvWa2MSVImmpmXcaluu5Pch/WVfAXfP5a5X2R25x/Ej6CsLQ+Ar9nutQ2FeqYrm1p+zfxzkmmW/8Q7h3yqbR/rlRDCzP9DEY/x992/5ffKPf7LCqJT8attQeY2cRUrkoyL44n/h1FpxX5GdyqmJ3nJHrk4rRO6+HOZnZtwYoOsK6kjpu3KDjTtick/SUTnP3OTbnFPWvLnuSs/VbwxcONV3/EDVmZQ3k/5fO/0o3e09cWeETSD3Bj2jfSi2RERTtvx1UF51phOokCP8ANZnfRP4fjuma2j6S9zOwnyfD220KZVa3+NByjzCyLqjkuO87cgl4sO9vM/pjKzrDkNWBmj0vK6zBfUskMBkmoV0V4jcPdem42s52S8P5aSbkxwL/otIQbnQacNudXJjjTb5otz2tbxkRJP6IzB+3EirKfw2dp+Ehav4rOtIgbSirzrOiVam+RoJ/w/B4+ZCta7l6P3xwfyW1bFX/rf1vSKnjPszQszYbcnX7cpzdV9YeXsQP+gO9Rsi9/8z4jaTPrjszZDFfEF8+9Pa7U/3la3wePCy5F0tfxh+xnadM4SdtbZ7jgqgw5lJ8ojwpassxQkeNnqQ274754B+NqjCLvxrPEf8vMnpZH7Xymos59cT/biamHdxZwZf4hTSxmZnWt6Zlh4mn5XFZ/w40ceZpMw5EX1kXrcrGd+STLs9WZZDn/AjkGdxP7GkNhi1vh+t/PVbSjlvuTmR3S47fMzfmnS/o4/sIFz2k7vaLsR3DVSda5+C0VCVfMbDY+pc335W5uY80sH6I7g/JnKug1pqdCT5L2lRqB0r6xuJFjIm6Rq9IhrY8Pxa7EBd+1eJ7AXm1anh7GAmDtXttwwf8X3OCyR1q+jOvKXl9y7M3kptHAXwg39zj/FHLOxLgOqdRJOu3v61Ce/y/oTBRxW0XZzfBMPYcDm/W6nqn8CFxf+AiuSvgynQajr+G9k1VJxqT8/kJdH0j/0Rvxh/txPJw1X2ZS2feK+sqmAsnWXyqUnZHO2VOHm7tGZ+PC63Y8KXDltcJVK8ul++ZGfJ6gCbn9n02fpXaCiv8of/6z+5x/Jdwf8/HsPiEZbQplTgR+jRv+xtT476/He8svT9fpFuB/6/4/i/LS78Le13QfKZdhbn19PMFuWdmeGZDwOZM2zOrFheuT6QZ6U0WdZQan2wvrq+D6uIvS8hV8JsCy+qbSKUiWp0c2GVx45su/nPIsNyPwmOf8tjHAeyvqzbL6XIEbgbYA/lxSbhxuVDkuLXeRsvtU1Lsprneemh701+Evvsm5Mn2FUdVv6vG/L49HDGXfewrlWjfzkMfE6LZ11DzPDvjLZvHctt3T58FlS5/6lh6mdl0OfBVP63gScFaNYyalzw/g7ofQ+YI+eV5ey//kpd+FvYGSRMb4sPTGimNqWdDT9sqebdp/D0O+qIfhRoCR+JwvtxbKbshQYoN35pb30aOXXOPmOgTvqf4YtzjO6PUw4EPxYvl9K8rWTm2HD9eXxfOoXof3VvYsKTcl/zDiEUpFC/aV2fXH3cAOoPul1xXOWLOddUJOH6B+D/HlvZay+6nqfitpR9+RT93zAz/Ofa+8Pwp1b4urgB5M65vh+XKr2noNKWUg/tL7YqFMMZFy3+uAv1xXTdfgtdk9VFJuZVw/flla35g0GeSiuvTTeX4GuEDSj+nUzbwXj0aZQ9Jzrobr7rZgSNc0BvcFK+NSSR+lOgPSi5b+Kfxter65Pua+EmX5BriAWY5OHc2zeGq1rJ1Fp+M5uyhRgJvZWZIuw3tkhk/T+7eK34N5Jp3rGZqStVf5OuGZ2bbM6PQPPK67CtGZVm4WnclKwP0VAfaxoVDM4vnmGN4k7YM7mT8rT4C7JfAVM5vU5jeZ2Vo92l8kHzHV1Uw6ExK/JOl0YKyk75X8pqJ3wIW4vu9HVE/RW/f8+ftmHL3THGacSJ9ponP8EH8ef5DKTknGuI7k2QU978j8etl9hY9OrgBuMrPb5CG7ZVFHP8Z14v+T1v+I/8dn9P2VCyk9haeZ3Sppa1z5/L60+W7cv+zxQvH/TmXG4okGMp7FXU3KODh95g0a+RvyhWR0eAwXGJ/OlesQyGZ2CXCJpG3NrHTCuUSbObu3xiNKsvZdWiyg7gnQsjjhV0p6pXXPcgk1wjObeBwkzgJukfQr/KHZi+4bfLnMK0Ge6q5YZ9FA+CUzu1DS6/FMSd/Ehc7risfW/E09XV/y18p6uG+VsHtq33/Tnb+yjL65XxuevzHWO59qnqXS85jfVjQuLkvnxHowNLle8UWTnf9C/CWSrU+nPJv+CmZ2gXwWXcxspjyT2CJL39j2JCSPSeFeG+HWz6dLyv0E+Imkd5nZRXVOXuPG/ARuSFkRV2LPAJD0Vjy7/RwkfdbMTgAOkCejLZ7r4+mzduxxqrdoPf94EtDFF8KRuGrh23RjdM9yWffBbGT1N7PvpJ7v69N5DynpIS6LC5qq3lRReGYPyduA083sN5KqpgvZyLpzXI4ulMmu0Wh8JHNnasum+O/dNndsE0H7d+B8SfdZwZuign4jnw7SCye7rr81nzYmI+vtipKeb8lLDupNE53xd3mybEtt2ZvCNMxNevTZ81L1ci5p73NyX+js/NvQ6Z2yyFE3tv2t+HDhz/jNsTZuQb2spOxyuKEnG37cABxnJZlzVDMDUq0fIu1hZpeqT7y0OpMgd1RBeQzyFGBzc5eOLF/ipOLwPu0bAWxrhQQefdq9HR5ZMudFZmZnl5S7GTeIZDHPvWY53BLvKc/GI17uKOxv5Pgs6de4Jf7N+JD937jOebOSsrVj8CX9Ep8i5K60vglwrJnlfX2v69E0s5yfa9NeuhrkfpXP7bQuQ0ls9sUNdh9L+0vvu1ylZfH6+XyqwvWO46wkXj8Np0/Hg0uewvXD76nqDEhaDXd+z99XN+b213pecuW3xI1Qm+CjzxWBva1iZtxFgbrC837cmjgtra8D/MbMNiwpexF+cbOLfxDuglF0Xic58i5WKDvLzD6Q9vf0LTSz7/TaPxwk4blj1htJvnDXlwnPtH+S1YzmkXQOHv8/maHenZX1UiRNxQVz1o7lcQv8BoVyR+O90otgzoykF5rZ/8uVqd3GVH4p3Hf0LvNpiFfFQ26vzJXJdN4/xQ1QeZ339yvulXuskMy4bFuDdjYWYA3qvh/vVWc9rxG4IXKjivJL2dC0JcOGPEHKCOuRyUjSN3Dhfi+d99Wec3nuUbhtQfRINrKoUDclXZM5hNYxs7zO5MvyDEVlvLbQe7lWHmKXkUUfbYAPncen9T3wKQDmIOlSevc6Sm8c9Z/W4XhgUuoBCe8ld2Wbz9Ekn+lWeNbu/m8wnxyv2I5jS8q9B39ZPQ9z1A6T6TQsHFTjfHNIQuCXkpaStBXwl7zgTLTReU9RdyRMaU9G0nsr2nZ27nsj4ZheCkfieRIOk89NtIF1R4SBJ/JYg6HUdqunbcU6t8V1zMsAa8iDLz5kZh8tKdtl1MKHwhOTDj8rtwGuEspeQPfJ58X6Y8VPe3v6HVXRSkgaX7UPhp4XdUfsZayvQuTeokZP4Zm7cBMlTaBzDqGqZMi1JipLzJK0jpn9OZV9FTmFuaU0ZpJuxON6n03rxwK/KdSVTUj2TtyPM3sg98cNTsXftieue+uY1oHCtLXWzHoOQ/lMZ0n6NxXqgMTdqa1Vk27l25G3+vdqR9+Juszsbpjz/1amT0vX6Hu4b+0X8dyfjwFrSfpcXlhZC5037gb2EYYSCd/IUARNkdfmvo/GE8DcgTuXdyAPH/4criPuFcp6Fm5g2S6tP4IbT8qE58twoXUr/gxsjT8XmaU8ezmfSH0L+mhcIGYGm3fhw/HNJO1kZp9IwviXuNrsdPw/2gK4XtI7rTzMdTo+oqsUnrhe+SFcDXEL5fpv6B1dVKYfX2TolxjkrF4HW0koWnrTns1Q9vKncL+3rh6FpF3wG3g6zJlc7RAzu65Qbiqe5OGFtL4E7otWlkBhohUmEKvYdiduxLnaPJHGTviUF12JgyVtSrdecq5vmtSL3BzvRecNFlW95J56rFTmYmpO1CVpGrCHVc8xVSvRRuGYLGJqrUI7jyu9CC1JuvXzzWzXkn1X4oa1T5MLZTWzzxXKTTSzrfJqDFXkfpXnBa3EPOQYSbeY2etq1nkznqRmVlofhYdSvh5XkWycXpjfsEIS7tSez5tZ19z1SXW2Ge4XWprIRZ1zTm2Kd0bOM7N7ev3OYIh+rkp14nSLx9yJvznHpPVn5FNrdAlPM7smGyqlTR0ZkHKcDdwqd78BH5ZUDdHqThVca1oHSWfiN9c9DMVZV75xJQkffq5tZl+RtDqeCOPWkuLHVvyGsnozPVaxHTcWiv4qLRnX96j2sSrBmaibaCPPJfjQ83Z693yyUcmxdL8Qugw2JTyHGy7LqDttTO2pn83sBnnijvXM7Op03KgS3WMTC/ry+PA+M6YujTvez5KUtWOdouDMtef0inrHM6TiKiUJ7MuBy9MLb3+8N/tlMzu57Bj5LBLFxDTD+lL8T6KWzjP1QMvcGd5fdYx1zu54JD6cyeo7EO/1npOE5ZS0/SBJs8zs3EJdX5V0Of5GhnL3m4xP4jdBvjf7oZJyT6vetA7bWEX6sApOxYXbznjY5z/x4e6cYaekU/AY9hsa1Pt2+uixEpdZwQdX0gZmNrWk7ERJP6c6fVrdRBt5xpb1Bis4A/+/bqfavzH7DXmd9gh8SH5BRfG608YcgwuQ1SX9jDT1c8X5P4jrHV+OG/nG4r6uuxSKfhi3oK+GqwGupNPnNc8JwOSkFsr02F+TG4WuTmV6TXFROg2JdaaKXB6fwbRs5LcE7n62Pz5S+B6dL9582e/jvtU74UEFe1OwOyxq1LW25w1Ao/E5bx61mnM1S3rIzFbPrd+CJ1D9Z6Hc0njYZ9nUqyPxELF8D6Vo3MnKdkwVXCZwVHNaB0lnAN82s8pMSoXyd5jZlr2GbZLG4RFaq+IC4LweL4PsmMvwiKB/9ik3FXdqvyCtfwoPo+t6AVSoZSx7KUp6gKFpN8rKlbn0nA6cZMn9qE9bbzGzMkf7srL5YfNM3GhVOmGZGkwbI/dd7Dv1s9zouTWeWDr7X+8qU100Qe65sHVavc3MHi3sfxxPCNJ1KJ5HYOWSOq/HY+9H4S+mx3GXtSNzZc7G3Y4m4OqPu/u0c4qZbZr7XAZ/Ub+h13ELM7WEZ9dB7qZxk5lt17ewl3/QzNbIrVf6Gao8kesReC/hMYbCDa1YLle+p++kGsxtnR7a8XhqtRdqnPsW3ABxWxKiK+Kx5F2uQWkYuF9alsSV9+dZiRW1jh4rlVsVNyw8j79s7gM+1U/oDheS7sX9IWfQ53rJPQFG4iqQ/G+6I1fmx2b2vvT9YBvm+cHr6JFTuQ5dZtJP3lFyr9ayoOfKLw+sR+dQOO+P2cZ/NGvjB/Be5zHF50rSbIZ6rnkhUOXvnP3+m3Gj7JN4nP26vdq3MFPXVanIehRyNKq38/mShW1LSlrazDqGHfJpahcvqWMcPmTtOdlXqqPUd5KcVdaaTXt7Bu7aUycRMAwNfVaS9FV8ePOlsoLmDs7fwJMWb4FPWXE0LlCK9NVjpTr/mlQcR6X2fr6kh18rukQNontydBkwepD1OvPGvGI0Vt7Q0jNmvOr3zKm4+0VTV48Mrjf9An7vvhnPp9kVpksNC3ru/KXZ6cn9/pYvi1HpJfpuhmLROzCzKrVLFb+WG+lOYCj09UfVxRd+6uo8M8Go9Pk3CklbzaxsXvEqzsDnoP5wEiBIWgvXDZYlGniI+qFgdX0n6057+39lw70qzOxn8gztu+DX6+1Wbc0ehQub/VL566kwItV9iCRdjev4NsGHrWdIutHM8nkBMhVEv2TTZaGmc5pEecjpX+Qx8OuZu1etiBtFiu3cEPc9vSUv3CUVhW+ToVH+93wZH6304u3U0yOD3+8fwF+iH8KHu2XCY1M6LeinkbOgF8qOo092erXzX66b7KMvkl6LT8vxlbS+TPod99M5hc4iR6th+7CcWPow3jtaBhcyzwJft5JEDUnvuAHuTpEf3nVFGMnn0Pm4pXm0e5y/bljaqXimpkupmJOmUP4cMzuo17bUc9mfNDkbrtO6pNgTL9Qxg/Je4qsK5d5uuZjrJKCPym7+tG2eDYXlUxBvhQul9SW9Eo9w2j5X5uO4EeU+3FVrXDakLap0cjo/4b3EDv1fld5dNaKoGuiRs0nRuqKkSspOxdM4/iOtL4uHsm5QbJOk28zstUmf+jrz6Vg6Iqxyut5S/2Uz+2S/Ns0Nku7Ac+c+KfdXPR84Av/fNrJcKO2iRj8n+TWBp3M3wk742/oB4BQrmV+8LuZzBX0/DdWxHuFmeHbzB/EhfdmwPs8KwL1yZ+ZK30nz+XWWxKNLyizRGUumenrNSZOnGG44Ek/ynOcoPBP4p8zsqR7nzpMf2o7G/S/nWJCVsjqZ2cXyaSJeALLsN1cV6mqcPk0ed150Ou9yUMeNiVuQsvmY2aPZf5zjg3jS63+mEccvJK1lZt+l2ziVz7jVZFqWyl5Bbnj/L9za3VOPnNQ8U1Uy71AJdSzoGQ+nofDFwFWSnmIogik7d+Y/+m3r9FW+VD51Sv53fRAPHf6TJOGjuL3x5/Vg62OUrGCkDSVK2RdPDHMRcJGqIwcXCfoN2y/AH4Z/yFOXXYiHK26Ou+R8oM1JVRKzrlyqrWKP0lKkUU2OrdmGPfCopMWBtdPvO65EyNbydZWn6sp0YpmbloAX8VyM+Tp3TsesI+lfqcexIy7UzraSydhK9L0nJvXA0Wn9XNK8QLjeLK+vPLWw3ojUm9wRF54TcFXDTZRE95BysCpNaJeERpERWW/PzB5Iv/0X6WXdITxtKKHLPubp0/Lt2qflT8qEzu3U0CMnlgfuSS/lvJqneL+cIY/GyyzoX7AhC/pnCmXfkb4eKw+YWBZ3nSqjjv/yODzvJnjPdDPcF3YLXBffxjI+UkNza+2Cu2tltLWZLBT0+/FL5v74A/H5t78tt7ZPnovz1o5ZB0h6s8/Sf+bIzHl4ZYb8Km+17tyj4EJ2a5ITuZlNTrqh4rnXx0MGVzazTeTRRntaLtFGOv544HhJx1vnZG+9uAjYStK6uIX8ElwIvrWkHXnhNwLvieb/P1V8L1tvmj5tb/xBnGRmh6Tr+1PKuUA+e+dyqSf0fgovD+AxSZub2eR0vn/K3YvOBKpcf44il3eybJs6jZZLFV5iZsmCnBPIS+MTu2X6yZF4OGsZpUa/Cp7HQ25H47O3rmvdkWAdqgDr7/Nb5r98WKHMTBtK1rE7/iJ+Ak9QfUKD9uc5DzeW/R137fttav+6LOIp6foJz/xDtzN+s2I+7Wnrk1qzmHWoP3Mkkt6NJ+u9PrX/JEmfMbNfFIq+ZGb/KPyOMmt6rQzeOTqSRaSH5IsVvefZaVj9Dtw38iT5/Nxl5I03M/Gh2Ltz26zie9l606Hwv9N/PlMeOfY4boyaQ3qYVjazbyWd7jP4y/EyvLea570UEvmmns17k+DN17sb/jJZrSDkx5TU0cRoCe729SbceAiuormSoVj3fN21AhpUw4Ke6muiCsDMLpdH4/XyX54tt7I/hfcSv5rbV/R4qYV5gMo1pKk6bMhIMgLXfS6y9BOe10q6AH+LLo/P8ZL5ErbWd+ZYuVDPi2lbkbrhduCuGa/Nepup13o1nlQ5zz2SDsCHJevh07T+vqS+Ohm88+wiDyo4FJ/g7Cw8p2kZL8kTNx/MUAKGquma+/mkVvUmhUe75OtqOhSemHRzP8SHuv/EBUKeExl6uV6Fx9Yj6dVp35wEE1bh3J72FXOhPooL+D3pzA7/LN4bmxtG541FqQfcMUOBpJvM7PXqdsUr9Yek/vzuUFMVkNqxGG7ln5P7VlIx9+3R+LUaCYy3FKcuNzpNr2hDX6wk+YhVZ3RaZOgnPD+BK4lXxRPxZn/UKlT4jzWkbsx63XA7cH1afpj+BOWhhEfgv+EFfKh8BeW9yb4ZvPOY2QGS9sXdOZ4DDigRCBmH4D3pr5rZjKTHOqesoNxqewzVSaZ79Sarepd9h8LpN2Xp1L4v9yEdY93hfitbSVSRmd0lNwq1wjxXwp2SzrXhzx/5nKQtLfmrSnoN3RnA3pPaUbdXW2t+90QTVcBp+Is1m3/9oLRtjt3BzH6d7r0XzF2UNsbzsN7P0PQowTDRyFVJHsr2Rny2vzpzxNSp8zUMxazfWGYRVHm43bFmVjaX0Ddxw0s+4/cU686oM+eh6dO+V9Esg/d6+AvgLnzaknuBI20uE+OqZpLpqt5kfltuKPxuhqb1AL+uG5vZ1oXjrzGzXXptk/QnM1uvou3TbC4jUdI98BWGooGqen5N6nwt7nrzaKpvFWA/M5uYKzPHdUrSRdaZq7aszl/hL8VP4EP1p4DFzKxLj92wrV2ZmYrb5Ia93fDrcxUehHAdnj3pCjPLD+ODucV6T0v6a2CT9H1VvMd1KS4QPtHr2LoLPsR4JZ5odg3cdajOcZ8orK+LOyeD+8R9Jy1H45lpisdfh/sZfiX7jX3OtzRu6BqJC8+qcvfjcfvgD+SnqJj6GI/U+kW6ntOzpaLs5Jrb+k79jBt/DsbdYg7OLe8Els+VG4338O+kc271tXCdW77O84APlpz7A8DPh+E+mYa/FDUc912qcwm8N7dJWhajewrmSWXfa9a/A4X53Qv7t8Hz4v4TV1nNAp6pKHtH/j7GJ3Mr/q93pftzKVznPCZtX5KS6YRjmcv7p8+ff0/u+xdw6x1JiMz1n4EPnf+Oh8dNSX9+rXpJc13n1n+NTw1RLPdq4NKKOlbBdZ2/S+f+Ym7fGHwIezL+5hZwON7zvKRHu8aUbFu/ouxNuGJ/Ct6jOhYfipeV/QOuOsnWtwf+kFvfDe+VP4a7pWTLjynMcZ87ZrE+13gcQzHqM3LLncDhhbIr4zrj63Hj1rdx1cIfgFWG4V65DlfJDN/NX+9Fc0ev8oWyIym8VPqUn4i/9CelYw8Bjq8ouwvu63x9uq4PADsVykwq+57WJw/ntYulv/CcnPt+DT6kGbY/A+9NvKLlsQ8V1m/rUfauPnW9Gtc1vpjbdkkSPB/C/V2zm3bzijo+m/u+T2Hf1yqOub3YvmxbSdnNktB6IC2T8OTE+f19e5OFOndP9TyJ91SepaTnAxzR4H/ZCX8pHgHsPGw3qhthspj9I7OlZV2r4IEL9+E+kFumZcei8CP1BtO1mZm+97pWl1B/9DQxfU7JbZvUo/wSeO97Uwo95LT/FtzACbkXDe4/2lPwx9J86Wcwekie0ejhdHNdDiCPzCm1CjekScx6kaKydrkeZbvcNCRthOtD34UblS7Ah9gZr7KUbkw+z85f8Yfi+WJdif3w6BLoNrrsSvk8Pi8kn9k/STocz//YEQeeubJYSZLpfDlrZ1g5EReud1l6yir4gTykco6ll4pZTs1nAbiu5vmb8FV8eDua/lFm/ag935KZlSVp6UVtCzrwL/mU3ncmP8y/UpEntaa1/Y02FFmWd7tbDH+RBsNIP+F5KJ5k4E3AvjYU+bIN7oIzt0zHb4LSmPUS95CMskxNEyV90Mw6HLKT312Zcess3Kf0o3ivtSgU59yU5j55D/cQnFmbyr6XrWeMw/VTH8d1rzvTfZNfTIoOqmOwAP5bUl3DykN4WrFeghPcwtvT0jsfeKWZbTIcFVm7+Zbq0sSCfhAuLD+Gu12NxV/mZdSxtldlwf87rh4LhpEFlhgE5lgHu7Bm4ZhZXSvjqeBeZEhYboX3Ut5habI0eaKMr+GRL5lz8uq4MP2f7E0uaRbec8gE35J4LHRVvsO8VbaY3KLRPOmFeifZUPLdOd97lJ9Gvd5kZm3+Cq6OKHt5jTJ34u9r6Z3XpJ7Z1dY9a2ebug40s5/KE0V3XSObx1NaS9oLz7h/Slq/BU/xaLj6p+iTXMvaHsxf+iUG6Rn3WzEUqU0bIdmjrseA7eTJS7Ieym/M7NpC0W/iBq+1bSiyaQwe5/4t0kyOLYZrm8nDAUV3fPvofMGG19UqvldRtzcJ/YfCt+K93p6znM4nPgJ8Wj63z0vMnatSFhPelSqPZinwupC0DW642wi/piOB5wrt/Cyu5slYAtfBLoO/xLuEJ4PxHwQ5+g3b605P2go1iFmvSw2d2+649XvOQ2I+Sd1HcDejcbn21U5F1lDYNrmuvYRymfD4LDBBUmlvskC/oXDWrk8D18njqsFdlWolTBkurHnoZS8mpDq7Xt7Jn3RuOBkXjBfiI5/3AusXyixuZg/l1m8yz1z0pAqJVOSTJ/4e+Dwe8Tcj7VoLHz0FC4h+2aRXwRXom+CTWr0Z+LuZ3WDNJi+r4me4wFobT177ANXzwQ8XVtYrM08OYSXbpkpao1h+Lql9Xc1spJmNMbOXmdmo9D1bL+t1fRVXL4zGe9jZUsYESW+p2AewojwD1uZ4bP+1afkhbqWeb0jaPhMskg6U9J25+F+uKot6knQI/n/MFWY2DU/lNsvMzsINhnmWL5Q/PLe6YqHsWNyw93PcDe1JPKHMdiWjqmA+0m/q4cbTkzakScz6cHGvpPdaIRelfEbP+0vKN7Ge1mIeX9cmhpV+Q+GRDCWrzjOKaoE8rzgN74VvhntF/Ah3L9uhRV1HAldKepuZ/QnIUgoe0LK+PHUs6LdUGDc/RCGrmKUZAFKdW+GRbjsCR0l62prN7BoMI33z8anB9KQtaBKzPlx8DPilpPfTaVhaEs9dWqSJ9bQ28/C6TpD0ljqGlRpD4b/a4MzLPdPMLBlbTk4v3UPbVGRmE9IL4zJJb8ct1lvjrj5PzWU761jQPwlcLE9Mk4UIvwbXfb69ot4l8cCNZdPyKN3TegTzkZ7WdjWcnrTxyRvErA83knZmKOv7vWZ2zbw+Z+7c8+y6JveupXF9Z0/DiqTt8WCH51LPe0vgREsp0upY9+cXSYd7Oa5rfSOeFu9Om4upfyW9AX9h/R6fxreXK1q/utpY0PP34D1lw3D5VM7/hfug3gLcjGdsmlshH8wl/YRno+lJh6VB0ifM7MThrrctNa2nTeuc79e1oh1T8MikTfFoqh/hQmSHtP/lNjQFwwJF0ir4sPo2M/tt0nfuWFS/1KwrP6HhEvhLJj+ldePrL+l3eATeQ2l9Mu63uwxwlhUSqzSo93J8apm7cSH/B+p7UwTzkAXq51mGCnO8L2jk88R0WU+tfrb4+Uq/3mSh7B3mc8sfDTyShsKtfVLnF5JWAJ4YJAGiNJlbbv3kzBAk6WYz22Yu6hbe+9wuLZvghqM/mFmpr3Qw72k6d/P8YFjdoYaDGtbTQeI03GiRGVb+TEWOUODZZCg5EPiNPFR0OMJuhw1J20i6XtIvJW0h6W68F/aYpEH6H5pY0Bthzt24mucyPJHNOuTc6oL5zyAKz4HpTSQy6+lkSSdI+iSDed0yZqYeWWZYOYVqy/i+uG70UPMIrLF4EMEgcTIeEXYe7ib1ATNbBdd7Hr8gG1bgFvmcTR2UWdCbIOnjks6X9CAeCbY77hXyTua9cTXowQIZtqtPzLqZDcysfPIZHR/D9Z2fxC2dp6be6MDR1rAyiENhcN2hmW2evt9nZhvl9g2SQWslPA/BC5RY0M0j4NrU+x28p/l7M6ucwSCY/wycznMQUb353QeCOoaVZAT7Oq43+wo+rF8B71G/18yqpr+d72ge5QyYV9SxoAcLByE8+6Dc/O5mtrYq5ncfRKp6k8kI9gW8F306sJuZ3SyfrOy8QenNQVeCliw5C2l9tJkNlI42WHQYZN3doHAs7kD9NPj87ng46UDR0LAyysyuNJ/X6G+WZkc0s7IIqwWK9Q5PDcEZLDAGRrc4wJTN7z6I3fWTGepNXkuhN0lKZJ3IJ8otzhY5iL8tCAaOEJ4VSJqAh9jVnd99QTMqC8mUdFy+N1kQ/NAgfV4QBOXEsL2as/C53B/AnZKz+d3/wWD619XuTcZQOAjmnjAY9UDSMnhikF1xi3R2sczmcbbxpoRhJQjmLzFs782LuEBaAo9RHtg3jTXPfB8EwVwQwrOCZKH+DjAe2NLM/tXnkCAIFiFi2F6BpN8CHzazexZ0W4IgGDxCeAZBELQgrO1BEAQtCOEZBEHQghCeQRAELQjhGQRB0IIQnkEQBC34/6p47/yzGctUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(), yticklabels=False, cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure'] = df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU8AAAE9CAYAAACLJ+A4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABDwklEQVR4nO2dd7gdVdX/P997A4QWQFFAQu+INBEpKk18UWkqShFERLGBUey+Sn0VxfJDBUuQIiggiEJQerdRAgmBINGYIE1BKYIoJbB+f6w9986ZM3POzMlN7oG7Ps8zzzkzs2fPPnNm1uy92paZEQRBEDRjYLQbEARB8EIkhGcQBEEPhPAMgiDogRCeQRAEPRDCMwiCoAdCeAZBEPRACM8gCF70SDpV0kOS7qjYL0nfkTRb0gxJm3erM4RnEARjgdOBXTrsfzOwTloOAb7frcIQnkEQvOgxs+uBRzoU2QM4w5wbgGUlrdSpznH1T/+nCEUKgqAm62p+a1h81X1ry5yn7j3ng3iPMWOymU1ucLqVgXtz6/elbX+rOqCB8AyCIOhPkqBsIiznmxCeY4DFVz1y6Pt/7zm69r4gGE2khapVvB9YJbc+MW2rJITnGKCTUAyBGfQrA1qo4mkKcKikc4DXAv8ys8ohO4TwDIKgTxnJnqeks4HtgeUl3QccCSwCYGY/AC4G3gLMBv4DHNStzhCeQRD0JdJ825yGMLN9u+w34KNN6gzhGQRBn9LfnpQhPIMg6EsWssGoMSE8gyDoS0J4BkEQ9MBCtrY3pr9bFwTBmCV6nkEQBD0QwjMIgqAHxMi5Ki0IQngGQdCXRM8zCIKgBwYG+ls89XfrgiAYw0TPMwiCoDExbA+CIOiBEJ5BEAQ9oBi2B0EQNCd6nkEQBD0wMDA42k3oSAjPIAj6khi2B0EQ9EAM24MgCHoghGcQBEEPxLA9CIKgBxThmUEQBM0ZyQngFgQhPIMg6Eti2B4EQdADYTAKgiDohRi2B0EQ9EB/dzxDeAZB0KcM9Lf0DOEZBEF/0t+yM4RnEAT9iYXOMwiCoAf6W3aG8AyCoE8Z6G/pGcIzCIL+JIbtQRAEPTAYwjMYZRZf9cih7/+95+ja+4JgVImeZzDadBKKITCDvqW/ZWcIzyAI+pQ+Nxj1uRtqEARjFjVYulUl7SJplqTZkj5Xsn9VSddImiZphqS3dKszep5BEPQlNjgyfTtJg8BJwM7AfcDNkqaY2Z25Yl8EzjWz70vaELgYWL1TvdHzDIKgPxm5nueWwGwzm2NmzwDnAHsUyhgwIX1fBnigW6UhPIMg6E+k2oukQyRNzS2H5GpaGbg3t35f2pbnKGB/Sffhvc7DujUvhu1BEPQnDQxGZjYZmDwfZ9sXON3Mvilpa+BMSRuZ2fOVzZuPkwVBECw4Rm7Yfj+wSm59YtqW52DgXAAz+wMwHli+U6UhPIMg6E8aDNu7cDOwjqQ1JC0K7ANMKZS5B9jJT6sNcOH5j06VxrA9CIL+ZITCM81snqRDgcuAQeBUM5sp6RhgqplNAT4JnCzpE7jx6L1mZp3qDeEZBEF/MoLhmWZ2MW4Iym87Ivf9TmDbJnWG8AyCoD/p7wCjEJ5BEPQn1ufhmSE8gyDoTyKrUhAEQQ/0t+wM4RkEQZ8yQrHtC4oQnkEQ9CfR8wyCIOiBMBgFQRD0QAjPIAiC5lh/y84QnkEQ9ClhMAqCIOiBGLYHQRD0QH93PEN4BkHQp0SEURAEQQ/EsD0IgqA5Fj3PIAiCHhgXwjMIgqA50fMMgiDogdB5BkEQ9EB/y84QnkEQ9CeRST4IgqAXQngGQRD0wAhNPbygCOEZBEF/Etb2IAiCHohhexAEQQ+E8AyCIGhOhGcGQRD0QhiMgiAIeiCG7UEQBD0QwjMIgqAH+lt2hvAMgqA/ifDMIAiCXghrexAEQQ+EtT0IgqA5A30+e2afNy8IgrGKVH/pXpd2kTRL0mxJn6so8y5Jd0qaKemsbnVGzzMIgr5kpFSekgaBk4CdgfuAmyVNMbM7c2XWAT4PbGtmj0p6ebd6o+cZBEFfIqn20oUtgdlmNsfMngHOAfYolPkAcJKZPQpgZg91qzSEZxAEfcnAQP1F0iGSpuaWQ3JVrQzcm1u/L23Lsy6wrqTfSbpB0i7d2hfD9iAI+hI16NqZ2WRg8nycbhywDrA9MBG4XtKrzOyxqgOi5xkEQV8yggaj+4FVcusT07Y89wFTzOxZM5sL/AkXppWE8AyCoC8ZUP2lCzcD60haQ9KiwD7AlEKZC/BeJ5KWx4fxczpVGsP2IAj6kpGytpvZPEmHApcBg8CpZjZT0jHAVDObkva9SdKdwHPAp83s4Y7tM7OaTfhT3YJBEIx51p1v0ffK066vLXNmHvSGhR6OFD3PIAj6koEIzwyCIGhOn+cFCeEZBEF/EsIzCIKgB0J4BkEQ9ECf50IO4RkEQX8SPc8gCIIeCGt7EARBD0TPMwiCoAdCeAZBEPRACM8gCIIeCGt7EARBDwwMjnYLOhPCMwiCviSG7UEQBD1QY26iUSWEZxAEfUmfy84QnkEQ9CchPINRZ/FVjxz6/t97jq69LwhGkxCewajTSSiGwAz6lXF9PsNaCM8xQPQ8gxciA+rvmX9CeI4BoucZvBAJJ/kgCIIe6PNRewjPIAj6kxi2B0EQ9EAM24MgCHpgXAjPIAiC5iiG7UEQBM2JYXsQBEEPhLU9CIKgB8LaHgRB0ANhMAqCIOiB0HkGQRD0QAzbgyAIeiB6nkEQBD0Q1vYgCIIeiGF7EARBD/R7MuQ+b14QBGOVgQZLNyTtImmWpNmSPteh3DskmaQtutUZPc8gCPqSkRq2SxoETgJ2Bu4DbpY0xczuLJRbGpgE3FirfSPSuiAIghFmQPWXLmwJzDazOWb2DHAOsEdJuWOBrwFP1Wpfg98SBEGw0GgybJd0iKSpueWQXFUrA/fm1u9L24aQtDmwipn9um77YtgeBEFf0sTP08wmA5N7OY+kAeBbwHubHBfCcwwQs2cGL0QGB0bMVel+YJXc+sS0LWNpYCPgWvlk8SsCUyTtbmZTqyoN4TkGiNkzgxciI6hTvBlYR9IauNDcB9gv22lm/wKWz9YlXQt8qpPghBCeQRD0KSNlbTezeZIOBS4DBoFTzWympGOAqWY2pZd6Q3gGQdCXjGRsu5ldDFxc2HZERdnt69QZwjMIgr4kEoMEQRD0wCIR2x4EQdCc6HkGQRD0QAjPIAiCHhgM4RkEQdCc6HkGQRD0QCRDDoIg6IFFoucZBEHQnBi2B6NOJAYJXojEsD0YdSIxSPBCJKztQRAEPRDD9iAIgh7o99kzQ3iOAULnGbwQGQydZzDahM4zeCHS5x3PEJ5BEPQnofMMgiDogRCeQRAEPRA6z2DUyRuFoFXP2WlfEIwmYW0PRp0wGAUvRGLYHgRB0AMRYRQEQdADEdseBEHQA32u8gzhGQRBfxI6zyAIgh5YZCCG7UEQBI2JnmcQBEEPhPAMgiDogTAYBUEQ9ICi5xkEQdCcGLYHQRD0QAzbgyAIekARYRQEQdCcPh+1h/AMgqA/6XeDUb+rFYIgGKOowdK1LmkXSbMkzZb0uZL9h0u6U9IMSVdJWq1bnSE8gyDoSwZVf+mEpEHgJODNwIbAvpI2LBSbBmxhZhsDPweO79a+EJ5BEPQlUv2lC1sCs81sjpk9A5wD7JEvYGbXmNl/0uoNwMRulYbwDIKgL2kybJd0iKSpueWQXFUrA/fm1u9L26o4GLikW/vCYDQGyM9TVJx2o9O+IBhNmtiLzGwyMHm+zyntD2wBbNetbAjPMUDMYRS8EBnBCKP7gVVy6xPTthYkvRH4X2A7M3u6a/tGrHlBEAQjyAha228G1pG0hqRFgX2AKS3nkjYDfgjsbmYP1Wlf9DyDIOhLRmoOIzObJ+lQ4DJgEDjVzGZKOgaYamZTgK8DSwHnyS1Q95jZ7p3qlVndBv6pv2OlgiDoI9ad70H3nCcuqi1z1lx6t4XuUh89zyAI+pJ+1ymG8AyCoC/p9/DMEJ5BEPQlfS47Q3gGQdCfRDLkIAiCHgjhGQRB0AN9LjtDeAZB0J9EJvkgCIIeiJ5nEARBD4SrUhAEQQ8MjnYDuhDCMwiCviR6nkEQBD3R39IzhGcQBH2JQngGQRA0R+rv1CAhPIMg6FOi5xkEQdAY9XlSuhCeQRD0JTFsD4Ig6IkYtgdBEDQmrO1BEAQ9EMIzCIKgB6T+DtAM4RkEQZ8SPc8gCILGxLA9CIKgJ8JVKQiCoDHR8wyCIOgB9XlOuhCeQRD0JerzdMghPIMg6FOi5xkEQdCYGLYHQRD0RAjPIAiCxkRKuiAIgp6InmcQBEFjBiKfZxAEQS+E8AyCIGhMv0cY9bdoD4JgDKMGS5eapF0kzZI0W9LnSvYvJulnaf+NklbvVmcIzyAI+hJJtZcu9QwCJwFvBjYE9pW0YaHYwcCjZrY28P+Ar3VrXwjPIAj6EjFYe+nClsBsM5tjZs8A5wB7FMrsAfw4ff85sJO6SWUza7QAh4xm2bF+/hdSW0f7/C+kto72+RdUWxfWAhwCTM0th+T27QX8KLd+AHBi4fg7gIm59b8Ay3c8Zw+NnDqaZcf6+V9IbR3t87+Q2jra519Qbe2HZUEJzxi2B0HwYud+YJXc+sS0rbSMpHHAMsDDnSoN4RkEwYudm4F1JK0haVFgH2BKocwU4MD0fS/gaktd0Cp68fOcPMplx/r5m5Qd6+dvUnasn79J2SZ1jjpmNk/SocBlwCBwqpnNlHQMroKYApwCnClpNvAILmA7oi7CNQiCICghhu1BEAQ9EMIzCIKgB0J4BpVIWnW02xAE/UoIzwokvaTT0uG4SXW2LWgkLTEC1VyQq+/8GucckLTNCJw3SMQLrH+pZTCStC0w3cyelLQ/sDnwbTP7a0X5jfAY0vHZNjM7o1BmEJhpZuvXaqi0GrCOmV0paXFgnJk9UefYXpA0FzA868CqwKPp+7LAPWa2RsVxt5rZ5oVt08xss4rybwVeSeu1Oqak3LbAUcBquJeEvKitWSi3DfAjYCkzW1XSJsAHzewjNX528ZxD7e70G6qO6VBmKzO7oYf2bAOsTs5LpHhfpXKLAe8oKXtM2n87/t+2HerFbOOSOtcC7jOzpyVtD2wMnGFmjzU5d9Pz5+8nSeeb2TtKjiu29WXAB0ra8L5cmcM71WFm3yrUKeDdwJpmdkwS6iua2U3d2vNipa6r0veBTdKD+En84TwD2K5YUNKRwPa48LwYD8b/bSo/hJk9l7KcrGpm93Q6uaQP4OFXLwHWwp1cfwDslCvzKuBkYGXgEuCzZvZo2neTmW2Zvj9B5xt3QmrfGqn8ycAvzezitP5mYM+SNu4L7AesISnvQzYBd30o+10/AJYAdsCv6V5A1c14CvAJ4BbguYoy4EkN/ofkx2Zmt0l6Q+G8ta4VrdeprlvGVZLeAfyig5/c9/AXMJL+YGZbd6tU0pn4fz+d4d9vFO6rxIXAv/Br9XTJ/l27na+E84EtJK2Nu+pcCJwFvKXhuZuePx9fvWZlqfY2/Aa4kup7ZekGbQD/z54HdgSOAZ7Ar8lrGtbz4qFmeNOt6fMI4OD8tpKyt+PqgNvS+grAFRVlr8f/hKvwh30KMKWk3HRgUWBa/jyFMr8FdsF7hp8CZgJrpX3TOv2+Lr/99prbVsNfGn/AXyrZsjneSy6re0bhcyngNxVlb6zZ3huLvzn7L5peK/zBezz9R/Ny358AHq84/xP4Q/ZMrvzjhTLTyr53+V1/JI2UapS9o9f/u0Od2TPwaeCwqraP9Lnzz1nVM1dyzPQF+Psr76uxttTteT4h6fPA/sAbJA0Ai1SU/a+ZPS9pnqQJwEO0hkbl+VLN8z9tZs9kSU5S+FSxV7O0mV2avn9D0i3ApZIOKCk7hKSX0zpkLvaCH5D0ReAnaf3dwAPFesxVGH+V9EaGr8G6wPr4C6WM/6bP/0h6BR4OtlJF2WskfR34BbkejZndWih3bxremqRFgEm44MlT61qZWdd0NUXMrE6PZkDScvhLNvs+1MMys7Ke+h3AisDfatT/e0mvMrOq6w64+gD4LrAB/nIeBJ60NPoo8GwaXRwI7Ja2lT0Dtc7d4PybSHocvz6L575DbqRU4FeS3mJptNSlDePxdGxF1dH7CkWfTao2S8e9DH9JjlnqCs+98SHpwWb296Tv+HpF2amSlsWHhbcA/8Z7Y22Y2XU1z3+dpC/gN8/OwEeAi4qFJC1jZv9KdV+Tho/n48P9YtndgW8Cr8AF/Gq4kHlloei+wJHAL9P69WlbFdcDr08C4XI8NGxvXOgW+VW6Vl8HbsVvzB9V1Pva9LlFbpvhw6g8HwK+jQ/J709t+GixsjrXKhmdnjWzZ9P6evgw9W4z+2WhvvXN7C5JLfreoYa2Cvll8HsjEwL5fUZueCrporRtaeBOSTfR+vLYPVc20yWOAw6SNCeVrdJlnohHkpyHX9f3AOuWtR84CL+2XzazuZLWAM6cj3PXOn+TF1hOJSXgC5KeBp7NtaFM0J4J3IWreo7B79PiyxbgO/gzsIKkL+Mqpi/WbduLkboGoyWBp8z1lFlv6pLsoepw3OrABDObUbE/r39cFH+Tt735U0/3YOBN+I1wGZ4lxXJl9gPmWMEQkQT9l8zsA4Xtt+GC50oz20zSDsD+ZnZwp9/UjUzBL+kwYHEzO17SdDPbtMtxiwHjM4HW47kHcSNGmaDOl6t1rSRdj78w/5x0fTcBP8X12Teb2edyx042s0MkXVNySjOzopCv+5va9OqFiq/LlV2tS9kWA6ekqWa2haQZmXDrZPCSGypXNbNZJfsanbvu+Zu8wHohO1/WhjRa+Y2ZbVVSdn2G7QxXm1mZkB071Bnb472EJfDezN34m/KnFWWFD++PSOurAlvWOIdwQ8xXK/Yvils4XwUsOr/6ClJaLeA2YCD7ntt/ETk9bHHpUO80YGvgBuCVaVubjjRtXwJXXZyc1tcBdq0ouwzwLYbzFX4TWKak3G+bXh9giYrtt+e+HwuclPsvSn9TRT2LFNZXy7cdN5h9GzeIlbYd+FqdbWn7mTW3XZ9+yxnA8en8pXo8fKg+C5ib1jctuw9wo9Zi6fv2wMeAZSvq7Hr+VGad9H1t3Pj4XdxOUPWsvK1wfZcF9qwoe1PuPBsBy+Mv1rKym6ffcxiweZN77MW41PXzlJn9B3g78D0ze2e60GV8Dxce2dD2CTwFfkfMuQAfPrSe3N15/oIPHU4EZierd3tDpXUlnSzpcklXZ0tJ0cckLYXfND+V9G3gydz+b+ACai6umzw5Lf9ObaliEvB53EI/U9KaQFlvDOA0fGiXWZvvB/6vouyp+LV8V1oeT8cXmQP8TtKXJB2eLWUVStpG0p34sA1Jm0j6Xq5IfliyI3AFgHk27o76Ljk7SToFuK+w+1xgyVRuU/xlfA8ukL5HOTuXbCu9ByioXlKP/NUl5Q7A9YyH4v/9KribURlH4RnJHwMws+mUW7/PB57LWeVXwa3yZdQ5/3Jm9uf0/UDgbDM7DP/tb62o90jLjWDM3amOrCg7OamYvoR3DO6kZAoKSUfgmdZfggvY05ItYOxSR8LSrDdV2yqHC+Ns2Qv4KvCHknJ3AWvn1tcC7qqo8zbgw/iN/upsKSm3JH7jjsNvyo8BLy0p15b4tWxbLwvDvd8612p6zW1Hli0Vdd6IP7D589+R+/4T/CVyOPAgqYeK92Sq2rkV/pK7B3/RHIgLgHyZGbnv3wCOT98H8vvStg/jBrcngRm5ZS6F0Q/+0sp7BmTW/oeB4+bzv7qh5L+aUVIuu/8/QwerfIPz5q/V78j1IDv8B2XtKnqn3InrLNeq2Y5ZuFopW18cmDU/1/SFvtQ1GDXpTTWxyu2W+z4PVwnsUVLuCTObnVufgz8UZcwzs+9X7BvCzPK9zB9XFoQlJa1pZnMAkqFgyW7158n0gSW7nkl6tOxarUW1b+B/Jb3OzH6bym7LsLV+CDM7uknbzOxetU7VkvcL/AD+368KvMl89AGu8/xG/iBJXwHeiQvNs4Gj8ZdD2bXNn3BH/N7C3EOhWPYs3Bf1OCA/6+ETVrDKm9lxwHGSjjOzz5f+4NY2z6XEE8MKgQeJmUlXPChpHfxl+/uScplV/j10tsrXPf8MSd/ARyVr4wZAkqGxiqmSvsXwiO+juOotz764sepySQ/j/9k5ZlblzfAAbo1/Kq0vRntC4THFiKekk/Ru3Lq8OS6U9gK+aGbnzUed38f1ZOfiN1v2kF4JYGa/yJU9Cree/5JWq2zLg9bAWLULPvyagz/0q+ERO5cVylWFbArvIUws+V0742//DfGHYlvgvWZ2bUnZTfHruUyq85FU9rZCuWsofyDbDDaSfo7rUU/ErfmTgC3MbJ9CuUlm9u1O2yQ9BPwJOAG4yDwSZ06ZIEoqkpWAv+MCZl0ze1bSSunYLYrH5I7t5lqWlVsO1yHny15fKPPS3Op4/L56iZkdUVLfEsD/4kZLcKPl/5nZU4VyG+JW+T+Y2dnpZfsuMysbCnc9f3q5TsKv16nZ/y13R1vLzM6kQDLwfgl4I34vXIF7CTxZLJvKb4U/s+/AVVJnmdnJhTIX4A7xV6Q6d8YNiPcBmNnHyup+MVPX2v4yfBhS9AXbsVBuAB+2PYJb5QRcZRVWOUkTceX3tmnTb4BJZnZfoVyZbi/XjJaws7kVZSqjM+TdnT2ArSxnQc7tXwz3MABXISxrZg8WyjwH/JXWXpWl9ZXNbNFC+QH8xXIVfs2EDw3/WdXOdFwWAfV4xf68bm88/kDMM7PPlJRdHjfUvBEfMl+GX/+HC+W6hpym0cbOeI9mJ3xk8kZgFTObVzhW+MO6InCemd2ftm8GvLz4Ykr7dsMFfYtrmZkVXcuQ9H5c4EzEAyy2woVZV4u/pFvMrEw/ulCoOr+kV5vZLYVtu5rZrwrbBnEPkh16OPf2eITahma2WGHfgZ2OrRhhvLipM7bHe0UH4/5f2+HGiypL57S6OgP8LXYQrnccB7yXimikhbF0ajuu5zsYF3YPlOz/M+7GUnbsvRXbu+pOcfcpcL1j21Lzd93U4/XYF/c6eJRWb4Nr8Jdi1XFZfPfPcV3pWSVlBoFrGrTlNuCl2X+EW+hPqSh7O/7imJ7W18fDRYvlNs8tW+A9xio94hXkrObAcsBlufVzc+eeUVwq6mxy/luBjQr/TWnUWbpHl6l5XV+Dv5T+Clyb2lCm+9+N5JUSiy91dZ4vNbNT0lDtOtxp/eaKsnVimzNeZmb5XuXpkj5eLFS3h5rKLoIbGbJ47muBH1rBJ1XS23OrA/jNWxyCLY73SPcDNsMdtffELfRFTsAfqLJh5PEl2wCulPQp4GfkLP3WqmLI9KtlkTtt17egPhjADWbLlJ086a6/jffMDA9m+IQl/S6u0/sbbl39Zu7QJ3ChUIqZPY1bnc+XtDTuOlMs85yk55Vz1u/Cs2b2sDxz04C5Y/8JFWWfMrOnJCFpMXPn/fVKyuV/U6Zzf1dFnctbLgmImT2aVAgZk9Jnk7j1JuffC/h50ru+Htepvqmi7L+B2yVdQet9NTS0TjrqvfFR4jnAtmXPU469gRPk2bVONbO7OpQdE9QVnpng+ZvcbegBSqJ2Eh/Ee0XzJD1F5+iGh+VZms5O6/tSPmPdabjh4J1pff+0rcx95fu4/jJzeTkgbXt/oVxHY5Wks/Cb9HJccF8NzLYSfSSAmZ2UHuxtzOz3hX3fLTsGvyGhNQLIyLnAmNkP09crzex3+YOT0ajILQyrC+bhVukqx/+zcKNCJtz2wf+L16Zz/xXvkWydzjeB4XumJeGJumTpqaDrQ56j6Fr2EK2uZXnuSwaVC4ArJD2afkcL1mxo+7xySWzkTvFDLy9LhharyDRWRpPzm9kcSfvgv+ke3IDXZjBM/CItnXgK2MWG3aC6nX//9P/vi3dyDH8Gz7YFmN2sn6mr89wV7+2tgguSCcDR5hMn9X5yvwG/iz+chvd0DjOzewvlplshQqdsW9p+m5lt0m1bjbZNx3tuZ+BWyPuqDCCF46ZZjdRtHY5f1NyPsri9TO/Ytq3huYYiW3Lbyq7fIXjo3lO450RbOjx5Nq1KrMQLoEqPZiX6s2QE+S/+n7wb703/1Ar62ZLjtktlL81f16Rf/SRurAMPPDjezGZLGmftetrMcHgd/vtfDxxi7YbDt+N+ki9P5Uo7D3XPr/b0dS/HszY9na5VWdgn8lkis1DPWcWRV67cR/Hr+FhaXw7Y18xK/W2TkesA4OO4Gm9t4DsdOggvXhakTgD3x/winrezbP+2Nbddhfc2B9OyPxU6N1w3tFZufU0K2WjwHubv8J7TI3jv8nVp3zK5cuvjLjd34ZE7/wBW6PKbv4Hr+2plAErHCDeynAI8WNi3Nf6Q3UurvvMoSvRjeO986fT9i3gPpDQaBH/IP4fnfVwNNwoeh48qXpIr92d82DrqeqbUnuXrXF88gmsLXD2U3/4OYDbwPjxqbeP0fXq63lX31vL4sHzXquuR6t2gS7tqnz/9L5VLRf3b4z3t6/Ce+lzgDRVlp5dsm5b7/vb0uTvuwXI7nlnq5blrfPdo3xOjch92+ZO/izs8ly4Vx7wiPdw34z2VI4FXVZRtS7FVsW013FDxD9zSegHVxpmd8GHNtenmuRvYIbf/w/hbfke8Bz0hff89PoyuUti/GtdR3QP8vsM1y1KyPUtFSrZc2ToO5dula/g3Wh3fDyeF7RXKZ+ntXpeuwVupNizM7bDMyZW7lIoQzpI6x+NqiO/hhsVTcR1ZvkypUYUS40q6RtfiL4HN8OxKf0/3wS6Fsrun//tWPP57Lh7Y8XfgwPw1AlYvafvq6Z79SsVvWw4PvnhDtpSU+V2Na9T4/Ok6LJ1bnwC8tqL+W4D1cuvrArdUlL2d3IsI75zMzK1nTv8/Lvu92TNX5954sS0dh+1N3BPS0G5fPP793LRcaCUZ1yVtDWyDd/3/X27XBOBt1nCIXVL/YkBmIJhlbsDI9v0R790W/T5fivusfcLMftChbgGvt4LPYMP2FR3Kf4lb3tuuVe6Y1ayGPk3DiR6Ow6NKzhoBVcJmuH7rRlp9Z9t0k5LOw3vq+5HL0mNmk3JlVut0vvzvlDQV+AI+9J4MvNnMbpAnqTjbWt2lbsOv6zK4R8DG5rrCl+O9uVelcnea2YaUIGmWmbUZl+q6P8l9WFfEX/D5a5X3Re7l/NPwEYSl9QH8nmlT21SoY9q2pe1fxzsnmW79g7h3yCfT/vlSDb2Y6WYw+hn+tvtHfqPc77OoJD4Rt9buZ2ZTU7kqybwonvh3HK1W5Mdxq2J2nu/SIRentVoPdzSzqwtWdIC1JbXcvEXBmbY9LOmvmeDsdm7KLe5ZW3YnZ+23gi8ebrz6E27IyhzKuymf/5Nu9I6+tsD9kn6IG9O+ll4kAxXtvAVXFZxlhekkCvwQN5jdTvccjmub2Tsl7WFmP06Gt98Uyqxk9afhGGdmWVTNMdlx5hb0YtnnzexPqexcS14DZvaQpLwO81mVzGCQhHpVhNck3K3nBjPbIQnvr5SUmwD8h1ZLuNFqwOnl/MoEZ/pNz8vz2pYxVdKPaM1BO7Wi7GfxWRo+nNavoDUt4vqSyjwrOqXaGxN0E57fwYdsRcvd6/Cb48O5bSvhb/1vSloR73mWhqXZsLvT6V16U1V/eBnb4Q/4biX78jfv45I2sfbInE1wRXzx3NviSv2fpfV34nHBpUj6Kv6Q/TRtmiRpW2sNF1yJYYfyE+RRQYuXGSpy/DS1YVfcF+9AXI1R5F14lvhvmNlj8qidT1fUuTfuZzs19fBOAy7PP6SJRcysrjU9M0w8Jp/L6u+4kSNPk2k48sK6aF0utjOfZPl5tSZZzr9AjsTdxL7CcNjiFrj+97MV7ajl/mRmB3X4LfNz/jmSPoa/cMFz2s6pKPthXHWSdS5+Q0XCFTN7Hp/S5gdyN7eJZpYP0Z1L+TMVdBrTU6EnSftKjUBp30TcyDEVt8hV6ZDWxYdil+OC72o8T2CnNi1HB2MBsEanbbjg/ytucNktLUfjurLXlRx7A7lpNPAXwg0dzj+DnDMxrkMqdZJO+7s6lOf/C1oTRdxcUXYTPFPPocAmna5nKj+A6wvvx1UJR9NqMPoK3jtZiWRMyu8v1PX+9B+9AX+4H8LDWfNlppV9r6ivbCqQbP3ZQtm56Zwddbi5a3QGLrxuwZMCV14rXLWybLpvrsfnCbo4t/8z6bPUTlDxH+XPf0aX878c98d8KLtPSEabQpkTgF/hhr8JNf77a/He8kvSdboR+H91/5+xvHS7sH9suo+UyzC3vi6eYLesbMcMSPicSetn9eLC9ZF0A72xos4yg9MthfUVcX3c+Wk5Fp8JsKy+WbQKkuXokE0GF5758i+hPMvNAB7znN82AXhPRb1ZVp/LcCPQZsBfSspNwo0qx6TldlJ2n4p6N8b1zrPSg/5a/MU3PVemqzCq+k0d/vfl8Iih7HtHoVzrZh72mBjfax01z7Md/rJZNLdt1/R5YNnSpb4lR6hdlwJfxtM6fhc4rcYx09Ln+3H3Q2h9QZ+4IK/lC3npdmGvoySRMT4svb7imFoW9LS9smeb9s9k2Bf1ENwIMIjP+XJToez6DCc2eHtueS8desk1bq6D8J7q6bjFcW6nhwEfihfL711RtnZqO3y4vgyeR/UavLeye0m5GfmHEY9QKlqwL8+uP+4Gth/tL722cMaa7awTcno39XuIL+m0lN1PVfdbSTu6jnzqnh84Pfe98v4o1L01rgK6J61vgufLrWrrVaSUgfhL74uFMsVEyl2vA/5yXSldg9dk91BJuRVw/fglaX1D0mSQY3XppvP8NHCupNNp1c28B49GGSLpOVfGdXebMaxrmoD7gpVxkaSPUJ0B6RlL/xT+Nj3HXB/zxxJl+Xq4gFmWVh3NE3hqtaydRafjoV2UKMDN7DRJl+A9MsOn6f17xe/BPJPOtQxPydqpfJ3wzGxbZnT6Fx7XXYVoTSv3HK3JSsD9FQHeacOhmMXzDRneJL0TdzJ/Qp4Ad3PgWDOb1stvMrPVO7S/SD5iqq2ZtCYkflbSZGCipO+U/Kaid8B5uL7vR1RP0Vv3/Pn7ZhKd0xxmnECXaaJznIw/jz9MZWckY1xL8uyCnncwv152X+Gjk8uA35rZzfKQ3bKoo9Nxnfj/pvU/4f/xKV1/5YuUjsLTzG6StCWufH5v2nwH7l/2UKH4/6QyE/FEAxlP4K4mZRyYPvMGjfwN+XQyOjyIC4xP5cq1CGQzuxC4UNLWZlY64Vyilzm7t8QjSrL2XVQsoPYJ0LI44VdIeoW1z3IJNcIzm3gcJE4DbpT0S/yh2YP2G3zZzCtBnuquWGfRQPglMztP0uvwTElfx4XOa4vH1vxNHV1f8tfKOrhvlbBrat//0J6/soyuuV8bnr8x1jmfap4l0vOY31Y0Li5D68R6MDy5XvFFk53/PPwlkq3PoTyb/vJmdq58Fl3MbJ48k9iYpWtsexKSR6Zwrw1w6+djJeV+DPxY0jvM7Pw6J69xY34cN6S8DFdizwWQ9BY8u/0Qkj5jZscD+8mT0RbP9bH0WTv2ONVbtJ5/LAno4gvhcFy18E3aMdpnuaz7YDay+pvZt1LP93XpvAeV9BCXwQVNVW+qKDyzh+StwGQz+7WkqulCNrD2HJfjC2WyazQeH8ncltqyMf57t84d20TQ/hM4R9IfreBNUUG3kU8L6YWTXdffmE8bk5H1dkVJz7fkJQf1ponO+Kc8WbaltuxFYRrmJj367HmpejmXtPdJuS90dv6taPVOGXPUjW1/Cz5c+At+c6yBW1AvKSm7LG7oyYYf1wHHWEnmHNXMgFTrh0i7mdlF6hIvrdYkyC1VUB6DPAPY1NylI8uXOK04vE/7BoCtrZDAo0u7t8EjS4ZeZGZ2Rkm5G3CDSBbz3GmWw83xnvLzeMTLrYX9jRyfJf0Kt8TvjA/Z/4vrnDcpKVs7Bl/SL/ApQm5P6xsBR5lZ3tf3mg5NM8v5uTbtpatB7lf53E5rM5zEZm/cYPfRtL/0vstVWhavn8+nKlzvOMlK4vXTcHoyHlzyKK4ffndVZ0DSyrjze/6+uj63v9bzkiu/OW6E2ggffb4M2MsqZsYdC9QVnnfh1sTZaX0t4Ndmtn5J2fPxi5td/ANwF4yi8zrJkXeRQtnnzOz9aX9H30Iz+1an/SNBEp7bZ72R5At3bZnwTPunWc1oHkln4vH/0xnu3VlZL0XSLFwwZ+1YDrfAr1codwTeKz0fhmYkPc/M/i9XpnYbU/klcN/R282nIV4JD7m9PFcm03n/BDdA5XXeP6i4V2ZaIZlx2bYG7WwswBrUfRfeq856XgO4IXKDivJL2PC0JSOGPEHKgHXIZCTpa7hwv5PW+2r3+Tz3ONy2IDokGxkr1E1J12QOobXMLK8zOVqeoaiM1xR6L1fLQ+wysuij9fCh85S0vhs+BcAQki6ic6+j9MZR92kdjgOmpR6Q8F5yW7b5HE3ymW6BZ+3u/gbzyfGK7TiqpNy78ZfVUzCkdphOq2HhgBrnGyIJgV9IWkLSFsBf84Iz0YvOe4baI2FKezKS3lPRtjNy3xsJx/RSOBzPk3CIfG6i9aw9Igw8kceqDKe2WyVtK9a5Na5jXgpYVR588UEz+0hJ2TajFj4Unpp0+Fm59XCVUPYC+qN8Xqw/Vfy0PdPvqIpWQtKUqn0w/LyoPWIvY10VIvfGGh2FZ+7CTZV0Ma1zCFUlQ641UVniOUlrmdlfUtk1ySnMLaUxk3Q9Htf7RFo/Cvh1oa5sQrK3436c2QO5L25wKv623XHdW8u0DhSmrbVm1nMYzmf6nKT/UqEOSNyR2lo16Va+HXmrf6d2dJ2oy8zugKH/tzJ9WrpG38F9a7+I5/58EFhd0mfzwsp60HnjbmAfZjiR8PUMR9AUeU3u+3g8AcytuHN5C/Lw4c/iOuJOoayn4QaWbdL6/bjxpEx4Lo0LrZvwZ2BL/LnILOXZy/kE6lvQx+MCMTPYvAMfjm8iaQcz+3gSxr/A1WaT8f9oM+BaSW+38jDXOfiIrlJ44nrle3E1xI2U67+hc3RRmX58zNAtMchpnQ62klC09KY9g+Hs5Y/ifm9tPQpJO+E38BwYmlztIDO7plBuFp7k4em0vhjui1aWQGGqFSYQq9h2G27EudI8kcYO+JQXbYmDJW1Mu15yvm+a1IvcFO9F5w0WVb3kjnqsVOYCak7UJWk2sJtVzzFVK9FG4ZgsYmr1QjuPKb0IPZJ06+eY2S4l+y7HDWufIhfKamafLZSbamZb5NUYqsj9Ks8LWol5yDGSbjSz19as8wY8Sc1zaX0cHkr5OlxFsmF6YX7NCkm4U3s+Z2Ztc9cn1dkmuF9oaSIXtc45tTHeGTnbzGZ2+p3BMN1clerE6RaPuQ1/c05I64/Lp9ZoE55mdlU2VEqbWjIg5TgDuEnufgM+LKkaotWdKrjWtA6STsVvrpkMx1lXvnElCR9+rmFmx0paBU+EcVNJ8aMqfkNZvZkeq9iO6wtFf5mWjGs7VPtgleBM1E20kedCfOh5C517Ptmo5CjaXwhtBpsSnsQNl2XUnTam9tTPZnadPHHHOmZ2ZTpuXInusYkFfTl8eJ8ZU5fEHe+fk5S1Y62i4My1Z3JFvVMYVnGVkgT2pcCl6YW3L96bPdrMTiw7Rj6LRDExzYi+FF9I1NJ5ph5omTvD+6qOsdbZHQ/HhzNZffvjvd4zk7CckbYfIOk5MzurUNeXJV2Kv5Gh3P0m4xP4TZDvzX6wpNxjqjetw1ZWkT6sgu/hwm1HPOzz3/hwd2jYKekkPIb9ugb17kkXPVbiEiv44Epaz8xmlZSdKulnVKdPq5toI8/Est5gBafg/9ctVPs3Zr8hr9MewIfk51YUrzttzJG4AFlF0k9JUz9XnP8DuN7xJbiRbyLu67pToeiHcAv6yrga4HJafV7zHA9MT2qhTI/9FblR6MpUptMUF6XTkFhrqsjl8BlMy0Z+i+HuZ/viI4Xv0PrizZf9Ae5bvQMeVLAXBbvDWKOutT1vABqPz3nzgNWcq1nSvWa2Sm79RjyB6r8L5ZbEwz7Lpl4dxEPE8j2UonEnK9syVXCZwFHNaR0knQJ808wqMykVyt9qZpt3GrZJmoRHaK2EC4CzO7wMsmMuwSOC/t2l3Czcqf3ctP5JPIyu7QVQoZax7KUo6W6Gp90oK1fm0jMZ+K4l96Mubb3RzMoc7cvK5ofN83CjVemEZWowbYzcd7Hr1M9yo+eWeGLp7H+9vUx10QS558KWafVmM3ugsP8hPCFI26F4HoEVSuq8Fo+9H4e/mB7CXdYOz5U5A3c7uhhXf9zRpZ0zzGzj3OdS+Iv69Z2OezFTS3i2HeRuGr81s226Fvby95jZqrn1Sj9DlSdyPQzvJTzIcLihFcvlynf0nVSDua3TQzsFT632dI1z34gbIG5OQvRleCx5m2tQGgbuk5bFceX92VZiRa2jx0rlVsINC0/hL5s/Ap/sJnRHCkl34v6Qc+lyveSeAIO4CiT/m27NlTndzN6bvh9oIzw/eB09cirXostM+slbS+7VWhb0XPnlgHVoHQrn/TF78R/N2vh+vNd5ZPG5kvQ8wz3XvBCo8nfOfv8NuFH2ETzOfu1O7XsxU9dVqcg6FHI0qrPz+eKFbYtLWtLMWoYd8mlqFy2pYxI+ZO042Veqo9R3kpxV1ppNe3sK7tpTJxEwDA99Xi7py/jw5ktlBc0dnL+GJy3eDJ+y4ghcoBTpqsdKdf4tqTg+n9r7uZIefq3oEjWI7snRZsDoQNbrzBvzitFYeUNLx5jxqt8zVHH7i6auHhlcb/oF/N7dGc+n2RamSw0Leu78pdnpyf3+Hl8W49JL9F0Mx6K3YGZVapcqfiU30h3PcOjrj6qLv/ipq/PMBKPS598pJG01s7J5xas4BZ+D+kNJgCBpdVw3WJZo4F7qh4LV9Z2sO+3tP8qGe1WY2U/lGdp3wq/XnlZtzR6HC5t9UvlrqTAi1X2IJF2J6/g2woetp0i63szyeQEyFUS3ZNNloaZDTaI85PSv8hj4dczdq16GG0WK7Vwf9z29MS/cJRWFb5OhUf73HI2PVjqxJ/X0yOD3+/vxl+gH8eFumfDYmFYL+vfJWdALZSfRJTu9evNfrpvsoyuSXoNPy3FsWl8q/Y67aJ1CZ8zR07B9RE4sfQjvHS2FC5kngK9aSaKGpHdcD3enyA/v2iKM5HPofMzSPNodzl83LO17eKami6iYk6ZQ/kwzO6DTttRz2Zc0ORuu07qw2BMv1DGX8l7imoVye1ou5joJ6M9nN3/atsCGwvIpiLfAhdK6kl6BRzhtmyvzMdyI8kfcVWtSNqQtqnRyOj/hvcQW/V+V3l01oqga6JGzSdHaoqRKys7C0zj+K60vg4eyrldsk6Sbzew1SZ/6WvPpWFoirHK63lL/ZTP7RLc2zQ+SbsVz5z4i91c9BzgM/982sFwo7Vijm5P8asBjuRthB/xtfTdwkpXML14X87mCfpCG6liHcDM8u/k9+JC+bFifZ3ngTrkzc6XvpPn8Oovj0SVlluiMxVM9neakyVMMNxzEkzzn+TyeCfyTZvZoh3PnyQ9tx+P+l0MWZKWsTmZ2gXyaiKeBLPvNFYW6GqdPk8edF53O2xzUcWPiZqRsPmb2QPYf5/gAnvT632nE8XNJq5vZt2k3TuUzbjWZlqWyV5Ab3v8Ht3Z31CMnNc8slcw7VEIdC3rGfWkofAFwhaRHGY5gys6d+Y9+01p9lS+ST52S/10fwEOH/yxJ+ChuL/x5PdC6GCUrGLThRCl744lhzgfOV3Xk4Jig27D9XPxh+Jc8ddl5eLjiprhLzvt7OalKYtaVS7VV7FFaijSqyVE127AbHpW0KLBG+n3HlAjZWr6u8lRdmU4sc9MS8AyeizFf547pmLUk/Sf1OLbHhdoZVjIZW4m+94SkHjgirZ9FmhcI15vl9ZXfK6w3IvUmt8eF58W4quG3lET3kHKwKk1ol4RGkYGst2dmd6ff/vP0sm4Rnjac0OWd5unT8u16Z48/KRM6t1BDj5xYDpiZXsp5NU/xfjlFHo2XWdC/YMMW9E8Xyr4tfT1KHjCxDO46VUYd/+VJeN5N8J7pJrgv7Ga4Lr4Xy/ighufW2gl318ro1WbyoqDbj18898fvj8+//U25tX36fJy3dsw6QNKbfYbuM0dmzsMrMOxXeZO15x4FF7JbkpzIzWx60g0Vz70uHjK4gpltJI822t1yiTbS8ccBx0k6zlone+vE+cAWktbGLeQX4kLwLSXtyAu/Abwnmv//VPG9bL1p+rS98AdxmpkdlK7vTyjnXPnsncumntD7KLw8gAclbWpm09P5/i13LzoVqHL9+Ty5vJNl29RqtFyi8BIzSxbknEBeEp/YLdNPDuLhrGWUGv0qeAoPuR2Pz966trVHgrWoAqy7z2+Z//IhhTLzbDhZx674i/hhPEH18Q3an+ds3Fj2T9y17zep/WszxlPSdROe+YduR/xmxXza055Pas1i1qH+zJFIeheerPfa1P7vSvq0mf28UPRZM/tX4XeUWdNrZfDO0ZIsIj0kX6zoPT+fhtVvw30jvyufn7uMvPFmHj4Ue1dum1V8L1tvOhT+b/rP58kjxx7CjVFDpIdpBTP7RtLpPo6/HC/Be6t53kMhkW/q2bwnCd58vW/GXyYrF4T8hJI6mhgtwd2+3ogbD8FVNJczHOuer7tWQINqWNBTfU1UAZjZpfJovE7+y8/LreyP4r3EL+f2FT1eamEeoHIVaaoOGzaSDOC6zzFLN+F5taRz8bfocvgcL5kvYc/6zhwrFOp5Jm0rUjfcDtw14zVZbzP1Wq/EkyrnmSlpP3xYsg4+TevvS+qrk8E7z07yoIKD8QnOTsNzmpbxrDxx84EMJ2Comq65m09qVW9SeLRLvq6mQ+GpSTd3Mj7U/TcuEPKcwPDL9Qo8th5Jr0r7hhJMWIVze9pXzIX6AC7gd6c1O/wTeG9sfhifNxalHnDLDAWSfmtmr1O7K16pPyT153eHmqqA1I5FcCv/UO5bScXct0fg12oQmGIpTl1udJpT0YauWEnyEavO6DRm6CY8P44riVfCE/Fmf9SKVPiPNaRuzHrdcDtwfVp+mP4w5aGEh+G/4Wl8qHwZ5b3Jrhm885jZfpL2xt05ngT2KxEIGQfhPekvm9ncpMc6s6yg3Gp7JNVJpjv1Jqt6l12Hwuk3ZenUfiD3IZ1g7eF+K1hJVJGZ3S43CvWEea6E2ySdZSOfP/JJSZtb8leV9GraM4C9O7Wjbq+21vzuiSaqgO/jL9Zs/vUD0rYhu4OZ/Srde0+buyhtiOdhvYvh6VGCEaKRq5I8lO0N+Gx/deaIqVPnqxmOWb++zCKo8nC7o8ysbC6hr+OGl3zG7xnWnlFn6KHp0r41aZbBex38BXA7Pm3JncDhNp+JcVUzyXRVbzK/LTcUfhfD03qAX9cNzWzLwvFXmdlOnbZJ+rOZrVPR9tk2n5Eo6R44luFooKqeX5M6X4O73jyQ6lsR2MfMpubKDLlOSTrfWnPVltX5S/yl+HF8qP4osIiZtemxG7a1LTNTcZvcsPdm/PpcgQchXINnT7rMzPLD+GB+sc7Tkv4K2Ch9XwnvcV2EC4SPdzq27oIPMV6BJ5pdFXcdqnPcxwvra+POyeA+cd9KyxF4Zpri8dfgfobHZr+xy/mWxA1dg7jwrCp3Fx63D/5AfpKKqY/xSK2fp+s5J1sqyk6vua3r1M+48edA3C3mwNzydmC5XLnxeA//NlrnVl8d17nl6zwb+EDJud8P/GwE7pPZ+EtRI3HfpToXw3tzG6VlEdqnYJ5W9r1m/dtRmN+9sH8rPC/uv3GV1XPA4xVlb83fx/hkbsX/9fZ0fy6B65wnpO2LUzKdcCzzef90+fNn5r5/AbfekYTIfP8Z+ND5n3h43Iz059eqlzTXdW79V/jUEMVyrwIuqqhjRVzX+bt07i/m9k3Ah7An4m9uAYfiPc8LO7RrQsm2dSvK/hZX7M/Ae1RH4UPxsrJ/wFUn2fq2wB9y62/Ge+UP4m4p2XI6hTnuc8cs0uUaT2I4Rn1ubrkNOLRQdgVcZ3wtbtz6Jq5a+AOw4gjcK9fgKpmRu/nrvWhu7VS+UHaQwkulS/mp+Et/Wjr2IOC4irI74b7O16brejewQ6HMtLLvaX36SF67WLoLz+m571fhQ5oR+zPw3sRLezz23sL6zR3K3t6lrlfhusZnctsuTILng7i/a3bTblpRx2dy399Z2PeVimNuKbYv21ZSdpMktO5OyzQ8OXF+f9feZKHOXVM9j+A9lSco6fkAhzX4X3bAX4qHATuO2I3qRpgsZv/wbOmxrhXxwIU/4j6Qm6dl+6LwI/UG07WZl753ulYXUn/0NDV9zshtm9ah/GJ473tjCj3ktP9G3MAJuRcN7j/aUfDH0nzpZjC6V57R6L50c10KII/MKbUKN6RJzHqRorJ22Q5l29w0JG2A60PfgRuVzsWH2BlrWko3Jp9n52/4Q/FUsa7EPnh0CbQbXXahfB6fp5PP7J8lHYrnf2yJA89cWawkyXS+nPVmWDkBF663W3rKKvihPKRyyNJLxSyn5rMAXFPz/E34Mj68HU/3KLNu1J5vyczKkrR0orYFHfiPfErv25If5t+oyJNa09r+BhuOLMu73S2Cv0iDEaSb8DwYTzLwRmBvG4582Qp3wZlf5uA3QWnMeol7SEZZpqapkj5gZi0O2cnvrsy4dRruU/oRvNdaFIpDN6W5T959HQRn1qay72XrGZNw/dTHcN3rjrTf5BeQooPqGCyA/5FU17ByL55WrJPgBLfwdrT0LgReYWYbjURF1tt8S3VpYkE/ABeWH8XdribiL/My6ljbq7Lg/xNXjwUjyKglBoEh62Ab1iwcM6trBTwV3DMMC8st8F7K2yxNliZPlPEVPPIlc05eBRem/5u9ySU9h/ccMsG3OB4LXZXvMG+VLSa3aDRPeqHeaTacfHfoe4fys6nXm8yszcfi6oiyl9c4cyf+rpbeBU3qmV1p7bN29lLX/mb2E3mi6LZrZAt4SmtJe+AZ909K6zfiKR4NV/8UfZJrWduDhUu3xCAd434rhiK16UVIdqjrQWAbefKSrIfyazO7ulD067jBaw0bjmyagMe5f4M0k2MPw7VN5OGAoj2+fXy+YMPrahXfq6jbm4TuQ+Gb8F5vx1lOFxIfBj4ln9vnWebPVSmLCW9LlUezFHhtSNoKN9xtgF/TQeDJQjs/g6t5MhbDdbBL4S/xNuFJf/wHQY5uw/a605P2hBrErNelhs5tV9z6PfSQmE9S92HczWhSrn21U5E1FLZNrmsnoVwmPD4DXCyptDdZoNtQOGvXp4Br5HHV4K5KtRKmjBTWPPSyExenOtte3smfdH44EReM5+Ejn/cA6xbKLGpm9+bWf2ueuegRFRKpyCdP/D3wOTzib27atTo+egpGiW7ZpFfEFegb4ZNa7Qz808yus2aTl1XxU1xgrYEnr72b6vngRwor65WZJ4ewkm2zJK1aLD+f1L6uZjZoZhPMbGkzG5e+Z+tlva4v4+qF8XgPO1vKuFjSmyr2AbxMngFrUzy2/+q0nIxbqRcakrbNBIuk/SV9az7+lyvKop4kHYT/H/OFmc3GU7k9Z2an4QbDPMsVyh+aW31ZoexE3LD3M9wN7RE8ocw2JaOqYCHSberhxtOTNqRJzPpIcaek91ghF6V8Rs+7Sso3sZ7WYgFf1yaGlW5D4UGGk1XnGUe1QF5QfB/vhW+Ce0X8CHcv266Hug4HLpf0VjP7M5ClFNyvx/ry1LGg31hh3PwghaxilmYASHVugUe6bQ98XtJj1mxm12AE6ZqPTw2mJ+2BJjHrI8VHgV9Ieh+thqXF8dylRZpYT2uzAK/rxZLeVMewUmMo/Dfrn3m555mZJWPLiemle3AvFZnZxemFcYmkPXGL9Za4q8+j89nOOhb0TwAXyBPTZCHCr8Z1n3tW1Ls4HrixTFoeoH1aj2Ah0tHarobTkzY+eYOY9ZFG0o4MZ32/08yuWtDnzJ17gV3X5N61JK7v7GhYkbQtHuzwZOp5bw6cYClFWh3r/sIi6XAvxXWtb8DT4t1m8zH1r6TX4y+s3+PT+HZyRetWVy8W9Pw9OLNsGC6fyvmVuA/qjcANeMam+RXywXzSTXg2mp50RBokfdzMThjpenulpvW0aZ0L/bpWtGMGHpm0MR5N9SNciGyX9r/EhqdgGFUkrYgPq282s98kfef2RfVLzbryExouhr9k8lNaN77+kn6HR+Ddm9an4367SwGnWSGxSoN6L8WnlrkDF/J/oL43RbAAGVU/zzJUmON9tJHPE9NmPbX62eIXKt16k4Wyt5rPLX8EcH8aCvfsk7qwkLQ88HA/CRClydxy6ydmhiBJN5jZVvNRt/De5zZp2Qg3HP3BzEp9pYMFT9O5mxcGI+oONRLUsJ72E9/HjRaZYeUvVOQIBZ5IhpL9gV/LQ0VHIux2xJC0laRrJf1C0maS7sB7YQ9K6qf/oYkFvRHm3IGreS7BE9msRc6tLlj49KPw7JveRCKznk6XdLykT9Cf1y1jXuqRZYaVk6i2jO+N60YPNo/AmogHEfQTJ+IRYWfjblLvN7MVcb3ncaPZsAI3yudsaqHMgt4ESR+TdI6ke/BIsF1xr5C3s+CNq0EHRmXYri4x62bWN7PyyWd0fBDXd34Ct3R+L/VG+45eDSv9OBQG1x2a2abp+x/NbIPcvn4yaL0cz0PwNCUWdPMIuF7q/Rbe0/y9mVXOYBAsfPpO59mPqN787n1BHcNKMoJ9FdebHYsP65fHe9TvMbOq6W8XOlpAOQMWFHUs6MGLgxCeXVBufnczW0MV87v3I1W9yWQE+wLei54MvNnMbpBPVnZ2v/TmoC1BS5achbQ+3sz6SkcbjB36WXfXLxyFO1A/Bj6/Ox5O2lc0NKyMM7PLzec1+rul2RHNrCzCalSxzuGpITiDUaNvdIt9TNn87v3YXT+R4d7k1RR6k6RE1ol8otzibJH9+NuCoO8I4VmBpIvxELu687uPNuOykExJx+R7kwXBDw3S5wVBUE4M26s5DZ/L/W7cKTmb3/1f9Kd/Xe3eZAyFg2D+CYNRByQthScG2QW3SGcXy2wBZxtvShhWgmDhEsP2zjyDC6TF8Bjlvn3TWPPM90EQzAchPCtIFupvAVOAzc3sP10OCYJgDBHD9gok/Qb4kJnNHO22BEHQf4TwDIIg6IGwtgdBEPRACM8gCIIeCOEZBEHQAyE8gyAIeiCEZxAEQQ/8f7vD9l3ZiCDjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(), yticklabels=False, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2'] = df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data has less categories than the train df, so will combine this two dfs to have proper and same categoreis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood',\n",
    "          'Condition2', 'BldgType', 'Condition1', 'HouseStyle', 'SaleType', 'SaleCondition', 'ExterCond', 'ExterQual',\n",
    "          'Foundation', 'BsmtQual', 'BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','RoofStyle','RoofMatl',\n",
    "           'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical',\n",
    "           'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "           'PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    \n",
    "    df_final = final_df\n",
    "    i = 0\n",
    "    \n",
    "    for fields in multcolumns:\n",
    "        print(fields)\n",
    "        df1 = pd.get_dummies(final_df[fields], drop_first=True)\n",
    "        final_df.drop([fields], axis=1, inplace=True)\n",
    "        \n",
    "        if i == 0:\n",
    "            df_final = df1.copy()\n",
    "        else:\n",
    "            df_final = pd.concat([df_final, df1], axis=1)\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    df_final = pd.concat([final_df, df_final], axis=1)\n",
    "    \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining test data\n",
    "test_df = pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df = category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates\n",
    "final_df = final_df.loc[:, ~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1960</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>85</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1994</td>\n",
       "      <td>94.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1454         160         21.0     1936            4            7       1970   \n",
       "1455         160         21.0     1894            4            5       1970   \n",
       "1456          20        160.0    20000            5            7       1960   \n",
       "1457          85         62.0    10441            5            5       1992   \n",
       "1458          60         74.0     9627            7            5       1993   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0             2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1             1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2             2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3             1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4             2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "...            ...         ...         ...         ...  ...   ...   ...  ...   \n",
       "1454          1970         0.0         0.0         0.0  ...     0     0    1   \n",
       "1455          1970         0.0       252.0         0.0  ...     0     0    1   \n",
       "1456          1996         0.0      1224.0         0.0  ...     0     0    1   \n",
       "1457          1992         0.0       337.0         0.0  ...     0     0    1   \n",
       "1458          1994        94.0       758.0         0.0  ...     0     0    1   \n",
       "\n",
       "      Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0          1        0        0        0       0    1  0  \n",
       "1          1        0        0        0       0    1  0  \n",
       "2          1        0        0        0       0    1  0  \n",
       "3          0        0        0        0       1    0  0  \n",
       "4          1        0        0        0       0    1  0  \n",
       "...      ...      ...      ...      ...     ...  ... ..  \n",
       "1454       1        0        0        0       0    0  0  \n",
       "1455       0        0        0        1       0    0  0  \n",
       "1456       0        0        0        0       1    0  0  \n",
       "1457       1        0        0        0       0    0  0  \n",
       "1458       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting it into train and test df \n",
    "df_Train = final_df.iloc[:1422, :]\n",
    "df_Test = final_df.iloc[1422:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          2003       196.0       706.0         0.0  ...     0     0    1   \n",
       "1          1976         0.0       978.0         0.0  ...     0     0    1   \n",
       "2          2002       162.0       486.0         0.0  ...     0     0    1   \n",
       "3          1970         0.0       216.0         0.0  ...     0     0    1   \n",
       "4          2000       350.0       655.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          20         80.0    11622            5            6       1961   \n",
       "1          20         81.0    14267            6            6       1958   \n",
       "2          60         74.0    13830            5            5       1997   \n",
       "3          60         78.0     9978            6            6       1998   \n",
       "4         120         43.0     5005            8            5       1992   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Min1  Min2  Typ  \\\n",
       "0          1961         0.0       468.0       144.0  ...     0     0    1   \n",
       "1          1958       108.0       923.0         0.0  ...     0     0    1   \n",
       "2          1998         0.0       791.0         0.0  ...     0     0    1   \n",
       "3          1998        20.0       602.0         0.0  ...     0     0    1   \n",
       "4          1992         0.0       263.0         0.0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 175)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziiv/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/frame.py:4315: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1459 entries, 0 to 1458\n",
      "Columns: 174 entries, MSSubClass to P\n",
      "dtypes: float64(10), int64(25), uint8(139)\n",
      "memory usage: 608.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_Test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_Train.drop(['SalePrice'], axis=1)\n",
    "y_train = df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and selecting algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "classifier = xgb.XGBRegressor()\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "filename = 'finalized_model_pk1'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129051.695, 150099.22 , 196159.06 , ..., 169300.45 , 108080.62 ,\n",
       "       233303.56 ], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sample submission file and submit \n",
    "\n",
    "pred = pd.DataFrame(y_pred)\n",
    "sub_df = pd.read_csv('sample_submission.csv')\n",
    "datasets = pd.concat([sub_df['Id'], pred], axis=1)\n",
    "datasets.columns = ['Id', 'Saleprice']\n",
    "datasets.to_csv('sample_submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = ['gbtree', 'gblinear']\n",
    "base_score = [0.25, 0.5, 0.75, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter optimization\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500] #level of decision tree\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "learning_rate = [0.05, 0.1, 0.15, 0.20]\n",
    "min_child_weight = [1,2,3,4]\n",
    "\n",
    "#defining the grid of hyperparameters to search \n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth': max_depth,\n",
    "    'learning_rate': learning_rate,\n",
    "    'min_child_weight': min_child_weight,\n",
    "    'booster': booster,\n",
    "    'base_score': base_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seting up random search with 4-fold cross validation \n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_cv = RandomizedSearchCV(estimator=regressor, param_distributions=hyperparameter_grid, cv=5, n_iter=50,\n",
    "                               scoring = 'neg_mean_absolute_error', n_jobs=4, verbose=5, return_train_score = True, \n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n...\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=900, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,colsample_bynode=1, \n",
    "                             colsample_bytree=1, gamma=0, gpu_id=-1, importance_type='gain', \n",
    "                             interaction_constraints='',\n",
    "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
    "             min_child_weight=1, missing=None, monotone_constraints='()',\n",
    "             n_estimators=900, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "             n_estimators=900, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model_pk1'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117275.625, 163568.39 , 188306.14 , ..., 181178.69 , 115435.21 ,\n",
       "       236526.36 ], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating sample submission file\n",
    "\n",
    "pred = pd.DataFrame(y_pred)\n",
    "sub_df = pd.read_csv('sample_submission.csv')\n",
    "datasets = pd.concat([sub_df['Id'], pred], axis=1)\n",
    "datasets.columns = ['Id', 'SalePrice']\n",
    "datasets.to_csv('sample_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.columns = [\"Saleprice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "# y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "114/114 [==============================] - 2s 8ms/step - loss: 193399.8277 - val_loss: 171401.7812\n",
      "Epoch 2/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 146545.7719 - val_loss: 84852.6719\n",
      "Epoch 3/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 72041.0156 - val_loss: 65154.4648\n",
      "Epoch 4/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 59774.5606 - val_loss: 63859.1992\n",
      "Epoch 5/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 73366.3958 - val_loss: 62651.9023\n",
      "Epoch 6/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 61870.7464 - val_loss: 61521.7617\n",
      "Epoch 7/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 61441.8311 - val_loss: 60317.6406\n",
      "Epoch 8/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 58436.2683 - val_loss: 59146.7070\n",
      "Epoch 9/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 58230.6222 - val_loss: 58057.5352\n",
      "Epoch 10/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 50785.7752 - val_loss: 56928.0508\n",
      "Epoch 11/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 55649.2357 - val_loss: 55881.2539\n",
      "Epoch 12/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 52928.6285 - val_loss: 54928.6133\n",
      "Epoch 13/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 50060.4731 - val_loss: 54127.9844\n",
      "Epoch 14/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 51700.8054 - val_loss: 53039.3672\n",
      "Epoch 15/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 47541.9565 - val_loss: 52226.1758\n",
      "Epoch 16/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 44063.4365 - val_loss: 51353.4570\n",
      "Epoch 17/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 47149.8791 - val_loss: 50434.6172\n",
      "Epoch 18/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 47980.4050 - val_loss: 49832.7500\n",
      "Epoch 19/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 42385.0133 - val_loss: 49130.9453\n",
      "Epoch 20/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 43375.6871 - val_loss: 48470.2070\n",
      "Epoch 21/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 40877.6209 - val_loss: 47880.0586\n",
      "Epoch 22/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 39443.1563 - val_loss: 47164.5039\n",
      "Epoch 23/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 42681.3533 - val_loss: 46593.8867\n",
      "Epoch 24/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 37574.6233 - val_loss: 46162.9883\n",
      "Epoch 25/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 39555.0023 - val_loss: 45811.8125\n",
      "Epoch 26/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 38576.7989 - val_loss: 45692.8281\n",
      "Epoch 27/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34661.2744 - val_loss: 46397.6406\n",
      "Epoch 28/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 36649.6520 - val_loss: 45330.4688\n",
      "Epoch 29/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35786.0419 - val_loss: 45217.0469\n",
      "Epoch 30/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36413.7371 - val_loss: 45630.3008\n",
      "Epoch 31/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 35367.2701 - val_loss: 44957.5234\n",
      "Epoch 32/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 35084.4347 - val_loss: 45301.5742\n",
      "Epoch 33/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 35369.7106 - val_loss: 45428.7148\n",
      "Epoch 34/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36806.0425 - val_loss: 44934.1797\n",
      "Epoch 35/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 35555.9485 - val_loss: 44915.7852\n",
      "Epoch 36/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36590.1609 - val_loss: 44980.1523\n",
      "Epoch 37/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33890.6735 - val_loss: 45178.7344\n",
      "Epoch 38/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 36786.4881 - val_loss: 44860.1914\n",
      "Epoch 39/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37993.3903 - val_loss: 45020.1992\n",
      "Epoch 40/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 37890.5880 - val_loss: 44855.9922\n",
      "Epoch 41/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35051.2549 - val_loss: 45420.7812\n",
      "Epoch 42/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36194.6607 - val_loss: 45053.5117\n",
      "Epoch 43/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36562.9953 - val_loss: 45113.2031\n",
      "Epoch 44/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33434.5950 - val_loss: 45479.6875\n",
      "Epoch 45/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36736.1994 - val_loss: 44823.3086\n",
      "Epoch 46/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36554.7043 - val_loss: 44699.9180\n",
      "Epoch 47/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34172.0739 - val_loss: 46068.7305\n",
      "Epoch 48/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 35692.7121 - val_loss: 44785.2617\n",
      "Epoch 49/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37009.2011 - val_loss: 44681.0859\n",
      "Epoch 50/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34935.9256 - val_loss: 44575.7070\n",
      "Epoch 51/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 35988.8981 - val_loss: 45121.4141\n",
      "Epoch 52/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 37949.6412 - val_loss: 44589.0664\n",
      "Epoch 53/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34790.6136 - val_loss: 44522.6719\n",
      "Epoch 54/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 35417.8955 - val_loss: 46625.7461\n",
      "Epoch 55/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34998.9574 - val_loss: 44549.2578\n",
      "Epoch 56/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36754.6568 - val_loss: 44497.2930\n",
      "Epoch 57/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36950.9943 - val_loss: 45038.0781\n",
      "Epoch 58/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34881.7206 - val_loss: 44503.6289\n",
      "Epoch 59/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33604.5297 - val_loss: 44656.2227\n",
      "Epoch 60/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 39405.9560 - val_loss: 44380.0859\n",
      "Epoch 61/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34616.9181 - val_loss: 44383.4414\n",
      "Epoch 62/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 40218.7277 - val_loss: 44556.7109\n",
      "Epoch 63/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34647.9019 - val_loss: 44704.2188\n",
      "Epoch 64/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34786.3077 - val_loss: 44796.3750\n",
      "Epoch 65/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34097.9090 - val_loss: 44511.7773\n",
      "Epoch 66/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33326.6347 - val_loss: 44860.0312\n",
      "Epoch 67/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 35427.5207 - val_loss: 44702.2500\n",
      "Epoch 68/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 32104.6748 - val_loss: 44345.6367\n",
      "Epoch 69/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34725.0225 - val_loss: 44492.7773\n",
      "Epoch 70/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 32240.0065 - val_loss: 45223.1797\n",
      "Epoch 71/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33426.4590 - val_loss: 44392.8164\n",
      "Epoch 72/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36877.9265 - val_loss: 44396.4258\n",
      "Epoch 73/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33572.8790 - val_loss: 44616.4570\n",
      "Epoch 74/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33265.2682 - val_loss: 44422.4961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35080.2934 - val_loss: 44323.4102\n",
      "Epoch 76/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 36066.1225 - val_loss: 44820.2930\n",
      "Epoch 77/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33314.0863 - val_loss: 44461.8477\n",
      "Epoch 78/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34574.7445 - val_loss: 44281.6875\n",
      "Epoch 79/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33536.7725 - val_loss: 44265.1953\n",
      "Epoch 80/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32850.1844 - val_loss: 44320.3086\n",
      "Epoch 81/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34200.5260 - val_loss: 44532.5117\n",
      "Epoch 82/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34845.6015 - val_loss: 44447.2969\n",
      "Epoch 83/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35583.0653 - val_loss: 44341.0469\n",
      "Epoch 84/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 37039.7455 - val_loss: 44399.9297\n",
      "Epoch 85/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33497.7750 - val_loss: 45126.0391\n",
      "Epoch 86/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34105.6774 - val_loss: 44999.3945\n",
      "Epoch 87/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34229.1779 - val_loss: 45362.5352\n",
      "Epoch 88/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32131.7677 - val_loss: 44202.5000\n",
      "Epoch 89/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32945.0733 - val_loss: 44382.3984\n",
      "Epoch 90/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32766.4193 - val_loss: 44329.8398\n",
      "Epoch 91/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32587.5525 - val_loss: 44194.3984\n",
      "Epoch 92/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34351.3748 - val_loss: 44310.5898\n",
      "Epoch 93/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33664.8897 - val_loss: 44237.3281\n",
      "Epoch 94/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35820.0595 - val_loss: 44593.4141\n",
      "Epoch 95/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33400.3754 - val_loss: 44208.2812\n",
      "Epoch 96/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35678.5181 - val_loss: 44223.3984\n",
      "Epoch 97/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 37229.6072 - val_loss: 44180.4492\n",
      "Epoch 98/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32498.5333 - val_loss: 44377.4492\n",
      "Epoch 99/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33290.0714 - val_loss: 44529.2305\n",
      "Epoch 100/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33106.7507 - val_loss: 44529.7109\n",
      "Epoch 101/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35393.4271 - val_loss: 44325.5156\n",
      "Epoch 102/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34157.4135 - val_loss: 44304.2812\n",
      "Epoch 103/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34901.4656 - val_loss: 44262.1836\n",
      "Epoch 104/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35658.7435 - val_loss: 44154.3164\n",
      "Epoch 105/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34739.0577 - val_loss: 44586.0703\n",
      "Epoch 106/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34421.0236 - val_loss: 44674.2070\n",
      "Epoch 107/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32840.7567 - val_loss: 44077.8555\n",
      "Epoch 108/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34588.6486 - val_loss: 44874.4062\n",
      "Epoch 109/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33911.5724 - val_loss: 44161.3008\n",
      "Epoch 110/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35046.9263 - val_loss: 44560.1797\n",
      "Epoch 111/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31004.3385 - val_loss: 44195.1953\n",
      "Epoch 112/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33062.2414 - val_loss: 45140.9648\n",
      "Epoch 113/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33619.0929 - val_loss: 44445.9102\n",
      "Epoch 114/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34027.2972 - val_loss: 44217.2695\n",
      "Epoch 115/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31461.4791 - val_loss: 44148.0508\n",
      "Epoch 116/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32409.5290 - val_loss: 44394.6016\n",
      "Epoch 117/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35009.9946 - val_loss: 44090.9648\n",
      "Epoch 118/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35241.3913 - val_loss: 43981.8242\n",
      "Epoch 119/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35826.3122 - val_loss: 43992.1211\n",
      "Epoch 120/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33391.6542 - val_loss: 44012.5195\n",
      "Epoch 121/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32385.7426 - val_loss: 43924.1914\n",
      "Epoch 122/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34162.4655 - val_loss: 44104.1562\n",
      "Epoch 123/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 36640.4842 - val_loss: 44626.3828\n",
      "Epoch 124/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31258.3033 - val_loss: 44101.1953\n",
      "Epoch 125/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33656.2603 - val_loss: 44219.1523\n",
      "Epoch 126/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33273.8693 - val_loss: 43983.7031\n",
      "Epoch 127/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 32795.6895 - val_loss: 44470.0039\n",
      "Epoch 128/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 30524.8593 - val_loss: 43964.1172\n",
      "Epoch 129/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 31827.1987 - val_loss: 44309.8164\n",
      "Epoch 130/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32702.2630 - val_loss: 43829.5273\n",
      "Epoch 131/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33374.3880 - val_loss: 44279.3906\n",
      "Epoch 132/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33002.7541 - val_loss: 43875.9492\n",
      "Epoch 133/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31636.5464 - val_loss: 44067.0703\n",
      "Epoch 134/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 36073.3591 - val_loss: 43938.2461\n",
      "Epoch 135/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 31888.2647 - val_loss: 44178.1953\n",
      "Epoch 136/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31205.3539 - val_loss: 43959.5391\n",
      "Epoch 137/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32468.7543 - val_loss: 44256.8438\n",
      "Epoch 138/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33442.8388 - val_loss: 43983.5430\n",
      "Epoch 139/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31384.3921 - val_loss: 43901.4961\n",
      "Epoch 140/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 32461.5065 - val_loss: 44045.0156\n",
      "Epoch 141/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33497.6945 - val_loss: 44705.9805\n",
      "Epoch 142/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32056.1847 - val_loss: 44482.5312\n",
      "Epoch 143/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33611.6481 - val_loss: 44144.6250\n",
      "Epoch 144/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33092.2694 - val_loss: 44213.1445\n",
      "Epoch 145/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33354.5472 - val_loss: 45293.5430\n",
      "Epoch 146/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34609.9861 - val_loss: 44929.8438\n",
      "Epoch 147/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32356.4887 - val_loss: 44199.1484\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 32510.1176 - val_loss: 43996.0391\n",
      "Epoch 149/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32910.5993 - val_loss: 44401.6719\n",
      "Epoch 150/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32567.4715 - val_loss: 43999.4766\n",
      "Epoch 151/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32444.3946 - val_loss: 43929.1914\n",
      "Epoch 152/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33746.5704 - val_loss: 43903.8008\n",
      "Epoch 153/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32194.2009 - val_loss: 43936.2617\n",
      "Epoch 154/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32760.0374 - val_loss: 44092.8398\n",
      "Epoch 155/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31278.9008 - val_loss: 44043.1914\n",
      "Epoch 156/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33278.4946 - val_loss: 44224.1641\n",
      "Epoch 157/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34256.5572 - val_loss: 44009.1484\n",
      "Epoch 158/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34337.4820 - val_loss: 43884.2969\n",
      "Epoch 159/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31761.2176 - val_loss: 43870.8242\n",
      "Epoch 160/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32144.5258 - val_loss: 44647.4258\n",
      "Epoch 161/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31436.7082 - val_loss: 44793.7383\n",
      "Epoch 162/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29791.3523 - val_loss: 44058.2383\n",
      "Epoch 163/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29997.7132 - val_loss: 43929.9844\n",
      "Epoch 164/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29970.5135 - val_loss: 43929.9844\n",
      "Epoch 165/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31957.8808 - val_loss: 43924.3164\n",
      "Epoch 166/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30002.7317 - val_loss: 44367.1367\n",
      "Epoch 167/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30302.1336 - val_loss: 43991.1484\n",
      "Epoch 168/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33030.6560 - val_loss: 43952.5742\n",
      "Epoch 169/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32715.1005 - val_loss: 44026.0898\n",
      "Epoch 170/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32939.6867 - val_loss: 44039.7773\n",
      "Epoch 171/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31150.4691 - val_loss: 44048.7383\n",
      "Epoch 172/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33832.4471 - val_loss: 44608.0430\n",
      "Epoch 173/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32864.4169 - val_loss: 43988.2461\n",
      "Epoch 174/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35060.9633 - val_loss: 44358.1562\n",
      "Epoch 175/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32452.4337 - val_loss: 43953.2617\n",
      "Epoch 176/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33804.8331 - val_loss: 44292.5781\n",
      "Epoch 177/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31581.2607 - val_loss: 44616.8438\n",
      "Epoch 178/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32033.2919 - val_loss: 44216.7383\n",
      "Epoch 179/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31717.0291 - val_loss: 44263.6719\n",
      "Epoch 180/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31123.6914 - val_loss: 44653.1523\n",
      "Epoch 181/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34155.3490 - val_loss: 44217.0664\n",
      "Epoch 182/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32354.5493 - val_loss: 44648.3750\n",
      "Epoch 183/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33903.9169 - val_loss: 44292.8672\n",
      "Epoch 184/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33951.9502 - val_loss: 44295.2305\n",
      "Epoch 185/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 32337.1948 - val_loss: 44898.4805\n",
      "Epoch 186/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35179.4845 - val_loss: 44080.5938\n",
      "Epoch 187/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32435.6952 - val_loss: 44243.5586\n",
      "Epoch 188/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32924.6424 - val_loss: 44275.4258\n",
      "Epoch 189/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32943.2429 - val_loss: 44155.4141\n",
      "Epoch 190/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30763.6403 - val_loss: 44697.0430\n",
      "Epoch 191/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34470.0395 - val_loss: 44634.7734\n",
      "Epoch 192/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32827.9185 - val_loss: 44865.4922\n",
      "Epoch 193/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31153.4961 - val_loss: 45118.2891\n",
      "Epoch 194/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 36429.8228 - val_loss: 44109.6602\n",
      "Epoch 195/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31336.2883 - val_loss: 44741.7695\n",
      "Epoch 196/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32730.7808 - val_loss: 44922.3320\n",
      "Epoch 197/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29730.7170 - val_loss: 44587.9336\n",
      "Epoch 198/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29634.2691 - val_loss: 44869.5859\n",
      "Epoch 199/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30210.4278 - val_loss: 44472.2930\n",
      "Epoch 200/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31380.1676 - val_loss: 44849.0078\n",
      "Epoch 201/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33329.3462 - val_loss: 44330.6367\n",
      "Epoch 202/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30452.4370 - val_loss: 44392.1172\n",
      "Epoch 203/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31626.4736 - val_loss: 44242.8086\n",
      "Epoch 204/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30018.2062 - val_loss: 44188.5547\n",
      "Epoch 205/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32991.4483 - val_loss: 44390.0938\n",
      "Epoch 206/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32288.0032 - val_loss: 44458.1719\n",
      "Epoch 207/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31944.2180 - val_loss: 44114.2773\n",
      "Epoch 208/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30421.9922 - val_loss: 44028.3750\n",
      "Epoch 209/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30543.9819 - val_loss: 44432.6172\n",
      "Epoch 210/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29237.6052 - val_loss: 44210.3867\n",
      "Epoch 211/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30752.1303 - val_loss: 44417.5938\n",
      "Epoch 212/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30655.6558 - val_loss: 45301.8320\n",
      "Epoch 213/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31080.7401 - val_loss: 44766.8438\n",
      "Epoch 214/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31552.8521 - val_loss: 44567.1758\n",
      "Epoch 215/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31691.8283 - val_loss: 44150.1562\n",
      "Epoch 216/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31182.1529 - val_loss: 44170.8633\n",
      "Epoch 217/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32015.3992 - val_loss: 44163.6289\n",
      "Epoch 218/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 35864.1429 - val_loss: 44221.3555\n",
      "Epoch 219/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 31307.7616 - val_loss: 45476.5820\n",
      "Epoch 220/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 32299.7293 - val_loss: 44412.6719\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 30335.4639 - val_loss: 44410.6445\n",
      "Epoch 222/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31085.9273 - val_loss: 44266.5508\n",
      "Epoch 223/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31438.2405 - val_loss: 44547.4375\n",
      "Epoch 224/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29617.8535 - val_loss: 44374.7070\n",
      "Epoch 225/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28144.3164 - val_loss: 44514.7617\n",
      "Epoch 226/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29706.7497 - val_loss: 44355.1172\n",
      "Epoch 227/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28682.7171 - val_loss: 44369.8398\n",
      "Epoch 228/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31999.5001 - val_loss: 44134.5703\n",
      "Epoch 229/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32353.8941 - val_loss: 44230.1328\n",
      "Epoch 230/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30922.4415 - val_loss: 44138.1914\n",
      "Epoch 231/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32210.3031 - val_loss: 44181.5234\n",
      "Epoch 232/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33754.7160 - val_loss: 44967.7578\n",
      "Epoch 233/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30354.9474 - val_loss: 44460.2148\n",
      "Epoch 234/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29925.6645 - val_loss: 44601.3789\n",
      "Epoch 235/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30264.5367 - val_loss: 44352.6016\n",
      "Epoch 236/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30668.4659 - val_loss: 44159.7773\n",
      "Epoch 237/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29523.5675 - val_loss: 44740.4609\n",
      "Epoch 238/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29764.9064 - val_loss: 44132.6172\n",
      "Epoch 239/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34421.1424 - val_loss: 44395.9688\n",
      "Epoch 240/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31999.3876 - val_loss: 44442.3398\n",
      "Epoch 241/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31484.1277 - val_loss: 44229.6758\n",
      "Epoch 242/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34593.9803 - val_loss: 44696.4023\n",
      "Epoch 243/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29905.0275 - val_loss: 44222.8789\n",
      "Epoch 244/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30900.6379 - val_loss: 44913.3477\n",
      "Epoch 245/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28980.8163 - val_loss: 44584.5078\n",
      "Epoch 246/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32921.3256 - val_loss: 45146.4531\n",
      "Epoch 247/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29290.8178 - val_loss: 44225.4570\n",
      "Epoch 248/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29483.4150 - val_loss: 44499.7969\n",
      "Epoch 249/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31279.8369 - val_loss: 44101.4961\n",
      "Epoch 250/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31949.1040 - val_loss: 44869.1445\n",
      "Epoch 251/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30903.1131 - val_loss: 44193.8672\n",
      "Epoch 252/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29931.8833 - val_loss: 44744.1172\n",
      "Epoch 253/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30564.5815 - val_loss: 44104.1914\n",
      "Epoch 254/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30533.4802 - val_loss: 44081.9336\n",
      "Epoch 255/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33809.3864 - val_loss: 44353.4297\n",
      "Epoch 256/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31577.4875 - val_loss: 45292.0312\n",
      "Epoch 257/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29065.1287 - val_loss: 44289.1406\n",
      "Epoch 258/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31607.3168 - val_loss: 44141.7969\n",
      "Epoch 259/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 30487.4088 - val_loss: 44053.1484\n",
      "Epoch 260/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30807.6528 - val_loss: 44214.5117\n",
      "Epoch 261/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31463.5251 - val_loss: 44422.5469\n",
      "Epoch 262/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31982.6137 - val_loss: 44249.7852\n",
      "Epoch 263/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29679.0984 - val_loss: 44095.8125\n",
      "Epoch 264/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29071.5462 - val_loss: 44218.2930\n",
      "Epoch 265/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28322.6026 - val_loss: 46111.5352\n",
      "Epoch 266/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30819.7708 - val_loss: 44313.9570\n",
      "Epoch 267/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 34497.4966 - val_loss: 45690.2148\n",
      "Epoch 268/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30714.3663 - val_loss: 44232.8398\n",
      "Epoch 269/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30404.9313 - val_loss: 44294.2422\n",
      "Epoch 270/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28086.9425 - val_loss: 44644.8359\n",
      "Epoch 271/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31788.0019 - val_loss: 44523.5781\n",
      "Epoch 272/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29015.2484 - val_loss: 44657.3320\n",
      "Epoch 273/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27734.5953 - val_loss: 44109.8594\n",
      "Epoch 274/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30544.2755 - val_loss: 44163.2539\n",
      "Epoch 275/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29964.4437 - val_loss: 43997.8047\n",
      "Epoch 276/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30905.2992 - val_loss: 44351.8438\n",
      "Epoch 277/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29196.4599 - val_loss: 43951.9375\n",
      "Epoch 278/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30162.0404 - val_loss: 44274.9258\n",
      "Epoch 279/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32835.6315 - val_loss: 44501.4062\n",
      "Epoch 280/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28445.7612 - val_loss: 44071.1211\n",
      "Epoch 281/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30499.5556 - val_loss: 44654.1680\n",
      "Epoch 282/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29983.9898 - val_loss: 44766.3477\n",
      "Epoch 283/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29396.8425 - val_loss: 43922.4219\n",
      "Epoch 284/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30186.5405 - val_loss: 43827.0391\n",
      "Epoch 285/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 30080.2207 - val_loss: 44201.0703\n",
      "Epoch 286/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28895.7062 - val_loss: 44155.7070\n",
      "Epoch 287/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27936.4417 - val_loss: 44378.8945\n",
      "Epoch 288/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29531.8892 - val_loss: 44165.5156\n",
      "Epoch 289/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29103.3330 - val_loss: 43799.6289\n",
      "Epoch 290/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30540.2108 - val_loss: 44828.5781\n",
      "Epoch 291/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33843.0502 - val_loss: 44514.8789\n",
      "Epoch 292/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29576.4016 - val_loss: 44010.9922\n",
      "Epoch 293/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 33616.3377 - val_loss: 43863.4141\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 3ms/step - loss: 28694.7793 - val_loss: 43993.9336\n",
      "Epoch 295/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31942.3948 - val_loss: 44403.4219\n",
      "Epoch 296/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29214.0696 - val_loss: 43924.8086\n",
      "Epoch 297/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29051.1627 - val_loss: 43870.6641\n",
      "Epoch 298/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28523.5789 - val_loss: 43986.6250\n",
      "Epoch 299/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 30924.0210 - val_loss: 43819.6758\n",
      "Epoch 300/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 31909.7061 - val_loss: 44069.5352\n",
      "Epoch 301/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29262.1674 - val_loss: 43791.8125\n",
      "Epoch 302/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29469.5552 - val_loss: 43665.1680\n",
      "Epoch 303/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29568.2414 - val_loss: 43638.6758\n",
      "Epoch 304/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 29383.2685 - val_loss: 43829.9023\n",
      "Epoch 305/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 31313.7097 - val_loss: 44525.2383\n",
      "Epoch 306/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28184.8658 - val_loss: 44039.4727\n",
      "Epoch 307/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29441.6463 - val_loss: 43834.6211\n",
      "Epoch 308/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30715.0351 - val_loss: 43524.8359\n",
      "Epoch 309/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30286.9282 - val_loss: 44070.7461\n",
      "Epoch 310/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29545.5785 - val_loss: 43744.6367\n",
      "Epoch 311/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29744.6803 - val_loss: 43561.2969\n",
      "Epoch 312/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28497.7691 - val_loss: 44603.0703\n",
      "Epoch 313/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29424.1726 - val_loss: 43551.2852\n",
      "Epoch 314/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29346.3008 - val_loss: 43727.0586\n",
      "Epoch 315/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32136.1580 - val_loss: 43555.6641\n",
      "Epoch 316/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 30672.4923 - val_loss: 43675.1016\n",
      "Epoch 317/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 30685.2947 - val_loss: 44168.2930\n",
      "Epoch 318/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31748.5384 - val_loss: 44199.7070\n",
      "Epoch 319/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 34471.8538 - val_loss: 43891.2188\n",
      "Epoch 320/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28714.1821 - val_loss: 44135.0078\n",
      "Epoch 321/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 32056.1008 - val_loss: 43614.9453\n",
      "Epoch 322/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28217.0537 - val_loss: 43605.8359\n",
      "Epoch 323/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30931.9826 - val_loss: 43509.4453\n",
      "Epoch 324/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 33038.2559 - val_loss: 44027.6172\n",
      "Epoch 325/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 32399.2950 - val_loss: 44239.6445\n",
      "Epoch 326/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27500.8221 - val_loss: 43670.9531\n",
      "Epoch 327/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28199.1426 - val_loss: 44641.7695\n",
      "Epoch 328/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31176.7096 - val_loss: 43579.1562\n",
      "Epoch 329/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30213.1491 - val_loss: 43552.7031\n",
      "Epoch 330/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28114.7527 - val_loss: 44173.3359\n",
      "Epoch 331/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27664.6241 - val_loss: 44541.1484\n",
      "Epoch 332/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29291.8936 - val_loss: 44162.6562\n",
      "Epoch 333/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29561.9025 - val_loss: 43796.8906\n",
      "Epoch 334/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 30138.2726 - val_loss: 43527.1484\n",
      "Epoch 335/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 28046.9788 - val_loss: 43662.0859\n",
      "Epoch 336/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28399.3716 - val_loss: 43810.7500\n",
      "Epoch 337/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 30574.0853 - val_loss: 44210.5352\n",
      "Epoch 338/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29909.5779 - val_loss: 43683.2617\n",
      "Epoch 339/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 34283.0814 - val_loss: 43591.3750\n",
      "Epoch 340/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27683.7145 - val_loss: 43653.6953\n",
      "Epoch 341/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 29109.4035 - val_loss: 43987.9102\n",
      "Epoch 342/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 30010.7481 - val_loss: 44717.9219\n",
      "Epoch 343/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26689.1026 - val_loss: 43660.5625\n",
      "Epoch 344/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 29904.8893 - val_loss: 43870.8438\n",
      "Epoch 345/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 27485.2722 - val_loss: 43323.3242\n",
      "Epoch 346/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28601.4580 - val_loss: 43448.6680\n",
      "Epoch 347/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 28556.0551 - val_loss: 43324.9492\n",
      "Epoch 348/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27839.5777 - val_loss: 43387.3984\n",
      "Epoch 349/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27582.8255 - val_loss: 43234.2031\n",
      "Epoch 350/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 28102.3640 - val_loss: 43360.4805\n",
      "Epoch 351/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28506.6147 - val_loss: 43353.5703\n",
      "Epoch 352/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 27838.0646 - val_loss: 43542.2539\n",
      "Epoch 353/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28420.2588 - val_loss: 44085.1758\n",
      "Epoch 354/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28832.2826 - val_loss: 43417.7578\n",
      "Epoch 355/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 29000.5816 - val_loss: 43533.0508\n",
      "Epoch 356/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 31128.7872 - val_loss: 43321.2227\n",
      "Epoch 357/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 27062.9260 - val_loss: 43571.0430\n",
      "Epoch 358/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 31684.4964 - val_loss: 43645.4023\n",
      "Epoch 359/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 26880.2872 - val_loss: 43380.4531\n",
      "Epoch 360/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28758.6084 - val_loss: 43502.9492\n",
      "Epoch 361/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27607.1766 - val_loss: 44339.5156\n",
      "Epoch 362/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28081.7596 - val_loss: 43696.7500\n",
      "Epoch 363/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26479.0992 - val_loss: 43380.0312\n",
      "Epoch 364/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 31613.0362 - val_loss: 45145.5859\n",
      "Epoch 365/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27585.7609 - val_loss: 43109.8477\n",
      "Epoch 366/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26794.8429 - val_loss: 43345.6797\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 3ms/step - loss: 28367.2664 - val_loss: 43644.5469\n",
      "Epoch 368/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27766.9655 - val_loss: 43818.4648\n",
      "Epoch 369/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29584.7542 - val_loss: 43191.1758\n",
      "Epoch 370/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24927.8333 - val_loss: 43164.5352\n",
      "Epoch 371/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28305.9463 - val_loss: 43353.8789\n",
      "Epoch 372/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29420.8798 - val_loss: 43154.6133\n",
      "Epoch 373/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25859.9391 - val_loss: 43020.6211\n",
      "Epoch 374/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27585.1949 - val_loss: 43232.0898\n",
      "Epoch 375/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27258.9766 - val_loss: 43075.6641\n",
      "Epoch 376/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 32841.9593 - val_loss: 43339.3398\n",
      "Epoch 377/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29400.8478 - val_loss: 43029.2969\n",
      "Epoch 378/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27519.0789 - val_loss: 43557.7695\n",
      "Epoch 379/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27518.2262 - val_loss: 43202.0781\n",
      "Epoch 380/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26550.9123 - val_loss: 42939.5195\n",
      "Epoch 381/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28479.7343 - val_loss: 43855.1914\n",
      "Epoch 382/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28986.9711 - val_loss: 43042.7031\n",
      "Epoch 383/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 26331.2947 - val_loss: 43595.8516\n",
      "Epoch 384/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26018.1592 - val_loss: 42949.4492\n",
      "Epoch 385/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 27346.7422 - val_loss: 42971.6602\n",
      "Epoch 386/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26529.4701 - val_loss: 43263.3750\n",
      "Epoch 387/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 31068.4801 - val_loss: 42847.4023\n",
      "Epoch 388/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27427.9342 - val_loss: 42991.0352\n",
      "Epoch 389/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27910.5962 - val_loss: 43236.8789\n",
      "Epoch 390/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26389.1833 - val_loss: 42872.6172\n",
      "Epoch 391/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26153.5183 - val_loss: 43002.0898\n",
      "Epoch 392/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27937.1708 - val_loss: 42798.8359\n",
      "Epoch 393/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27267.5967 - val_loss: 44188.8516\n",
      "Epoch 394/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26881.7936 - val_loss: 42763.5156\n",
      "Epoch 395/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27218.3340 - val_loss: 43002.7422\n",
      "Epoch 396/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28667.4912 - val_loss: 42895.6367\n",
      "Epoch 397/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 30721.4986 - val_loss: 42880.7734\n",
      "Epoch 398/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29118.8800 - val_loss: 42793.6367\n",
      "Epoch 399/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27432.4606 - val_loss: 43082.0195\n",
      "Epoch 400/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29844.9917 - val_loss: 43109.3281\n",
      "Epoch 401/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27430.1146 - val_loss: 42820.1055\n",
      "Epoch 402/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27719.8799 - val_loss: 42820.7422\n",
      "Epoch 403/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26202.0370 - val_loss: 43677.8477\n",
      "Epoch 404/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29064.5438 - val_loss: 42727.6445\n",
      "Epoch 405/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29918.7377 - val_loss: 43339.9609\n",
      "Epoch 406/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27478.8771 - val_loss: 43664.6953\n",
      "Epoch 407/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28451.6811 - val_loss: 42803.7695\n",
      "Epoch 408/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26000.0784 - val_loss: 43099.3555\n",
      "Epoch 409/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26048.0560 - val_loss: 42572.8242\n",
      "Epoch 410/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27362.4096 - val_loss: 42633.7812\n",
      "Epoch 411/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28691.4470 - val_loss: 42722.3320\n",
      "Epoch 412/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27789.8413 - val_loss: 42571.8672\n",
      "Epoch 413/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27446.8283 - val_loss: 42848.5078\n",
      "Epoch 414/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26702.6224 - val_loss: 42891.8320\n",
      "Epoch 415/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29426.5904 - val_loss: 42724.6367\n",
      "Epoch 416/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 26204.2296 - val_loss: 44623.3945\n",
      "Epoch 417/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26550.6483 - val_loss: 43063.5312\n",
      "Epoch 418/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 28370.6383 - val_loss: 42591.0195\n",
      "Epoch 419/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25111.7622 - val_loss: 43153.0625\n",
      "Epoch 420/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 26764.5092 - val_loss: 42746.3984\n",
      "Epoch 421/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25837.0931 - val_loss: 44241.6875\n",
      "Epoch 422/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 28823.8778 - val_loss: 42546.1484\n",
      "Epoch 423/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26044.3606 - val_loss: 42689.4922\n",
      "Epoch 424/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28673.5471 - val_loss: 42470.2188\n",
      "Epoch 425/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 27972.1050 - val_loss: 42840.1250\n",
      "Epoch 426/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27566.3724 - val_loss: 43132.2930\n",
      "Epoch 427/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25875.1310 - val_loss: 42708.8203\n",
      "Epoch 428/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27405.8770 - val_loss: 42337.3555\n",
      "Epoch 429/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 30480.4447 - val_loss: 42326.5625\n",
      "Epoch 430/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27580.4376 - val_loss: 42856.9844\n",
      "Epoch 431/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28148.5385 - val_loss: 42766.2969\n",
      "Epoch 432/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25746.4955 - val_loss: 43448.8203\n",
      "Epoch 433/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26879.4518 - val_loss: 42840.8789\n",
      "Epoch 434/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 29144.2724 - val_loss: 42152.7305\n",
      "Epoch 435/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27236.7717 - val_loss: 42181.1406\n",
      "Epoch 436/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27392.6108 - val_loss: 42317.1992\n",
      "Epoch 437/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26007.2409 - val_loss: 42227.4336\n",
      "Epoch 438/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24435.5724 - val_loss: 42224.3867\n",
      "Epoch 439/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 31704.0630 - val_loss: 42553.0586\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 28011.6451 - val_loss: 42583.4805\n",
      "Epoch 441/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27174.2056 - val_loss: 42344.4570\n",
      "Epoch 442/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26972.9197 - val_loss: 42097.1094\n",
      "Epoch 443/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27525.9839 - val_loss: 42025.7266\n",
      "Epoch 444/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28257.0994 - val_loss: 42163.4648\n",
      "Epoch 445/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 30809.6077 - val_loss: 42108.1992\n",
      "Epoch 446/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26984.8667 - val_loss: 42210.6250\n",
      "Epoch 447/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25618.1553 - val_loss: 42209.7461\n",
      "Epoch 448/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27643.4833 - val_loss: 42073.8281\n",
      "Epoch 449/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27036.7945 - val_loss: 42196.8555\n",
      "Epoch 450/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27411.5286 - val_loss: 41947.7227\n",
      "Epoch 451/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26854.0279 - val_loss: 42588.6172\n",
      "Epoch 452/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27380.5431 - val_loss: 42114.6406\n",
      "Epoch 453/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26839.4140 - val_loss: 41823.0586\n",
      "Epoch 454/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26091.4511 - val_loss: 41941.6562\n",
      "Epoch 455/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25543.6622 - val_loss: 42137.0352\n",
      "Epoch 456/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25820.7580 - val_loss: 43583.1016\n",
      "Epoch 457/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26826.9637 - val_loss: 41895.9531\n",
      "Epoch 458/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27429.4895 - val_loss: 41990.8203\n",
      "Epoch 459/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26508.1430 - val_loss: 41865.5898\n",
      "Epoch 460/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25547.8467 - val_loss: 42465.9961\n",
      "Epoch 461/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27182.6548 - val_loss: 43737.9180\n",
      "Epoch 462/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25914.6426 - val_loss: 42487.2422\n",
      "Epoch 463/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25519.2528 - val_loss: 41997.7266\n",
      "Epoch 464/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25897.1296 - val_loss: 42063.4414\n",
      "Epoch 465/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24630.6983 - val_loss: 41795.8398\n",
      "Epoch 466/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28166.2013 - val_loss: 42485.8398\n",
      "Epoch 467/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25293.4562 - val_loss: 41711.5352\n",
      "Epoch 468/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29254.3189 - val_loss: 41705.2930\n",
      "Epoch 469/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25531.5450 - val_loss: 41508.4336\n",
      "Epoch 470/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23469.9892 - val_loss: 42737.9414\n",
      "Epoch 471/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25971.8894 - val_loss: 41774.8594\n",
      "Epoch 472/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26686.5928 - val_loss: 42568.4648\n",
      "Epoch 473/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24963.7034 - val_loss: 41606.4062\n",
      "Epoch 474/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27218.4728 - val_loss: 44460.8750\n",
      "Epoch 475/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24485.3831 - val_loss: 42174.7773\n",
      "Epoch 476/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25947.0787 - val_loss: 41577.3945\n",
      "Epoch 477/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24895.7722 - val_loss: 43590.4141\n",
      "Epoch 478/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24832.8073 - val_loss: 41387.5898\n",
      "Epoch 479/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26990.5888 - val_loss: 41486.2539\n",
      "Epoch 480/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26089.9110 - val_loss: 41475.5625\n",
      "Epoch 481/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23019.6300 - val_loss: 41413.3477\n",
      "Epoch 482/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25206.1690 - val_loss: 41380.4023\n",
      "Epoch 483/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26270.9819 - val_loss: 41338.9844\n",
      "Epoch 484/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26706.3584 - val_loss: 41443.8867\n",
      "Epoch 485/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25896.4405 - val_loss: 41873.1836\n",
      "Epoch 486/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28076.9208 - val_loss: 41144.5000\n",
      "Epoch 487/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23767.9202 - val_loss: 41407.4922\n",
      "Epoch 488/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24583.5961 - val_loss: 41781.6719\n",
      "Epoch 489/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 28447.1898 - val_loss: 41168.0000\n",
      "Epoch 490/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27157.1910 - val_loss: 41147.5977\n",
      "Epoch 491/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25233.7862 - val_loss: 41711.0859\n",
      "Epoch 492/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24493.7313 - val_loss: 41352.0117\n",
      "Epoch 493/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25293.4902 - val_loss: 41115.9453\n",
      "Epoch 494/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23195.4198 - val_loss: 41294.1641\n",
      "Epoch 495/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26512.7113 - val_loss: 43492.3359\n",
      "Epoch 496/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24658.2748 - val_loss: 41071.2617\n",
      "Epoch 497/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27715.8361 - val_loss: 41583.1406\n",
      "Epoch 498/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23606.4132 - val_loss: 41120.0156\n",
      "Epoch 499/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24881.2283 - val_loss: 41085.4688\n",
      "Epoch 500/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25137.4290 - val_loss: 41347.1914\n",
      "Epoch 501/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23152.7175 - val_loss: 41146.7461\n",
      "Epoch 502/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25512.7724 - val_loss: 41050.1328\n",
      "Epoch 503/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24793.7682 - val_loss: 41249.8945\n",
      "Epoch 504/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24818.6036 - val_loss: 41197.1562\n",
      "Epoch 505/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23166.4548 - val_loss: 41068.9688\n",
      "Epoch 506/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24829.8270 - val_loss: 41243.4414\n",
      "Epoch 507/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24468.3133 - val_loss: 40927.0703\n",
      "Epoch 508/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24761.1624 - val_loss: 40689.6172\n",
      "Epoch 509/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23855.3119 - val_loss: 41029.3867\n",
      "Epoch 510/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25682.3888 - val_loss: 42356.5117\n",
      "Epoch 511/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25925.2572 - val_loss: 40814.9531\n",
      "Epoch 512/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27578.2126 - val_loss: 41178.6953\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 1s 6ms/step - loss: 23939.6252 - val_loss: 41659.0430\n",
      "Epoch 514/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24220.2011 - val_loss: 42073.7344\n",
      "Epoch 515/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 26375.6036 - val_loss: 40823.4219\n",
      "Epoch 516/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 22261.2714 - val_loss: 41676.5391\n",
      "Epoch 517/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25343.9182 - val_loss: 40793.0742\n",
      "Epoch 518/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24724.4340 - val_loss: 41077.5352\n",
      "Epoch 519/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22863.8475 - val_loss: 40731.2930\n",
      "Epoch 520/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23672.9871 - val_loss: 40540.5664\n",
      "Epoch 521/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24416.6600 - val_loss: 40385.4922\n",
      "Epoch 522/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24360.9680 - val_loss: 40328.7812\n",
      "Epoch 523/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24630.6652 - val_loss: 40605.1016\n",
      "Epoch 524/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24381.8661 - val_loss: 40418.4688\n",
      "Epoch 525/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24334.3870 - val_loss: 40494.3555\n",
      "Epoch 526/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23956.1403 - val_loss: 40212.1719\n",
      "Epoch 527/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23718.9110 - val_loss: 40327.8164\n",
      "Epoch 528/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22390.8688 - val_loss: 40447.2422\n",
      "Epoch 529/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24624.7996 - val_loss: 40140.6523\n",
      "Epoch 530/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24842.3706 - val_loss: 40203.7383\n",
      "Epoch 531/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26258.6366 - val_loss: 41087.6719\n",
      "Epoch 532/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23100.7702 - val_loss: 40753.2891\n",
      "Epoch 533/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24562.2306 - val_loss: 40754.5664\n",
      "Epoch 534/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23956.6398 - val_loss: 40050.2188\n",
      "Epoch 535/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26142.8491 - val_loss: 40087.3008\n",
      "Epoch 536/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24503.9360 - val_loss: 40431.6289\n",
      "Epoch 537/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24990.7779 - val_loss: 40334.5898\n",
      "Epoch 538/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24344.6227 - val_loss: 40195.5234\n",
      "Epoch 539/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23869.8397 - val_loss: 40140.7148\n",
      "Epoch 540/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27398.8562 - val_loss: 40775.0000\n",
      "Epoch 541/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24051.9086 - val_loss: 40466.0742\n",
      "Epoch 542/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21846.7253 - val_loss: 42944.2461\n",
      "Epoch 543/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24777.9632 - val_loss: 40206.7383\n",
      "Epoch 544/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 25642.2696 - val_loss: 40001.0508\n",
      "Epoch 545/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23253.6684 - val_loss: 40050.8633\n",
      "Epoch 546/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25697.0694 - val_loss: 40726.0664\n",
      "Epoch 547/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24603.2686 - val_loss: 40541.6094\n",
      "Epoch 548/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24370.9461 - val_loss: 40477.8164\n",
      "Epoch 549/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23175.0391 - val_loss: 42436.7188\n",
      "Epoch 550/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24784.9006 - val_loss: 39885.9844\n",
      "Epoch 551/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23944.8463 - val_loss: 39985.5469\n",
      "Epoch 552/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25812.0401 - val_loss: 40049.9492\n",
      "Epoch 553/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 25020.7529 - val_loss: 39928.3672\n",
      "Epoch 554/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24230.3968 - val_loss: 40540.8750\n",
      "Epoch 555/1000\n",
      "114/114 [==============================] - 1s 7ms/step - loss: 27595.3978 - val_loss: 39926.4492\n",
      "Epoch 556/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 26956.2089 - val_loss: 41793.6680\n",
      "Epoch 557/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21654.2690 - val_loss: 39956.1406\n",
      "Epoch 558/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 23170.9119 - val_loss: 39631.9062\n",
      "Epoch 559/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24223.4723 - val_loss: 39896.5234\n",
      "Epoch 560/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23545.1164 - val_loss: 39679.0625\n",
      "Epoch 561/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24021.7421 - val_loss: 39571.4609\n",
      "Epoch 562/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25174.7193 - val_loss: 39490.1211\n",
      "Epoch 563/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 23574.8873 - val_loss: 39788.4492\n",
      "Epoch 564/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22353.4715 - val_loss: 40673.3242\n",
      "Epoch 565/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24014.5843 - val_loss: 39508.2930\n",
      "Epoch 566/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24866.1910 - val_loss: 39709.6445\n",
      "Epoch 567/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22870.5386 - val_loss: 39472.7891\n",
      "Epoch 568/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24422.0873 - val_loss: 39627.1211\n",
      "Epoch 569/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26228.1037 - val_loss: 40157.3125\n",
      "Epoch 570/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22971.8642 - val_loss: 39282.2930\n",
      "Epoch 571/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25704.8764 - val_loss: 39645.8789\n",
      "Epoch 572/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22276.4382 - val_loss: 39056.4648\n",
      "Epoch 573/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 27768.3624 - val_loss: 39760.6953\n",
      "Epoch 574/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23942.4762 - val_loss: 39279.6367\n",
      "Epoch 575/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21782.8666 - val_loss: 40071.9297\n",
      "Epoch 576/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23587.4433 - val_loss: 39468.1367\n",
      "Epoch 577/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22465.0503 - val_loss: 40159.4922\n",
      "Epoch 578/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24658.6786 - val_loss: 40516.7930\n",
      "Epoch 579/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23313.3085 - val_loss: 39402.6914\n",
      "Epoch 580/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23733.5035 - val_loss: 39258.6016\n",
      "Epoch 581/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23068.0799 - val_loss: 39021.2695\n",
      "Epoch 582/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 22195.6848 - val_loss: 39202.3008\n",
      "Epoch 583/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 23411.2880 - val_loss: 39918.0352\n",
      "Epoch 584/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 25549.0367 - val_loss: 39241.2305\n",
      "Epoch 585/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23072.0374 - val_loss: 38866.4375\n",
      "Epoch 586/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 3ms/step - loss: 23482.7014 - val_loss: 39143.1289\n",
      "Epoch 587/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25365.9100 - val_loss: 39044.8203\n",
      "Epoch 588/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22844.0808 - val_loss: 38842.3789\n",
      "Epoch 589/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24992.2097 - val_loss: 39585.3203\n",
      "Epoch 590/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24383.0646 - val_loss: 38937.2148\n",
      "Epoch 591/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23567.6232 - val_loss: 39522.6094\n",
      "Epoch 592/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22001.4571 - val_loss: 38705.0273\n",
      "Epoch 593/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26614.3324 - val_loss: 39827.6250\n",
      "Epoch 594/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21611.5466 - val_loss: 38911.7422\n",
      "Epoch 595/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23781.2338 - val_loss: 38984.6328\n",
      "Epoch 596/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23928.8781 - val_loss: 38964.4023\n",
      "Epoch 597/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22378.5322 - val_loss: 38752.9336\n",
      "Epoch 598/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25220.2249 - val_loss: 38716.4219\n",
      "Epoch 599/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22512.7160 - val_loss: 38590.9453\n",
      "Epoch 600/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24118.4801 - val_loss: 39058.5352\n",
      "Epoch 601/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23998.7056 - val_loss: 38849.8086\n",
      "Epoch 602/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21326.9598 - val_loss: 38834.0859\n",
      "Epoch 603/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27129.8063 - val_loss: 38437.2930\n",
      "Epoch 604/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22588.5760 - val_loss: 38977.4102\n",
      "Epoch 605/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24649.3637 - val_loss: 39164.8711\n",
      "Epoch 606/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21156.8945 - val_loss: 38587.3516\n",
      "Epoch 607/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28275.6477 - val_loss: 39170.5898\n",
      "Epoch 608/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20029.3949 - val_loss: 38574.2930\n",
      "Epoch 609/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23271.5752 - val_loss: 39876.4531\n",
      "Epoch 610/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22414.3833 - val_loss: 38406.3984\n",
      "Epoch 611/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21763.9446 - val_loss: 38535.9375\n",
      "Epoch 612/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23160.3827 - val_loss: 38508.9141\n",
      "Epoch 613/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 29309.5767 - val_loss: 38556.6641\n",
      "Epoch 614/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23092.6631 - val_loss: 38837.5078\n",
      "Epoch 615/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22470.0625 - val_loss: 38974.2617\n",
      "Epoch 616/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22671.4077 - val_loss: 38712.1133\n",
      "Epoch 617/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22380.5098 - val_loss: 38479.2305\n",
      "Epoch 618/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 27880.8584 - val_loss: 38617.7188\n",
      "Epoch 619/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25372.9492 - val_loss: 38496.5352\n",
      "Epoch 620/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19754.4470 - val_loss: 38563.4297\n",
      "Epoch 621/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24837.7014 - val_loss: 39244.2656\n",
      "Epoch 622/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23620.5322 - val_loss: 38233.0547\n",
      "Epoch 623/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26318.0604 - val_loss: 38294.2344\n",
      "Epoch 624/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 28431.8952 - val_loss: 39026.6875\n",
      "Epoch 625/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22554.7837 - val_loss: 38219.7539\n",
      "Epoch 626/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23068.5356 - val_loss: 39852.6367\n",
      "Epoch 627/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22399.7156 - val_loss: 38257.1172\n",
      "Epoch 628/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24142.8202 - val_loss: 38522.1094\n",
      "Epoch 629/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21911.7269 - val_loss: 38099.0195\n",
      "Epoch 630/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21009.6617 - val_loss: 38606.3477\n",
      "Epoch 631/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21613.0540 - val_loss: 38617.4219\n",
      "Epoch 632/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23442.6543 - val_loss: 38176.8164\n",
      "Epoch 633/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21116.2294 - val_loss: 38393.9805\n",
      "Epoch 634/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22041.3363 - val_loss: 37953.7812\n",
      "Epoch 635/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21415.5633 - val_loss: 40814.2812\n",
      "Epoch 636/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21617.9604 - val_loss: 38209.3633\n",
      "Epoch 637/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 22332.5845 - val_loss: 39260.3633\n",
      "Epoch 638/1000\n",
      "114/114 [==============================] - 1s 8ms/step - loss: 22940.3230 - val_loss: 38140.1953\n",
      "Epoch 639/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 25252.2885 - val_loss: 38047.4180\n",
      "Epoch 640/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21659.9718 - val_loss: 38930.3242\n",
      "Epoch 641/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21858.5520 - val_loss: 38087.7812\n",
      "Epoch 642/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22564.6336 - val_loss: 37999.3398\n",
      "Epoch 643/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24368.4946 - val_loss: 38252.0781\n",
      "Epoch 644/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24789.9994 - val_loss: 38174.1797\n",
      "Epoch 645/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 26057.6415 - val_loss: 38106.9492\n",
      "Epoch 646/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 30993.3521 - val_loss: 37967.7148\n",
      "Epoch 647/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21728.3422 - val_loss: 39098.8711\n",
      "Epoch 648/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21822.4226 - val_loss: 38161.0820\n",
      "Epoch 649/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21273.2438 - val_loss: 39767.5703\n",
      "Epoch 650/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22896.1963 - val_loss: 38171.9102\n",
      "Epoch 651/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21008.7970 - val_loss: 38123.1914\n",
      "Epoch 652/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22858.1331 - val_loss: 38092.6016\n",
      "Epoch 653/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 23697.6300 - val_loss: 37923.7109\n",
      "Epoch 654/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21763.2290 - val_loss: 38099.2930\n",
      "Epoch 655/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22025.8413 - val_loss: 37946.9805\n",
      "Epoch 656/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22039.5161 - val_loss: 37792.4688\n",
      "Epoch 657/1000\n",
      "114/114 [==============================] - 1s 4ms/step - loss: 23191.8408 - val_loss: 38283.1250\n",
      "Epoch 658/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19489.2819 - val_loss: 37897.5508\n",
      "Epoch 659/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 22069.6791 - val_loss: 38149.6250\n",
      "Epoch 660/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23586.4825 - val_loss: 37930.1211\n",
      "Epoch 661/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 23324.7932 - val_loss: 38696.9805\n",
      "Epoch 662/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 21560.6565 - val_loss: 39350.9297\n",
      "Epoch 663/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 23046.7285 - val_loss: 38011.9492\n",
      "Epoch 664/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 22001.3697 - val_loss: 38905.5078\n",
      "Epoch 665/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21415.1378 - val_loss: 38188.7617\n",
      "Epoch 666/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21437.3596 - val_loss: 37900.2422\n",
      "Epoch 667/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25930.9797 - val_loss: 38206.0859\n",
      "Epoch 668/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23188.3984 - val_loss: 37967.7852\n",
      "Epoch 669/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22182.1354 - val_loss: 38061.1211\n",
      "Epoch 670/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20780.7326 - val_loss: 40811.3203\n",
      "Epoch 671/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25449.0332 - val_loss: 38551.7227\n",
      "Epoch 672/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21893.8892 - val_loss: 38738.6953\n",
      "Epoch 673/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22864.1868 - val_loss: 37977.2852\n",
      "Epoch 674/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21125.7978 - val_loss: 38633.6289\n",
      "Epoch 675/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20743.3786 - val_loss: 37765.1797\n",
      "Epoch 676/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21950.0776 - val_loss: 37780.7539\n",
      "Epoch 677/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21066.7069 - val_loss: 39029.7500\n",
      "Epoch 678/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26054.4484 - val_loss: 37859.0898\n",
      "Epoch 679/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20932.7428 - val_loss: 37839.2930\n",
      "Epoch 680/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20489.9936 - val_loss: 37885.5234\n",
      "Epoch 681/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21978.3929 - val_loss: 38749.9531\n",
      "Epoch 682/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 23704.9768 - val_loss: 37840.5039\n",
      "Epoch 683/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23814.0744 - val_loss: 38251.7500\n",
      "Epoch 684/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21990.1057 - val_loss: 38706.6328\n",
      "Epoch 685/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21145.7851 - val_loss: 37570.2773\n",
      "Epoch 686/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23727.3677 - val_loss: 37746.6875\n",
      "Epoch 687/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22231.3372 - val_loss: 37668.4180\n",
      "Epoch 688/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24997.8956 - val_loss: 38292.8164\n",
      "Epoch 689/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19165.1977 - val_loss: 38541.9766\n",
      "Epoch 690/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21964.4633 - val_loss: 37789.9531\n",
      "Epoch 691/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21589.4579 - val_loss: 37473.8828\n",
      "Epoch 692/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23991.0400 - val_loss: 38413.1914\n",
      "Epoch 693/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21878.1048 - val_loss: 37700.9375\n",
      "Epoch 694/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19288.9799 - val_loss: 37519.2305\n",
      "Epoch 695/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23588.8809 - val_loss: 37938.0859\n",
      "Epoch 696/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21583.5026 - val_loss: 37947.0898\n",
      "Epoch 697/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22655.9126 - val_loss: 40314.3398\n",
      "Epoch 698/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21587.7491 - val_loss: 37633.0156\n",
      "Epoch 699/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21082.1886 - val_loss: 37646.5117\n",
      "Epoch 700/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21436.4431 - val_loss: 37585.4180\n",
      "Epoch 701/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19999.3327 - val_loss: 37864.3320\n",
      "Epoch 702/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21697.8797 - val_loss: 38118.8555\n",
      "Epoch 703/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21208.5415 - val_loss: 37715.8984\n",
      "Epoch 704/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20463.2385 - val_loss: 38084.8789\n",
      "Epoch 705/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24683.7626 - val_loss: 37403.3789\n",
      "Epoch 706/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22163.1782 - val_loss: 37658.4609\n",
      "Epoch 707/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22560.5243 - val_loss: 37563.6094\n",
      "Epoch 708/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20809.0443 - val_loss: 37510.1836\n",
      "Epoch 709/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24072.7085 - val_loss: 38045.8867\n",
      "Epoch 710/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20580.4164 - val_loss: 37606.1445\n",
      "Epoch 711/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21338.0823 - val_loss: 38073.8398\n",
      "Epoch 712/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20208.5964 - val_loss: 37549.4648\n",
      "Epoch 713/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22120.9239 - val_loss: 37948.3125\n",
      "Epoch 714/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23392.7252 - val_loss: 37571.2773\n",
      "Epoch 715/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23359.8336 - val_loss: 37840.7656\n",
      "Epoch 716/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21380.1594 - val_loss: 37392.9688\n",
      "Epoch 717/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20915.6235 - val_loss: 39265.9883\n",
      "Epoch 718/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22248.5519 - val_loss: 37439.4062\n",
      "Epoch 719/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22953.5076 - val_loss: 38602.3086\n",
      "Epoch 720/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22364.3082 - val_loss: 37580.9844\n",
      "Epoch 721/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19496.4873 - val_loss: 37374.3750\n",
      "Epoch 722/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21485.6981 - val_loss: 37659.3281\n",
      "Epoch 723/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21185.8005 - val_loss: 37427.0977\n",
      "Epoch 724/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20648.5782 - val_loss: 37397.1680\n",
      "Epoch 725/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20171.6365 - val_loss: 37467.9648\n",
      "Epoch 726/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21271.2160 - val_loss: 37173.7773\n",
      "Epoch 727/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22388.5898 - val_loss: 38180.4375\n",
      "Epoch 728/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21501.3603 - val_loss: 38074.2422\n",
      "Epoch 729/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22934.2187 - val_loss: 39062.8008\n",
      "Epoch 730/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21762.2061 - val_loss: 38289.6641\n",
      "Epoch 731/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22997.0318 - val_loss: 37708.1836\n",
      "Epoch 732/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 4ms/step - loss: 22502.4087 - val_loss: 37941.0859\n",
      "Epoch 733/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22316.4079 - val_loss: 37824.2031\n",
      "Epoch 734/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24868.7140 - val_loss: 38024.7031\n",
      "Epoch 735/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21677.3168 - val_loss: 37721.5586\n",
      "Epoch 736/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21727.4442 - val_loss: 37465.1797\n",
      "Epoch 737/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21439.6748 - val_loss: 37514.5508\n",
      "Epoch 738/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23000.9614 - val_loss: 37467.0586\n",
      "Epoch 739/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25939.2355 - val_loss: 37336.7383\n",
      "Epoch 740/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23246.7317 - val_loss: 37499.1758\n",
      "Epoch 741/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 25251.3211 - val_loss: 37726.7148\n",
      "Epoch 742/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20877.3807 - val_loss: 37570.6016\n",
      "Epoch 743/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20089.2531 - val_loss: 37325.5430\n",
      "Epoch 744/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21297.6020 - val_loss: 37326.6562\n",
      "Epoch 745/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20759.0152 - val_loss: 39227.4648\n",
      "Epoch 746/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20924.3653 - val_loss: 37649.5117\n",
      "Epoch 747/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22486.3919 - val_loss: 37607.4180\n",
      "Epoch 748/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21669.1805 - val_loss: 37743.2227\n",
      "Epoch 749/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20432.6687 - val_loss: 37456.2266\n",
      "Epoch 750/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21434.8401 - val_loss: 37382.7461\n",
      "Epoch 751/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23429.9732 - val_loss: 37530.7188\n",
      "Epoch 752/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19453.0423 - val_loss: 38011.3086\n",
      "Epoch 753/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21347.0571 - val_loss: 37782.3945\n",
      "Epoch 754/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20971.2394 - val_loss: 38085.8438\n",
      "Epoch 755/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21635.3750 - val_loss: 38332.2109\n",
      "Epoch 756/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21276.5953 - val_loss: 37364.5586\n",
      "Epoch 757/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 24188.4266 - val_loss: 37639.7070\n",
      "Epoch 758/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21338.5878 - val_loss: 38277.5898\n",
      "Epoch 759/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21137.3052 - val_loss: 37602.4062\n",
      "Epoch 760/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21894.7865 - val_loss: 37328.0781\n",
      "Epoch 761/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19880.4233 - val_loss: 38163.0508\n",
      "Epoch 762/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22397.3734 - val_loss: 37953.0508\n",
      "Epoch 763/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24471.2997 - val_loss: 38093.4375\n",
      "Epoch 764/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21259.1945 - val_loss: 37790.7773\n",
      "Epoch 765/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21554.1741 - val_loss: 37968.5664\n",
      "Epoch 766/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21872.5975 - val_loss: 37548.5000\n",
      "Epoch 767/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21149.8305 - val_loss: 37416.5664\n",
      "Epoch 768/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21110.2412 - val_loss: 37560.2227\n",
      "Epoch 769/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20426.6788 - val_loss: 37412.9336\n",
      "Epoch 770/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 19755.3883 - val_loss: 37710.3750\n",
      "Epoch 771/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19228.1214 - val_loss: 37571.0508\n",
      "Epoch 772/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20551.0361 - val_loss: 37649.3828\n",
      "Epoch 773/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20604.7921 - val_loss: 37392.1680\n",
      "Epoch 774/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20448.6123 - val_loss: 37270.7891\n",
      "Epoch 775/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20719.3687 - val_loss: 37582.7578\n",
      "Epoch 776/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21375.9206 - val_loss: 37914.9492\n",
      "Epoch 777/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20539.0404 - val_loss: 38890.7734\n",
      "Epoch 778/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20821.2730 - val_loss: 37749.1562\n",
      "Epoch 779/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21481.5184 - val_loss: 37198.0508\n",
      "Epoch 780/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19730.7103 - val_loss: 37511.2266\n",
      "Epoch 781/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19131.2192 - val_loss: 37289.6367\n",
      "Epoch 782/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22891.3272 - val_loss: 37512.8750\n",
      "Epoch 783/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20139.3899 - val_loss: 37304.0156\n",
      "Epoch 784/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21025.0052 - val_loss: 38116.0859\n",
      "Epoch 785/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22025.2532 - val_loss: 37318.2578\n",
      "Epoch 786/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20615.4350 - val_loss: 38297.6367\n",
      "Epoch 787/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23063.7764 - val_loss: 38303.6484\n",
      "Epoch 788/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20637.9865 - val_loss: 37235.8789\n",
      "Epoch 789/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21408.2586 - val_loss: 37393.3984\n",
      "Epoch 790/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21279.6452 - val_loss: 37431.0742\n",
      "Epoch 791/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 19853.0038 - val_loss: 37371.6719\n",
      "Epoch 792/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20342.1305 - val_loss: 37215.4492\n",
      "Epoch 793/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20693.1691 - val_loss: 37328.9102\n",
      "Epoch 794/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20260.0952 - val_loss: 38205.9531\n",
      "Epoch 795/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 18796.1552 - val_loss: 37637.5078\n",
      "Epoch 796/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19114.3164 - val_loss: 37467.4883\n",
      "Epoch 797/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21808.8941 - val_loss: 37797.6836\n",
      "Epoch 798/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21584.7676 - val_loss: 38183.8438\n",
      "Epoch 799/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20414.9418 - val_loss: 38513.6367\n",
      "Epoch 800/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22266.1176 - val_loss: 37276.4258\n",
      "Epoch 801/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 26833.1362 - val_loss: 37186.2031\n",
      "Epoch 802/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 18995.3995 - val_loss: 37468.5469\n",
      "Epoch 803/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22513.9997 - val_loss: 37159.8711\n",
      "Epoch 804/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 18599.0585 - val_loss: 37010.4766\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 4ms/step - loss: 19163.1909 - val_loss: 37441.0859\n",
      "Epoch 806/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22776.3299 - val_loss: 37112.7500\n",
      "Epoch 807/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21283.0533 - val_loss: 37011.2188\n",
      "Epoch 808/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24184.2102 - val_loss: 37007.8008\n",
      "Epoch 809/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20405.3040 - val_loss: 37300.3789\n",
      "Epoch 810/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18352.9153 - val_loss: 37147.7031\n",
      "Epoch 811/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21372.9403 - val_loss: 37102.6758\n",
      "Epoch 812/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23259.6208 - val_loss: 39184.6836\n",
      "Epoch 813/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20543.5754 - val_loss: 37339.5000\n",
      "Epoch 814/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19715.2048 - val_loss: 37398.5703\n",
      "Epoch 815/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20503.4641 - val_loss: 37294.9375\n",
      "Epoch 816/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22265.5964 - val_loss: 37204.5781\n",
      "Epoch 817/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22083.5227 - val_loss: 37243.1406\n",
      "Epoch 818/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19933.6419 - val_loss: 37490.2695\n",
      "Epoch 819/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21561.1572 - val_loss: 38177.6562\n",
      "Epoch 820/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21735.4918 - val_loss: 36983.6875\n",
      "Epoch 821/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20960.7364 - val_loss: 37253.8555\n",
      "Epoch 822/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21940.5362 - val_loss: 37596.6758\n",
      "Epoch 823/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21982.3768 - val_loss: 37847.9336\n",
      "Epoch 824/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19126.2438 - val_loss: 37149.1406\n",
      "Epoch 825/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19624.8747 - val_loss: 37613.0820\n",
      "Epoch 826/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20991.8860 - val_loss: 37026.4297\n",
      "Epoch 827/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21554.8063 - val_loss: 37345.9492\n",
      "Epoch 828/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22857.5844 - val_loss: 37800.9609\n",
      "Epoch 829/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19669.9998 - val_loss: 37722.0469\n",
      "Epoch 830/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20516.6174 - val_loss: 37108.3867\n",
      "Epoch 831/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21183.4623 - val_loss: 37618.5625\n",
      "Epoch 832/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20418.0941 - val_loss: 37210.1562\n",
      "Epoch 833/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19121.8379 - val_loss: 37382.7070\n",
      "Epoch 834/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21677.1077 - val_loss: 37031.2031\n",
      "Epoch 835/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20385.8774 - val_loss: 39865.4766\n",
      "Epoch 836/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20766.0722 - val_loss: 37100.3984\n",
      "Epoch 837/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19957.5440 - val_loss: 37201.1875\n",
      "Epoch 838/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21179.9587 - val_loss: 36892.1016\n",
      "Epoch 839/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22890.5574 - val_loss: 36975.2227\n",
      "Epoch 840/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19659.9625 - val_loss: 37428.1289\n",
      "Epoch 841/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18383.3912 - val_loss: 37227.7227\n",
      "Epoch 842/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21718.2161 - val_loss: 37237.6406\n",
      "Epoch 843/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21242.2858 - val_loss: 36963.3164\n",
      "Epoch 844/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22706.0108 - val_loss: 36929.9375\n",
      "Epoch 845/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20458.4718 - val_loss: 37399.9062\n",
      "Epoch 846/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20246.2746 - val_loss: 37033.7070\n",
      "Epoch 847/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20571.9705 - val_loss: 38092.3945\n",
      "Epoch 848/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21931.5759 - val_loss: 37033.7812\n",
      "Epoch 849/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20023.9402 - val_loss: 37776.9023\n",
      "Epoch 850/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 18751.5034 - val_loss: 36976.2031\n",
      "Epoch 851/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20976.8680 - val_loss: 37052.5352\n",
      "Epoch 852/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 24824.3911 - val_loss: 37492.1523\n",
      "Epoch 853/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19839.9596 - val_loss: 37652.2734\n",
      "Epoch 854/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21174.6298 - val_loss: 37666.8477\n",
      "Epoch 855/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21005.8696 - val_loss: 37504.8828\n",
      "Epoch 856/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20292.6815 - val_loss: 36906.8516\n",
      "Epoch 857/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 20835.0322 - val_loss: 37199.4961\n",
      "Epoch 858/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19563.1167 - val_loss: 37012.9648\n",
      "Epoch 859/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22247.8526 - val_loss: 37849.0078\n",
      "Epoch 860/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20759.7814 - val_loss: 36902.5078\n",
      "Epoch 861/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19862.3593 - val_loss: 37253.8594\n",
      "Epoch 862/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21969.1251 - val_loss: 37215.0391\n",
      "Epoch 863/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19280.3236 - val_loss: 38041.3906\n",
      "Epoch 864/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22119.5079 - val_loss: 37428.2773\n",
      "Epoch 865/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20473.0130 - val_loss: 37604.3516\n",
      "Epoch 866/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19085.0675 - val_loss: 36875.6836\n",
      "Epoch 867/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19345.0750 - val_loss: 36967.5352\n",
      "Epoch 868/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21998.7131 - val_loss: 37006.7148\n",
      "Epoch 869/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22748.4424 - val_loss: 38557.7109\n",
      "Epoch 870/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19037.3823 - val_loss: 36930.0469\n",
      "Epoch 871/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 19032.8058 - val_loss: 37630.6367\n",
      "Epoch 872/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22769.6256 - val_loss: 36923.4375\n",
      "Epoch 873/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19594.5083 - val_loss: 36873.9023\n",
      "Epoch 874/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24226.0230 - val_loss: 37992.0078\n",
      "Epoch 875/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20175.9781 - val_loss: 37396.9648\n",
      "Epoch 876/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21492.5790 - val_loss: 37355.3438\n",
      "Epoch 877/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21569.0346 - val_loss: 36811.0859\n",
      "Epoch 878/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 3ms/step - loss: 20233.2649 - val_loss: 36985.1055\n",
      "Epoch 879/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19148.7258 - val_loss: 37086.7305\n",
      "Epoch 880/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22175.9216 - val_loss: 37220.5352\n",
      "Epoch 881/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20249.7700 - val_loss: 37148.0898\n",
      "Epoch 882/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 21064.9838 - val_loss: 36906.2070\n",
      "Epoch 883/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21348.7152 - val_loss: 37143.6016\n",
      "Epoch 884/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20037.4794 - val_loss: 37501.5508\n",
      "Epoch 885/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19338.9948 - val_loss: 37190.3672\n",
      "Epoch 886/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20342.3490 - val_loss: 36849.7383\n",
      "Epoch 887/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18606.8249 - val_loss: 37413.6719\n",
      "Epoch 888/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19411.6365 - val_loss: 37102.4219\n",
      "Epoch 889/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19730.7830 - val_loss: 37430.9062\n",
      "Epoch 890/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20178.4970 - val_loss: 39687.0742\n",
      "Epoch 891/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20878.2997 - val_loss: 36775.0273\n",
      "Epoch 892/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23202.7052 - val_loss: 38327.8945\n",
      "Epoch 893/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20285.6235 - val_loss: 37197.8086\n",
      "Epoch 894/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23727.9036 - val_loss: 37896.2500\n",
      "Epoch 895/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 19806.9939 - val_loss: 37898.5273\n",
      "Epoch 896/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22891.5800 - val_loss: 36796.0898\n",
      "Epoch 897/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22443.0785 - val_loss: 36832.3203\n",
      "Epoch 898/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21882.2418 - val_loss: 37313.2969\n",
      "Epoch 899/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21841.4082 - val_loss: 37001.5000\n",
      "Epoch 900/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 19246.9834 - val_loss: 37149.4648\n",
      "Epoch 901/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19491.9490 - val_loss: 39706.0625\n",
      "Epoch 902/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19281.1922 - val_loss: 36835.5938\n",
      "Epoch 903/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18603.1667 - val_loss: 37425.3086\n",
      "Epoch 904/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19656.5931 - val_loss: 37067.0312\n",
      "Epoch 905/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23418.5370 - val_loss: 36773.7812\n",
      "Epoch 906/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21765.4944 - val_loss: 37119.4922\n",
      "Epoch 907/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21946.7441 - val_loss: 37318.4297\n",
      "Epoch 908/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20729.3522 - val_loss: 37526.8984\n",
      "Epoch 909/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20033.8338 - val_loss: 36973.7266\n",
      "Epoch 910/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 18063.0211 - val_loss: 37152.1250\n",
      "Epoch 911/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22225.1896 - val_loss: 37341.7734\n",
      "Epoch 912/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20078.5657 - val_loss: 36889.0859\n",
      "Epoch 913/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23049.9236 - val_loss: 37007.4297\n",
      "Epoch 914/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 24351.5463 - val_loss: 37283.6367\n",
      "Epoch 915/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20948.2877 - val_loss: 37258.4766\n",
      "Epoch 916/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 18498.0850 - val_loss: 36654.8242\n",
      "Epoch 917/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20950.9773 - val_loss: 37279.4414\n",
      "Epoch 918/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19940.8056 - val_loss: 36844.1641\n",
      "Epoch 919/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20975.5805 - val_loss: 36835.8438\n",
      "Epoch 920/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 23557.8731 - val_loss: 36907.7031\n",
      "Epoch 921/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 22229.8987 - val_loss: 36926.8789\n",
      "Epoch 922/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21871.8563 - val_loss: 37024.0156\n",
      "Epoch 923/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22762.3527 - val_loss: 36808.7422\n",
      "Epoch 924/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23394.3241 - val_loss: 37215.8008\n",
      "Epoch 925/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21763.4007 - val_loss: 36755.2148\n",
      "Epoch 926/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20504.4024 - val_loss: 36679.3711\n",
      "Epoch 927/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19497.0058 - val_loss: 36708.6641\n",
      "Epoch 928/1000\n",
      "114/114 [==============================] - 1s 5ms/step - loss: 20315.6684 - val_loss: 36685.0938\n",
      "Epoch 929/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19545.7626 - val_loss: 36730.9023\n",
      "Epoch 930/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19713.2705 - val_loss: 36714.2266\n",
      "Epoch 931/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20523.1915 - val_loss: 36729.0078\n",
      "Epoch 932/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19734.0317 - val_loss: 37577.4766\n",
      "Epoch 933/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19219.7957 - val_loss: 37261.7422\n",
      "Epoch 934/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20864.1532 - val_loss: 37216.7305\n",
      "Epoch 935/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20472.4309 - val_loss: 37452.6016\n",
      "Epoch 936/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22582.2717 - val_loss: 37114.2109\n",
      "Epoch 937/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20725.0185 - val_loss: 39302.9570\n",
      "Epoch 938/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 19351.4160 - val_loss: 36775.5156\n",
      "Epoch 939/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 18611.3514 - val_loss: 37261.8242\n",
      "Epoch 940/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21090.6878 - val_loss: 36821.1562\n",
      "Epoch 941/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21919.8310 - val_loss: 37266.1953\n",
      "Epoch 942/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18192.8938 - val_loss: 36731.7578\n",
      "Epoch 943/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21352.7223 - val_loss: 37079.3125\n",
      "Epoch 944/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20688.4544 - val_loss: 37149.4062\n",
      "Epoch 945/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19558.6724 - val_loss: 36689.4180\n",
      "Epoch 946/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17247.9941 - val_loss: 36933.9922\n",
      "Epoch 947/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 22988.2193 - val_loss: 37485.5078\n",
      "Epoch 948/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19155.6249 - val_loss: 37026.1016\n",
      "Epoch 949/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20397.1217 - val_loss: 37494.3125\n",
      "Epoch 950/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18398.1378 - val_loss: 36912.6719\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 3ms/step - loss: 22746.7754 - val_loss: 37342.2148\n",
      "Epoch 952/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 21462.1312 - val_loss: 37123.5078\n",
      "Epoch 953/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18323.6131 - val_loss: 36885.4961\n",
      "Epoch 954/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 23279.6761 - val_loss: 37572.6367\n",
      "Epoch 955/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19451.4886 - val_loss: 36558.1445\n",
      "Epoch 956/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21545.9870 - val_loss: 37479.0195\n",
      "Epoch 957/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19445.4527 - val_loss: 36489.3477\n",
      "Epoch 958/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20812.4887 - val_loss: 36949.4531\n",
      "Epoch 959/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19710.7505 - val_loss: 36726.4023\n",
      "Epoch 960/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19966.4347 - val_loss: 36712.9922\n",
      "Epoch 961/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 17287.1055 - val_loss: 36541.6797\n",
      "Epoch 962/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19970.8476 - val_loss: 37471.8711\n",
      "Epoch 963/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19395.4462 - val_loss: 36535.8164\n",
      "Epoch 964/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 18777.6742 - val_loss: 37431.6328\n",
      "Epoch 965/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20085.7520 - val_loss: 36718.2617\n",
      "Epoch 966/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18024.1628 - val_loss: 36888.5820\n",
      "Epoch 967/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18941.5463 - val_loss: 37029.8477\n",
      "Epoch 968/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19115.4122 - val_loss: 37025.9414\n",
      "Epoch 969/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17939.9625 - val_loss: 37108.6992\n",
      "Epoch 970/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 17289.4658 - val_loss: 36530.6797\n",
      "Epoch 971/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19866.6303 - val_loss: 36482.1875\n",
      "Epoch 972/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18862.1268 - val_loss: 40001.5312\n",
      "Epoch 973/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21991.5340 - val_loss: 37157.1953\n",
      "Epoch 974/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19803.9931 - val_loss: 36888.7148\n",
      "Epoch 975/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18232.6990 - val_loss: 37983.3008\n",
      "Epoch 976/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22765.3287 - val_loss: 36769.8086\n",
      "Epoch 977/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19757.3400 - val_loss: 37531.8203\n",
      "Epoch 978/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20210.0630 - val_loss: 36688.0508\n",
      "Epoch 979/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19999.9685 - val_loss: 36653.2539\n",
      "Epoch 980/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 18278.5912 - val_loss: 37132.2188\n",
      "Epoch 981/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19217.4746 - val_loss: 36542.7266\n",
      "Epoch 982/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19340.1206 - val_loss: 36797.0703\n",
      "Epoch 983/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 21481.2028 - val_loss: 36557.7773\n",
      "Epoch 984/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19738.8783 - val_loss: 37081.9375\n",
      "Epoch 985/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 18281.7748 - val_loss: 36412.4570\n",
      "Epoch 986/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 20120.6020 - val_loss: 36884.7578\n",
      "Epoch 987/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19441.4866 - val_loss: 37521.1914\n",
      "Epoch 988/1000\n",
      "114/114 [==============================] - 0s 4ms/step - loss: 18770.6945 - val_loss: 37679.4688\n",
      "Epoch 989/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 20116.0612 - val_loss: 36694.9688\n",
      "Epoch 990/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19637.9351 - val_loss: 36440.0430\n",
      "Epoch 991/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22754.1233 - val_loss: 36555.1250\n",
      "Epoch 992/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19728.5820 - val_loss: 37139.2461\n",
      "Epoch 993/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18333.4743 - val_loss: 36982.8086\n",
      "Epoch 994/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18867.6802 - val_loss: 37936.7656\n",
      "Epoch 995/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22496.8113 - val_loss: 36658.6875\n",
      "Epoch 996/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 17636.5416 - val_loss: 36587.2344\n",
      "Epoch 997/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 22171.1828 - val_loss: 36427.3281\n",
      "Epoch 998/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 18206.8905 - val_loss: 36702.1953\n",
      "Epoch 999/1000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 19902.3547 - val_loss: 36623.2734\n",
      "Epoch 1000/1000\n",
      "114/114 [==============================] - 0s 3ms/step - loss: 19997.4083 - val_loss: 36899.4570\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units= 50, kernel_initializer = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 25, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(units = 50, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['SalePrice'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-fb5f8506a3e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mann_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_Test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4313\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4314\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4315\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4316\u001b[0m         )\n\u001b[1;32m   4317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4153\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4188\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5590\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5591\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['SalePrice'] not found in axis\""
     ]
    }
   ],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[120598.984],\n",
       "       [139502.98 ],\n",
       "       [191971.78 ],\n",
       "       ...,\n",
       "       [185340.42 ],\n",
       "       [133224.34 ],\n",
       "       [222842.1  ]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_pred = classifier.predict(df_Test)\n",
    "ann_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing the Keras libraries and packages\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LeakyReLU,PReLU,ELU\n",
    "# from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# # Initialising the ANN\n",
    "# classifier = Sequential()\n",
    "\n",
    "# # Adding the input layer and the first hidden layer\n",
    "# classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# # Adding the second hidden layer\n",
    "# classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# # Adding the third hidden layer\n",
    "# classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# # Adding the output layer\n",
    "# classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# # Compiling the ANN\n",
    "# classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# # Fitting the ANN to the Training set\n",
    "# model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
